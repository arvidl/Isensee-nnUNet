{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GejzW3QmYc0"
   },
   "source": [
    "# nnU-Net Workshop \n",
    "\n",
    "(modified AL 2022-11-27)\n",
    "\n",
    "The nnU-Net is a toolkit to segment imaging data and was specifically designed for biomedical data.\n",
    "\n",
    "It was designed by **Fabian Isensee** while pursuing his PhD at the [Medical Image Computing Division of the German Cancer Research Institute](https://www.dkfz.de/en/mic/index.php).\n",
    "\n",
    "More information about nnU-Net, as well as the installataion guide on your own workstation can be found on:\n",
    "- Isensee, F., Jaeger, P. F., Kohl, S. A. A., Petersen, J. & Maier-Hein, K. H. [nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation](http://www.nature.com/articles/s41592-020-01008-z). Nat Methods 18, 203–211 (2021).\n",
    "- [nnU-Net GitHub Page](https://github.com/MIC-DKFZ/nnUNet)\n",
    "\n",
    "\n",
    "\n",
    "## What is this Workshop all about?\n",
    "\n",
    "The goal of this workshop is to allow end-users to understand in how to use nnU-Net for their own applications.\n",
    "\n",
    "It includes initial setup and how to use nnU-Net in the Google Colab environment. \n",
    "Some steps are only needed for GoogleColab and will be explained, while others are generally applicable. \n",
    "\n",
    "Further it is advised to visualize the data with segmentations using the [MITK-Workbench](https://www.mitk.org/wiki/The_Medical_Imaging_Interaction_Toolkit_(MITK)), which is also developed in the Medical Image Computing Division of the German Cancer Research Institute - at least this is what we advocate.\n",
    "\n",
    "- [MITK Workbench Download Link](https://www.mitk.org/wiki/Downloads)\n",
    "\n",
    "### Requirements for Google Colab \n",
    "1. Google Account\n",
    "   1. At least 4GB of free disk space\n",
    "2. Visualization tool for volumetric data, we advise to use MITK.\n",
    "\n",
    "### Some notes about the Workshop\n",
    "\n",
    "This workshop was created by **Carsten Lüth**, a PhD student in the [Interactive Machine Learning Research Group](https://www.dkfz.de/en/interaktives-maschinelles-lernen/index.php) headed by Dr. Paul F. Jäger.\n",
    "\n",
    "If you happen to find this workshop in any way useful, please share this version of it:\n",
    "- [https://github.com/IML-DKFZ/nnunet-workshop](https://github.com/IML-DKFZ/nnunet-workshop)\n",
    "\n",
    "## Further information\n",
    "\n",
    "Further Information about nnU-Net is presented in the following lectures:\n",
    "- [Lecture by Paul F. Jäger](https://www.youtube.com/watch?v=3po8qVzz5Tc&t=2196s)\n",
    "- [Lecture by Fabian Isensee](https://www.youtube.com/watch?v=C6tpnJRpt90)\n",
    "\n",
    "### MITK with nnU-Net\n",
    "MITK has a new experimental feature which uses pretrained nnU-Net models as a segmentation tool.\n",
    "This feature has been added since its release of version 2022.04.\n",
    "For further information about this we refer to the [MITK Documentation](https://docs.mitk.org/2022.04/org_mitk_views_segmentation.html#org_mitk_views_segmentationnnUNetTool).\n",
    "\n",
    "\n",
    "**Notes**:\n",
    "- quite some time was spent to optimize the way of downloading and unpacking the data. I did not get to run it at all when automated... If you have any idea how to do this better (and show that it works I would greatly appreciate this!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THifmOYu9Cip"
   },
   "source": [
    "# 1. Import Packages for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "k-hj38QV_raZ"
   },
   "outputs": [],
   "source": [
    "# Import basic packages for later use\n",
    "import os\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ld3_-quILggy"
   },
   "outputs": [],
   "source": [
    "# check whether GPU accelerated computing is available\n",
    "assert torch.cuda.is_available() # if there is an error here, enable GPU in the Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0+cu117'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.14.0+cu117'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 27 18:15:24 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Quadro RTX 6000     Off  | 00000000:65:00.0  On |                  Off |\r\n",
      "| 33%   27C    P8    27W / 260W |    412MiB / 24197MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      2657      G   /usr/lib/xorg/Xorg                171MiB |\r\n",
      "|    0   N/A  N/A      3070      G   /usr/bin/gnome-shell               50MiB |\r\n",
      "|    0   N/A  N/A      3815      G   ...veSuggestionsOnlyOnDemand       43MiB |\r\n",
      "|    0   N/A  N/A     21019      G   ...084675465893193554,131072      140MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The notebook is not running on Colab. colab=False.\n"
     ]
    }
   ],
   "source": [
    "# This is a quick check of whether the notebook is currently running on Google Colaboratory, as that makes some difference for the code below.\n",
    "# We'll do this in every notebook of the course.\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('The notebook is running on Colab. colab=True.')\n",
    "    colab=True\n",
    "else:\n",
    "    print('The notebook is not running on Colab. colab=False.')\n",
    "    colab=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNfZ1NHt9WeI"
   },
   "source": [
    "# 2. Installing nnU-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9626,
     "status": "ok",
     "timestamp": 1643208040182,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "2BYdj3iw1q-8",
    "outputId": "ac758cda-6e94-41a2-8b69-592df6b9a20a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleITK version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "# due to problems with the dataset with newest simple ITK version preinstall a special version\n",
    "# for more information about this see: https://github.com/MIC-DKFZ/nnUNet/issues/756\n",
    "\n",
    "if colab:\n",
    "    !pip install SimpleITK==2.0.2\n",
    "else:\n",
    "    import SimpleITK as sitk\n",
    "    print(f\"SimpleITK version: {sitk.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 22403,
     "status": "ok",
     "timestamp": 1643208064772,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "K--4dWRI_xGW",
    "outputId": "42890394-93a6-463f-8ad1-76c35c49524a"
   },
   "outputs": [],
   "source": [
    "# install nnunet - yes it is that easy\n",
    "if colab:\n",
    "    !pip install nnunet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtDKBF_4SJV8"
   },
   "source": [
    "**Note**: you do not have to restart the Runtime even when the following error appears, this is simply due to a reinstallation of a package - so no worries. \n",
    "\n",
    "\n",
    "```\n",
    "WARNING: The following packages were previously imported in this runtime:\n",
    "\n",
    "[argparse]\n",
    "\n",
    "You must restart the runtime in order to use newly installed versions.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oE-RujwI9efB"
   },
   "source": [
    "# 3. Verifying installation of nn-Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 477,
     "status": "ok",
     "timestamp": 1643208071545,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "7aFVfOoP_2XS",
    "outputId": "570e2e8f-2869-4014-c3af-3c4e664a0594"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if nnunet can be imported\n",
    "import nnunet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDq5g_uk9pBU"
   },
   "source": [
    "You should read the following if the installation was successful:\n",
    "\n",
    "\n",
    "```\n",
    "Please cite the following paper when using nnUNet:\n",
    "\n",
    "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
    "\n",
    "\n",
    "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9U4Uy_jSv7Z"
   },
   "source": [
    "## 3.1 Installation and initialization of Weights&Biases (non-mandatory)\n",
    "This is a package which allows you to easily visualize metrics during your training.\n",
    "\n",
    "We will use this here to get access to System Information (GPU utilization etc.)when running on Google Colab - however it is also useful to use at a local workstation.\n",
    "\n",
    "To use Weights&Biases you will need an account.\n",
    "This can be created at https://wandb.ai\n",
    "\n",
    "During the initialization with ```wandb.init()``` it will ask you for an API key, which you can obtain from:\n",
    "https://wandb.ai/settings \n",
    "under API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9552,
     "status": "ok",
     "timestamp": 1643208093086,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "04pXUQbq7_Sy",
    "outputId": "f0e8cdda-ee22-45f2-aeda-53139b5131b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb version: 0.13.5\n"
     ]
    }
   ],
   "source": [
    "if colab:\n",
    "    !pip install wandb\n",
    "else:\n",
    "    # !pip install wandb (See above)\n",
    "    import wandb\n",
    "    print(f\"wandb version: {wandb.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "executionInfo": {
     "elapsed": 34256,
     "status": "ok",
     "timestamp": 1643208132962,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "LcEDj7vrYmkK",
    "outputId": "e721c305-97b0-4c76-f162-abe2e3b5f7ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marvidl\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arvid/GitHub/Isensee-nnUNet/nnunet-workshop/wandb/run-20221127_181530-2sc5w4y5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/arvidl/Isensee-nnUNet/runs/2sc5w4y5\" target=\"_blank\">lucky-dew-7</a></strong> to <a href=\"https://wandb.ai/arvidl/Isensee-nnUNet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/arvidl/Isensee-nnUNet/runs/2sc5w4y5?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f421c6a1940>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"Isensee-nnUNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHOVufx9BOT6"
   },
   "source": [
    "### 3.2 Installation of GDOWN (only for in-person workshops)\n",
    "GDown allows to download files from GoogleDrive with Python.\n",
    "Therefore it is used for in-person workshops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3498,
     "status": "ok",
     "timestamp": 1643208184049,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "deZRQMrRxfWX",
    "outputId": "af59c39f-9e02-4337-b1e1-1d685c77081c"
   },
   "outputs": [],
   "source": [
    "# install gdown to download files from GoogleDrive\n",
    "if colab:\n",
    "    !pip install gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgssjiuNVvq5"
   },
   "source": [
    "# 4. Connect Google Colab with GoogleDrive\n",
    "This is heavily encouraged when using Google Colab, otherwise loading, accessing and saving of data checkpoints etc. is just much harder (if not impossible).\n",
    "\n",
    "**Note**:\n",
    "When ```drive.mount()``` is executed, there will appear a popup window, which will ask you which Google Account should be connected and then for permission regarding Colab accessing your GoogleDrive.\n",
    "\n",
    "There can be some problems at this step, for me the solution was to Download the GoogleDrive Application.\n",
    "You can download it from: https://www.google.com/drive/download/\n",
    "\n",
    "\n",
    "If there are any problems at this stage, feel free to contact me (during the workshop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23111,
     "status": "ok",
     "timestamp": 1643208211084,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "_WLi-mVRjbfb",
    "outputId": "3297794c-79fb-46a5-b976-8dbedd47942d"
   },
   "outputs": [],
   "source": [
    "# for colab users only - mounting the drive\n",
    "\n",
    "if colab:\n",
    "    !pip install gdown\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive',force_remount = True)\n",
    "    \n",
    "    drive_dir = \"/content/drive/My Drive\"\n",
    "    mount_dir = os.path.join(drive_dir, \"Colab Notebooks\")\n",
    "    base_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AheBsrsiYmkY"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    assert os.path.exists(drive_dir) # if this fails, something went wrong with mounting GoogleDrive\n",
    "    if os.path.exists(mount_dir) is False:\n",
    "        os.makedirs(mount_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-CV4Jc4W77P"
   },
   "source": [
    "# 5. Setting up nnU-Nets folder structure and environment variables\n",
    "nnUnet expects a certain folder structure and environment variables. \n",
    "\n",
    "Roughly they tell nnUnet:\n",
    "1. Where to look for stuff\n",
    "2. Where to put stuff\n",
    "\n",
    "For more information about this please check: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/setting_up_paths.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "T9ifLrYhjfAT"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    def make_if_dont_exist(folder_path,overwrite=False):\n",
    "        \"\"\"\n",
    "        creates a folder if it does not exists\n",
    "        input: \n",
    "        folder_path : relative path of the folder which needs to be created\n",
    "        over_write :(default: False) if True overwrite the existing folder \n",
    "        \"\"\"\n",
    "        if os.path.exists(folder_path):\n",
    "        \n",
    "            if not overwrite:\n",
    "                print(f\"{folder_path} exists.\")\n",
    "            else:\n",
    "                print(f\"{folder_path} overwritten\")\n",
    "                shutil.rmtree(folder_path)\n",
    "                os.makedirs(folder_path)\n",
    "\n",
    "        else:\n",
    "            os.makedirs(folder_path)\n",
    "            print(f\"{folder_path} created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAvjVPF0_7t3"
   },
   "source": [
    "## 5.1 Set environment Variables and creating folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1643208223481,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "3rlqq-V-CWh8",
    "outputId": "f9978966-693e-4591-fe5c-48fe9695e9bb"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    # Maybe move path of preprocessed data directly on content - this may be signifcantely faster!\n",
    "    print(\"Current Working Directory {}\".format(os.getcwd()))\n",
    "    path_dict = {\n",
    "        \"nnUNet_raw_data_base\" : os.path.join(mount_dir, \"nnUNet_raw_data_base\"), \n",
    "        \"nnUNet_preprocessed\" : os.path.join(mount_dir, \"nnUNet_preprocessed\"), # 1 experiment: 1 epoch took 112s\n",
    "        # \"nnUNet_preprocessed\" : os.path.join(base_dir, \"nnUNet_preprocessed\"), # 1 experiment: 1 epoch took 108s -> seems faster take this\n",
    "        \"RESULTS_FOLDER\" : os.path.join(mount_dir, \"nnUNet_Results_Folder\"),\n",
    "        \"RAW_DATA_PATH\" : os.path.join(mount_dir, \"RawData\"), # This is used here only for convenience (not necessary for nnU-Net)!\n",
    "    }\n",
    "\n",
    "    # Write paths to environment variables\n",
    "    for env_var, path in path_dict.items():\n",
    "        os.environ[env_var] = path \n",
    "\n",
    "    # Check whether all environment variables are set correct!\n",
    "    for env_var, path in path_dict.items():\n",
    "        if os.getenv(env_var) != path:\n",
    "            print(\"Error:\")\n",
    "            print(\"Environment Variable {} is not set correctly!\".format(env_var))\n",
    "            print(\"Should be {}\".format(path))\n",
    "            print(\"Variable is {}\".format(os.getenv(env_var)))\n",
    "        make_if_dont_exist(path, overwrite=False)\n",
    "\n",
    "    print(\"If No Error Occured Continue Forward. =)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLG69VKoX-BA"
   },
   "source": [
    "# 6. Using nnU-Net on Medical Decathlon tasks\n",
    "To get us started and also verify that nnU-Net works properly on our system, we will now run a training with nnU-Net and then make some predictions.\n",
    "\n",
    "This will be done on parts of the Medical Decathlon Dataset, because everything is already nicely set up for these datasets.\n",
    "\n",
    "Also for these two tasks there exist pre-written scripts, automatically unpacking and preparing the data for nnU-Net to use.\n",
    "\n",
    "For this we will follow the two examples given in the nnU-Net repository for:\n",
    "- [Training on Task004 Hippocampus Dataset](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/training_example_Hippocampus.md)\n",
    "- [Run Inference on Task005 Prostate Dataset](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/inference_example_Prostate.md)\n",
    "\n",
    "Bottom Line:\n",
    "If something goes wrong here, it is worth to check whether anything went wrong before these steps! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBxlyQ3rY7X_"
   },
   "source": [
    "## 6.1 Downloading the Data\n",
    "Download the data, unpack it and put it in the proper folder.\n",
    "Generally, you will then have to download and move the files to the correct folder yourself.\n",
    "\n",
    "Link to official [GoogleDrive](https://drive.google.com/drive/folders/1HqEgzS8BV2c7xYNrZdEAnrHk7osJJ--2) for the download.\n",
    "\n",
    "If you are doing this by hand - skip the two next cells!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 Downloading the Data for in-person workshops\n",
    "For in person workshops, this will be automated and I host the data from GoogleDrive.\n",
    "This is due to time constraints of this workshop and I will take the links down later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VHp6RxzNPjka"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    # only for in person workshops\n",
    "\n",
    "    # Download the data with gdown\n",
    "\n",
    "    os.chdir(path_dict[\"RAW_DATA_PATH\"])\n",
    "    # Download the Hippocampus Dataset\n",
    "    !gdown 'https://drive.google.com/uc?export=download&id=1L-22VV6J8O6afTSOQuQKFiH-tblxb_TW'\n",
    "\n",
    "    # Download the Prostate Dataset\n",
    "    !gdown  'https://drive.google.com/uc?export=download&id=1L-4D5szfpo7eO639TBmnukw9y_X9h5Yc'\n",
    "    os.chdir(base_dir)\n",
    "\n",
    "    print(\"Data should be located in folder: {}\".format(path_dict[\"RAW_DATA_PATH\"]))\n",
    "    assert os.path.isfile(os.path.join(path_dict[\"RAW_DATA_PATH\"], \"Task04_Hippocampus.zip\")) # check whether the file is correctly downloaded\n",
    "    assert os.path.isfile(os.path.join(path_dict[\"RAW_DATA_PATH\"], \"Task05_Prostate.zip\")) # check whether the file is correctly downloaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qZ6MpBLNYmk2"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    # only for in person workshops\n",
    "\n",
    "    # unzip the files in the folder\n",
    "    os.chdir(path_dict[\"RAW_DATA_PATH\"])\n",
    "    !unzip Task04_Hippocampus.zip\n",
    "    !unzip Task05_Prostate.zip\n",
    "    os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Verification of data\n",
    "Here we test, wether the data is saved in the correct folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rcALoM7JYmk4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data should be located in folder: /media/arvid/ssd1tb/prj/nnUNet/nnUNet_raw_data_base/nnUNet_raw_data\n"
     ]
    }
   ],
   "source": [
    "if colab:\n",
    "    print(\"Data should be located in folder: {}\".format(path_dict[\"RAW_DATA_PATH\"]))\n",
    "    assert os.path.exists(os.path.join(path_dict[\"RAW_DATA_PATH\"], \"Task04_Hippocampus\")) # check whether the file is correctly downloaded\n",
    "    assert os.path.exists(os.path.join(path_dict[\"RAW_DATA_PATH\"], \"Task05_Prostate\")) # check whether the file is correctly downloaded\n",
    "else:\n",
    "    RAW_DATA_PATH = f\"{os.environ['nnUNet_raw_data_base']}/nnUNet_raw_data\"\n",
    "    print(\"Data should be located in folder: {}\".format(RAW_DATA_PATH))\n",
    "\n",
    "    assert os.path.exists(os.path.join(RAW_DATA_PATH, \"Task04_Hippocampus\")) # check whether the file is correctly downloaded\n",
    "    assert os.path.exists(os.path.join(RAW_DATA_PATH, \"Task05_Prostate\")) # check whether the file is correctly downloaded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEloIMv_qba4"
   },
   "source": [
    "## 6.2 Training nnU-Net on the Decathlon Task004 Hippocampus\n",
    "For this we will use already pre-existing scripts for handling the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Dataset Conversion\n",
    "The Decathlon datasets are 4D nifti files, for nnU-Net they have to be converted to 3D nifti files.\n",
    "\n",
    "For more information about dataset conversion see: [nnU-Net Dataset Conversion](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/dataset_conversion.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: /media/arvid/ssd1tb/prj/nnUNet/nnUNet_raw_data_base/nnUNet_raw_data/Task04_Hippocampus\n"
     ]
    }
   ],
   "source": [
    "task = f\"{RAW_DATA_PATH}/Task04_Hippocampus\"\n",
    "print(f\"task: {task}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "usage: nnUNet_convert_decathlon_task [-h] -i I [-p P]\n",
      "                                     [-output_task_id OUTPUT_TASK_ID]\n",
      "\n",
      "The MSD provides data as 4D Niftis with the modality being the first\n",
      "dimension. We think this may be cumbersome for some users and therefore expect\n",
      "3D niftixs instead, with one file per modality. This utility will convert 4D\n",
      "MSD data into the format nnU-Net expects\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -i I                  Input folder. Must point to a TaskXX_TASKNAME folder\n",
      "                        as downloaded from the MSD website\n",
      "  -p P                  Use this to specify how many processes are used to run\n",
      "                        the script. Default is 8\n",
      "  -output_task_id OUTPUT_TASK_ID\n",
      "                        If specified, this will overwrite the task id in the\n",
      "                        output folder. If unspecified, the task id of the\n",
      "                        input folder will be used.\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_convert_decathlon_task -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30089,
     "status": "ok",
     "timestamp": 1643125184634,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "LPjnXq4DPtzr",
    "outputId": "9b9b5d3e-c634-455d-a262-2f8d5de837fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash -s $task\n",
    "\n",
    "nnUNet_convert_decathlon_task -i $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.2 Extracting Rule Based Parameters\n",
    "This will preprocess the dataset to allow fast training and saves it into the \"nnUNet_preprocessed\" folder.\n",
    "Further rule based parameters will be extracted in the planning step.\n",
    "\n",
    "\n",
    "From https://stackoverflow.com/questions/43288550/iopub-data-rate-exceeded-in-jupyter-notebook-when-viewing-image<br>\n",
    "If you get the warning message:\n",
    "\n",
    "```\n",
    "IOPub message rate exceeded.\n",
    "The notebook server will temporarily stop sending output\n",
    "to the client in order to avoid crashing it.\n",
    "\n",
    "\n",
    "Current values:\n",
    "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
    "```\n",
    "try:\n",
    "```\n",
    "yourTerminal:prompt> jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 142590,
     "status": "ok",
     "timestamp": 1643125389006,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "O5gf6khI10WL",
    "outputId": "72ec90ba-9638-4459-8c26-d212f944e922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "hippocampus_150\n",
      "hippocampus_050\n",
      "hippocampus_105\n",
      "hippocampus_178\n",
      "hippocampus_166\n",
      "hippocampus_017\n",
      "hippocampus_109\n",
      "hippocampus_074\n",
      "hippocampus_174\n",
      "hippocampus_084\n",
      "hippocampus_233\n",
      "hippocampus_184\n",
      "hippocampus_333\n",
      "hippocampus_250\n",
      "hippocampus_350\n",
      "hippocampus_378\n",
      "hippocampus_205\n",
      "hippocampus_305\n",
      "hippocampus_149\n",
      "hippocampus_057\n",
      "hippocampus_157\n",
      "hippocampus_102\n",
      "hippocampus_161\n",
      "hippocampus_173\n",
      "hippocampus_370\n",
      "hippocampus_301\n",
      "hippocampus_180\n",
      "hippocampus_189\n",
      "hippocampus_243\n",
      "hippocampus_343\n",
      "hippocampus_220\n",
      "hippocampus_097\n",
      "hippocampus_320\n",
      "hippocampus_197\n",
      "hippocampus_351\n",
      "hippocampus_251\n",
      "hippocampus_245\n",
      "hippocampus_345\n",
      "hippocampus_238\n",
      "hippocampus_338\n",
      "hippocampus_349\n",
      "hippocampus_249\n",
      "hippocampus_334\n",
      "hippocampus_083\n",
      "hippocampus_234\n",
      "hippocampus_006\n",
      "hippocampus_106\n",
      "hippocampus_065\n",
      "hippocampus_165\n",
      "hippocampus_287\n",
      "hippocampus_130\n",
      "hippocampus_387\n",
      "hippocampus_053\n",
      "hippocampus_299\n",
      "hippocampus_155\n",
      "hippocampus_036\n",
      "hippocampus_136\n",
      "hippocampus_381\n",
      "hippocampus_393\n",
      "hippocampus_124\n",
      "hippocampus_024\n",
      "hippocampus_171\n",
      "hippocampus_163\n",
      "hippocampus_099\n",
      "hippocampus_353\n",
      "hippocampus_253\n",
      "hippocampus_222\n",
      "hippocampus_095\n",
      "hippocampus_322\n",
      "hippocampus_195\n",
      "hippocampus_341\n",
      "hippocampus_070\n",
      "hippocampus_051\n",
      "hippocampus_132\n",
      "hippocampus_385\n",
      "hippocampus_260\n",
      "hippocampus_360\n",
      "hippocampus_203\n",
      "hippocampus_303\n",
      "hippocampus_372\n",
      "hippocampus_311\n",
      "hippocampus_367\n",
      "hippocampus_304\n",
      "hippocampus_204\n",
      "hippocampus_279\n",
      "hippocampus_308\n",
      "hippocampus_375\n",
      "hippocampus_216\n",
      "hippocampus_316\n",
      "hippocampus_089\n",
      "hippocampus_294\n",
      "hippocampus_023\n",
      "hippocampus_394\n",
      "hippocampus_123\n",
      "hippocampus_176\n",
      "hippocampus_015\n",
      "hippocampus_068\n",
      "hippocampus_019\n",
      "hippocampus_164\n",
      "hippocampus_158\n",
      "hippocampus_292\n",
      "hippocampus_025\n",
      "hippocampus_125\n",
      "hippocampus_046\n",
      "hippocampus_146\n",
      "hippocampus_226\n",
      "hippocampus_091\n",
      "hippocampus_326\n",
      "hippocampus_228\n",
      "hippocampus_181\n",
      "hippocampus_336\n",
      "hippocampus_236\n",
      "hippocampus_259\n",
      "hippocampus_359\n",
      "hippocampus_224\n",
      "hippocampus_093\n",
      "hippocampus_193\n",
      "hippocampus_044\n",
      "hippocampus_144\n",
      "hippocampus_039\n",
      "hippocampus_290\n",
      "hippocampus_390\n",
      "hippocampus_127\n",
      "hippocampus_156\n",
      "hippocampus_056\n",
      "hippocampus_148\n",
      "hippocampus_268\n",
      "hippocampus_215\n",
      "hippocampus_264\n",
      "hippocampus_219\n",
      "hippocampus_319\n",
      "hippocampus_207\n",
      "hippocampus_067\n",
      "hippocampus_004\n",
      "hippocampus_104\n",
      "hippocampus_185\n",
      "hippocampus_332\n",
      "hippocampus_232\n",
      "hippocampus_298\n",
      "hippocampus_152\n",
      "hippocampus_052\n",
      "hippocampus_386\n",
      "hippocampus_286\n",
      "hippocampus_040\n",
      "hippocampus_257\n",
      "hippocampus_302\n",
      "hippocampus_361\n",
      "hippocampus_261\n",
      "hippocampus_210\n",
      "hippocampus_310\n",
      "hippocampus_373\n",
      "hippocampus_355\n",
      "hippocampus_328\n",
      "hippocampus_295\n",
      "hippocampus_141\n",
      "hippocampus_041\n",
      "hippocampus_321\n",
      "hippocampus_221\n",
      "hippocampus_096\n",
      "hippocampus_242\n",
      "hippocampus_188\n",
      "hippocampus_088\n",
      "hippocampus_366\n",
      "hippocampus_317\n",
      "hippocampus_217\n",
      "hippocampus_374\n",
      "hippocampus_274\n",
      "hippocampus_309\n",
      "hippocampus_252\n",
      "hippocampus_352\n",
      "hippocampus_098\n",
      "hippocampus_244\n",
      "hippocampus_327\n",
      "hippocampus_190\n",
      "hippocampus_227\n",
      "hippocampus_090\n",
      "hippocampus_356\n",
      "hippocampus_235\n",
      "hippocampus_335\n",
      "hippocampus_248\n",
      "hippocampus_170\n",
      "hippocampus_101\n",
      "hippocampus_001\n",
      "hippocampus_162\n",
      "hippocampus_380\n",
      "hippocampus_037\n",
      "hippocampus_280\n",
      "hippocampus_154\n",
      "hippocampus_058\n",
      "hippocampus_048\n",
      "hippocampus_135\n",
      "hippocampus_035\n",
      "hippocampus_282\n",
      "hippocampus_169\n",
      "hippocampus_114\n",
      "hippocampus_014\n",
      "hippocampus_177\n",
      "hippocampus_077\n",
      "hippocampus_126\n",
      "hippocampus_026\n",
      "hippocampus_138\n",
      "hippocampus_038\n",
      "hippocampus_145\n",
      "hippocampus_045\n",
      "hippocampus_034\n",
      "hippocampus_383\n",
      "hippocampus_049\n",
      "hippocampus_314\n",
      "hippocampus_269\n",
      "hippocampus_277\n",
      "hippocampus_318\n",
      "hippocampus_265\n",
      "hippocampus_330\n",
      "hippocampus_087\n",
      "hippocampus_230\n",
      "hippocampus_199\n",
      "hippocampus_175\n",
      "hippocampus_075\n",
      "hippocampus_108\n",
      "hippocampus_008\n",
      "hippocampus_143\n",
      "hippocampus_389\n",
      "hippocampus_289\n",
      "hippocampus_297\n",
      "hippocampus_020\n",
      "hippocampus_064\n",
      "hippocampus_107\n",
      "hippocampus_007\n",
      "hippocampus_296\n",
      "hippocampus_288\n",
      "hippocampus_042\n",
      "hippocampus_142\n",
      "hippocampus_133\n",
      "hippocampus_033\n",
      "hippocampus_212\n",
      "hippocampus_363\n",
      "hippocampus_263\n",
      "hippocampus_300\n",
      "hippocampus_160\n",
      "hippocampus_060\n",
      "hippocampus_003\n",
      "hippocampus_172\n",
      "hippocampus_011\n",
      "hippocampus_231\n",
      "hippocampus_331\n",
      "hippocampus_340\n",
      "hippocampus_194\n",
      "hippocampus_223\n",
      "hippocampus_094\n",
      "hippocampus_376\n",
      "hippocampus_276\n",
      "hippocampus_368\n",
      "hippocampus_337\n",
      "hippocampus_229\n",
      "hippocampus_329\n",
      "hippocampus_354\n",
      "hippocampus_325\n",
      "hippocampus_225\n",
      "hippocampus_092\n",
      "hippocampus_358\n",
      "\n",
      "\n",
      "\n",
      " Task004_Hippocampus\n",
      "number of threads:  (8, 8) \n",
      "\n",
      "not using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalization? OrderedDict([(0, False)])\n",
      "the median shape of the dataset is  [36. 50. 35.]\n",
      "the max shape in the dataset is  [47. 59. 43.]\n",
      "the min shape in the dataset is  [24. 40. 31.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [36. 50. 35.]\n",
      "generating configuration for 3d_fullres\n",
      "{0: {'batch_size': 9, 'num_pool_per_axis': [3, 3, 3], 'patch_size': array([40, 56, 40]), 'median_patient_size_in_voxels': array([36, 50, 35]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\n",
      "transpose forward [0, 1, 2]\n",
      "transpose backward [0, 1, 2]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /media/arvid/ssd1tb/prj/nnUNet/nnUNet_raw_data_base/nnUNet_cropped_data/Task004_Hippocampus\n",
      "output_folder: /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 28, 49, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 28, 49, 38)} \n",
      "\n",
      "1 1488\n",
      "2 1654\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_092.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 53, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 53, 34)} \n",
      "\n",
      "1 1762\n",
      "2 1980\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_093.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 50, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 50, 38)} \n",
      "\n",
      "1 2362\n",
      "2 1667\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_094.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 39, 49, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 39, 49, 34)} \n",
      "\n",
      "1 2191\n",
      "2 1594\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_095.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 39, 47, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 39, 47, 34)} \n",
      "\n",
      "1 1890\n",
      "2 1450\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_096.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 48, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 48, 37)} \n",
      "\n",
      "1 1354\n",
      "2 1399\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_097.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 48, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 48, 37)} \n",
      "\n",
      "1 1515\n",
      "2 1375\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_098.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 27, 52, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 27, 52, 33)} \n",
      "\n",
      "1 1252\n",
      "2 1283\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_099.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 52, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 52, 36)} \n",
      "\n",
      "1 1888\n",
      "2 1706\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_101.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 42, 46, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 42, 46, 32)} \n",
      "\n",
      "1 1171\n",
      "2 1363\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_138.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 42, 44, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 42, 44, 33)} \n",
      "\n",
      "1 1235\n",
      "2 1479\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_141.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 41, 43, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 41, 43, 38)} \n",
      "\n",
      "1 1322\n",
      "2 1375\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_142.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 41, 45, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 41, 45, 32)} \n",
      "\n",
      "1 1193\n",
      "2 1204\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_143.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 43, 45, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 43, 45, 34)} \n",
      "\n",
      "1 1227\n",
      "2 1244\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_144.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 53, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 53, 36)} \n",
      "\n",
      "1 2074\n",
      "2 1462\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_145.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 51, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 51, 36)} \n",
      "\n",
      "1 2017\n",
      "2 1505\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_146.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 48, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 48, 34)} \n",
      "\n",
      "1 1689\n",
      "2 1256\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_148.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 49, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 49, 33)} \n",
      "\n",
      "1 1620\n",
      "2 1523\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_149.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 48, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 48, 37)} \n",
      "\n",
      "1 2033\n",
      "2 1638\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_228.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 55, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 55, 36)} \n",
      "\n",
      "1 2289\n",
      "2 1666\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_102.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 39, 53, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 39, 53, 35)} \n",
      "\n",
      "1 2221\n",
      "2 1596\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_104.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 47, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 47, 33)} \n",
      "\n",
      "1 1832\n",
      "2 1328\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_105.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 46, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 46, 34)} \n",
      "\n",
      "1 1712\n",
      "2 1380\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_106.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 55, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 55, 35)} \n",
      "\n",
      "1 1911\n",
      "2 2035\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_107.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 53, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 53, 36)} \n",
      "\n",
      "1 2059\n",
      "2 1881\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_108.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 49, 36)} \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 49, 36)} \n",
      "\n",
      "1 1589\n",
      "2 1630\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_109.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 39, 50, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 39, 50, 38)} \n",
      "\n",
      "1 2459\n",
      "2 1245\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_114.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 53, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 53, 32)} \n",
      "\n",
      "1 1712\n",
      "2 1517\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_123.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 49, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 49, 35)} \n",
      "\n",
      "1 1841\n",
      "2 1272\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_185.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 54, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 54, 37)} \n",
      "\n",
      "1 1446\n",
      "2 1928\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_188.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 30, 53, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 30, 53, 35)} \n",
      "\n",
      "1 1781\n",
      "2 1674\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_189.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 30, 52, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 30, 52, 37)} \n",
      "\n",
      "1 1665\n",
      "2 1644\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_190.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 29, 50, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 29, 50, 33)} \n",
      "\n",
      "1 1351\n",
      "2 1357\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_193.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 30, 50, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 30, 50, 35)} \n",
      "\n",
      "1 1361\n",
      "2 1533\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_194.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 28, 53, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 28, 53, 33)} \n",
      "\n",
      "1 1831\n",
      "2 1830\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_195.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 31, 51, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 31, 51, 38)} \n",
      "\n",
      "1 1784\n",
      "2 1593\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_197.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 26, 52, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 26, 52, 37)} \n",
      "\n",
      "1 1158\n",
      "2 1412\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_199.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 56, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 56, 37)} \n",
      "\n",
      "1 2302\n",
      "2 1685\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_238.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 48, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 48, 35)} \n",
      "\n",
      "1 2135\n",
      "2 1343\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_017.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 41, 47, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 41, 47, 36)} \n",
      "\n",
      "1 1888\n",
      "2 1468\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_019.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 43, 46, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 43, 46, 36)} \n",
      "\n",
      "1 2146\n",
      "2 1465\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_020.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 51, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 51, 35)} \n",
      "\n",
      "1 1748\n",
      "2 1820\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_023.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 52, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 52, 38)} \n",
      "\n",
      "1 2011\n",
      "2 2019\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_024.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 48, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 48, 35)} \n",
      "\n",
      "1 1896\n",
      "2 1430\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_025.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 50, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 50, 36)} \n",
      "\n",
      "1 1863\n",
      "2 1765\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_026.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 48, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 48, 33)} \n",
      "\n",
      "1 1855\n",
      "2 1568\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_033.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 49, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 49, 36)} \n",
      "\n",
      "1 1830\n",
      "2 1545\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_034.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 53, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 53, 35)} \n",
      "\n",
      "1 1539\n",
      "2 2018\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_173.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 55, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 55, 37)} \n",
      "\n",
      "1 1794\n",
      "2 2153\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_174.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 47, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 47, 33)} \n",
      "\n",
      "1 1575\n",
      "2 1164\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_175.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 50, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 50, 35)} \n",
      "\n",
      "1 1791\n",
      "2 1129\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_176.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 44, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 44, 33)} \n",
      "\n",
      "1 1054\n",
      "2 1539\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_177.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 41, 44, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 41, 44, 35)} \n",
      "\n",
      "1 1224\n",
      "2 1490\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_178.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 45, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 45, 37)} \n",
      "\n",
      "1 1397\n",
      "2 1281\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_180.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 49, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 49, 33)} \n",
      "\n",
      "1 1963\n",
      "2 1729\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_181.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 51, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 51, 37)} \n",
      "\n",
      "1 1948\n",
      "2 1657\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_184.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 26, 55, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 26, 55, 37)} \n",
      "\n",
      "1 2060\n",
      "2 1515\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_252.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 51, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 51, 35)} \n",
      "\n",
      "1 1324\n",
      "2 1624\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_001.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 52, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 52, 34)} \n",
      "\n",
      "1 1550\n",
      "2 1803\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_003.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 52, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 52, 36)} \n",
      "\n",
      "1 1832\n",
      "2 1866\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_004.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 52, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 52, 35)} \n",
      "\n",
      "1 2314\n",
      "2 1949\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_006.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 47, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 47, 34)} \n",
      "\n",
      "1 1842\n",
      "2 1530\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_007.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 48, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 48, 36)} \n",
      "\n",
      "1 1725\n",
      "2 1523\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_008.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 31, 50, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 31, 50, 36)} \n",
      "\n",
      "1 1912\n",
      "2 1544\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_011.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 50, 39)} \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 50, 39)} \n",
      "\n",
      "1 2017\n",
      "2 1605\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_014.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 28, 51, 42)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 28, 51, 42)} \n",
      "\n",
      "1 1511\n",
      "2 1308\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_015.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 41, 55, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 41, 55, 35)} \n",
      "\n",
      "1 1606\n",
      "2 1531\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_124.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 39, 42, 43)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 39, 42, 43)} \n",
      "\n",
      "1 1657\n",
      "2 1069\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_125.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 43, 44, 39)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 43, 44, 39)} \n",
      "\n",
      "1 1650\n",
      "2 1495\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_126.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 31, 55, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 31, 55, 38)} \n",
      "\n",
      "1 2094\n",
      "2 1655\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_127.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 49, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 49, 35)} \n",
      "\n",
      "1 1705\n",
      "2 1580\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_130.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 50, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 50, 36)} \n",
      "\n",
      "1 1572\n",
      "2 1679\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_132.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 42, 41, 39)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 42, 41, 39)} \n",
      "\n",
      "1 1899\n",
      "2 1510\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_133.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 49, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 49, 32)} \n",
      "\n",
      "1 1363\n",
      "2 1266\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_135.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 41, 49, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 41, 49, 34)} \n",
      "\n",
      "1 1445\n",
      "2 1368\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_136.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 51, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 51, 34)} \n",
      "\n",
      "1 1437\n",
      "2 1617\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_268.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 47, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 47, 35)} \n",
      "\n",
      "1 1867\n",
      "2 1583\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_035.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 39, 47, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 39, 47, 36)} \n",
      "\n",
      "1 1849\n",
      "2 1660\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_036.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 51, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 51, 34)} \n",
      "\n",
      "1 1578\n",
      "2 1617\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_037.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 51, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 51, 37)} \n",
      "\n",
      "1 1837\n",
      "2 1721\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_038.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 53, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 53, 34)} \n",
      "\n",
      "1 2038\n",
      "2 1620\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_039.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 52, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 52, 36)} \n",
      "\n",
      "1 1906\n",
      "2 1539\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_040.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 51, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 51, 36)} \n",
      "\n",
      "1 1777\n",
      "2 1986\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_041.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 52, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 52, 37)} \n",
      "\n",
      "1 1871\n",
      "2 1976\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_042.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 48, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 48, 38)} \n",
      "\n",
      "1 1692\n",
      "2 1528\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_044.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 49, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 49, 37)} \n",
      "\n",
      "1 1605\n",
      "2 1483\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_150.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 53, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 53, 36)} \n",
      "\n",
      "1 2121\n",
      "2 1873\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_152.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 42, 46, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 42, 46, 35)} \n",
      "\n",
      "1 1599\n",
      "2 1658\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_154.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 53, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 53, 34)} \n",
      "\n",
      "1 2046\n",
      "2 1509\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_155.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 52, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 52, 36)} \n",
      "\n",
      "1 2102\n",
      "2 1498\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_156.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 51, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 51, 36)} \n",
      "\n",
      "1 1444\n",
      "2 1908\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_157.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 52, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 52, 38)} \n",
      "\n",
      "1 1874\n",
      "2 1538\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_158.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 26, 51, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 26, 51, 34)} \n",
      "\n",
      "1 1682\n",
      "2 1464\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_160.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 51, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 51, 35)} \n",
      "\n",
      "1 1775\n",
      "2 1942\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_161.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 39, 50, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 39, 50, 37)} \n",
      "\n",
      "1 1766\n",
      "2 1934\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_287.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 41, 47, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 41, 47, 32)} \n",
      "\n",
      "1 1222\n",
      "2 1826\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_075.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 45, 47, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 45, 47, 35)} \n",
      "\n",
      "1 1984\n",
      "2 1734\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_077.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 52, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 52, 33)} \n",
      "\n",
      "1 1650\n",
      "2 1721\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_083.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 52, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 52, 34)} \n",
      "\n",
      "1 1390\n",
      "2 1760\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_084.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 55, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 55, 35)} \n",
      "\n",
      "1 1933\n",
      "2 1774\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_087.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 52, 40)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 52, 40)} \n",
      "\n",
      "1 2110\n",
      "2 1768\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_088.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 51, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 51, 34)} \n",
      "\n",
      "1 1725\n",
      "2 1961\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_089.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 50, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 50, 37)} \n",
      "\n",
      "1 2044\n",
      "2 1957\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_090.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 29, 51, 36)} \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 29, 51, 36)} \n",
      "\n",
      "1 1389\n",
      "2 1672\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_091.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 51, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 51, 38)} \n",
      "\n",
      "1 1800\n",
      "2 1620\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_162.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 44, 47, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 44, 47, 36)} \n",
      "\n",
      "1 1569\n",
      "2 1934\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_163.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 47, 48, 41)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 47, 48, 41)} \n",
      "\n",
      "1 1700\n",
      "2 2169\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_164.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 29, 49, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 29, 49, 34)} \n",
      "\n",
      "1 1544\n",
      "2 1479\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_165.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 31, 49, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 31, 49, 36)} \n",
      "\n",
      "1 1402\n",
      "2 1625\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_166.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 39, 45, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 39, 45, 36)} \n",
      "\n",
      "1 1363\n",
      "2 1496\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_169.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 48, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 48, 34)} \n",
      "\n",
      "1 1311\n",
      "2 1559\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_170.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 28, 56, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 28, 56, 35)} \n",
      "\n",
      "1 1849\n",
      "2 1825\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_171.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 31, 56, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 31, 56, 34)} \n",
      "\n",
      "1 1981\n",
      "2 1942\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_172.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 50, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 50, 37)} \n",
      "\n",
      "1 1798\n",
      "2 1059\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_298.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 51, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 51, 35)} \n",
      "\n",
      "1 1390\n",
      "2 1383\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_057.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 53, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 53, 34)} \n",
      "\n",
      "1 1334\n",
      "2 1793\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_058.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 31, 52, 39)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 31, 52, 39)} \n",
      "\n",
      "1 1726\n",
      "2 1683\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_060.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 53, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 53, 35)} \n",
      "\n",
      "1 2044\n",
      "2 1616\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_064.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 52, 39)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 52, 39)} \n",
      "\n",
      "1 1730\n",
      "2 1920\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_065.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 41, 42, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 41, 42, 36)} \n",
      "\n",
      "1 1521\n",
      "2 1290\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_067.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 43, 40, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 43, 40, 36)} \n",
      "\n",
      "1 1733\n",
      "2 1267\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_068.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 50, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 50, 37)} \n",
      "\n",
      "1 1895\n",
      "2 1555\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_070.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 42, 47, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 42, 47, 37)} \n",
      "\n",
      "1 1438\n",
      "2 1562\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_074.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 39, 45, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 39, 45, 37)} \n",
      "\n",
      "1 1538\n",
      "2 1292\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_219.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 45, 39)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 45, 39)} \n",
      "\n",
      "1 1850\n",
      "2 1080\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_220.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 48, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 48, 32)} \n",
      "\n",
      "1 1193\n",
      "2 1255\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_221.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 49, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 49, 34)} \n",
      "\n",
      "1 1691\n",
      "2 993\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_222.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 52, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 52, 35)} \n",
      "\n",
      "1 1577\n",
      "2 1925\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_223.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 48, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 48, 37)} \n",
      "\n",
      "1 2033\n",
      "2 1787\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_224.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 26, 53, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 26, 53, 33)} \n",
      "\n",
      "1 1119\n",
      "2 1356\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_225.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 28, 51, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 28, 51, 32)} \n",
      "\n",
      "1 1364\n",
      "2 1182\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_226.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 47, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 47, 36)} \n",
      "\n",
      "1 1979\n",
      "2 1557\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_227.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 46, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 46, 34)} \n",
      "\n",
      "1 1601\n",
      "2 1349\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_321.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 48, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 48, 36)} \n",
      "\n",
      "1 1246\n",
      "2 1622\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_045.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 49, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 49, 36)} \n",
      "\n",
      "1 1611\n",
      "2 1681\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_046.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 29, 52, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 29, 52, 38)} \n",
      "\n",
      "1 1957\n",
      "2 1315\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_048.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 51, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 51, 35)} \n",
      "\n",
      "1 1908\n",
      "2 1820\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_049.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 49, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 49, 38)} \n",
      "\n",
      "1 2023\n",
      "2 1808\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_050.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 39, 54, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 39, 54, 33)} \n",
      "\n",
      "1 1521\n",
      "2 1588\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_051.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 52, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 52, 34)} \n",
      "\n",
      "1 1847\n",
      "2 1514\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_052.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 51, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 51, 37)} \n",
      "\n",
      "1 1650\n",
      "2 1869\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_053.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 42, 47, 41)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 42, 47, 41)} \n",
      "\n",
      "1 1965\n",
      "2 1768\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_056.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 49, 34)} \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 49, 34)} \n",
      "\n",
      "1 1526\n",
      "2 1301\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_203.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 39, 48, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 39, 48, 36)} \n",
      "\n",
      "1 1642\n",
      "2 1231\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_204.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 47, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 47, 32)} \n",
      "\n",
      "1 1314\n",
      "2 1390\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_205.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 53, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 53, 35)} \n",
      "\n",
      "1 1987\n",
      "2 2087\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_207.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 48, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 48, 34)} \n",
      "\n",
      "1 1641\n",
      "2 1354\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_210.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 56, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 56, 35)} \n",
      "\n",
      "1 1746\n",
      "2 1836\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_212.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 49, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 49, 35)} \n",
      "\n",
      "1 1600\n",
      "2 1733\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_215.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 49, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 49, 32)} \n",
      "\n",
      "1 1882\n",
      "2 1560\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_216.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 27, 53, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 27, 53, 38)} \n",
      "\n",
      "1 2020\n",
      "2 1082\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_217.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 52, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 52, 34)} \n",
      "\n",
      "1 1782\n",
      "2 1830\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_309.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 52, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 52, 35)} \n",
      "\n",
      "1 1823\n",
      "2 1950\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_310.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 49, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 49, 37)} \n",
      "\n",
      "1 1565\n",
      "2 1636\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_311.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 53, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 53, 37)} \n",
      "\n",
      "1 1697\n",
      "2 1246\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_314.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 51, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 51, 37)} \n",
      "\n",
      "1 1580\n",
      "2 1515\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_316.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 51, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 51, 33)} \n",
      "\n",
      "1 1656\n",
      "2 1629\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_317.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 51, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 51, 37)} \n",
      "\n",
      "1 2029\n",
      "2 1487\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_318.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 48, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 48, 33)} \n",
      "\n",
      "1 1380\n",
      "2 1042\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_319.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 47, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 47, 33)} \n",
      "\n",
      "1 1054\n",
      "2 1397\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_320.npz\n",
      "{'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 54, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 54, 32)} \n",
      "\n",
      "1 1517\n",
      "2 1685\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_299.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 53, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 53, 34)} \n",
      "\n",
      "1 1846\n",
      "2 1558\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_300.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 50, 31)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 50, 31)} \n",
      "\n",
      "1 1595\n",
      "2 1865\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_301.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 39, 46, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 39, 46, 35)} \n",
      "\n",
      "1 2209\n",
      "2 1647\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_302.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 48, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 48, 35)} \n",
      "\n",
      "1 1758\n",
      "2 1536\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_303.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 48, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 48, 36)} \n",
      "\n",
      "1 2016\n",
      "2 1520\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_304.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 30, 49, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 30, 49, 34)} \n",
      "\n",
      "1 1649\n",
      "2 1380\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_305.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 48, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 48, 38)} \n",
      "\n",
      "1 2011\n",
      "2 1643\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_308.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 29, 55, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 29, 55, 33)} \n",
      "\n",
      "1 1777\n",
      "2 1643\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_383.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 48, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 48, 35)} \n",
      "\n",
      "1 2113\n",
      "2 1284\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_385.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 45, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 45, 37)} \n",
      "\n",
      "1 1959\n",
      "2 1249\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_386.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 51, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 51, 33)} \n",
      "\n",
      "1 1509\n",
      "2 1571\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_387.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 49, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 49, 34)} \n",
      "\n",
      "1 1763\n",
      "2 1184\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_389.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 51, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 51, 38)} \n",
      "\n",
      "1 1886\n",
      "2 1366\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_390.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 31, 51, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 31, 51, 36)} \n",
      "\n",
      "1 1864\n",
      "2 1818\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_393.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 52, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 52, 36)} \n",
      "\n",
      "1 1987\n",
      "2 1827\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_394.npz\n",
      "{'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 47, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 47, 38)} \n",
      "\n",
      "1 1979\n",
      "2 1471\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_322.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 51, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 51, 35)} \n",
      "\n",
      "1 1898\n",
      "2 1936\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_325.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 41, 49, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 41, 49, 36)} \n",
      "\n",
      "1 2135\n",
      "2 1848\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_326.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 27, 54, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 27, 54, 36)} \n",
      "\n",
      "1 2092\n",
      "2 1551\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_327.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 30, 54, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 30, 54, 38)} \n",
      "\n",
      "1 2371\n",
      "2 1586\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_328.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 53, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 53, 34)} \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 1937\n",
      "2 1738\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_329.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 55, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 55, 35)} \n",
      "\n",
      "1 2232\n",
      "2 1765\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_330.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 52, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 52, 35)} \n",
      "\n",
      "1 1561\n",
      "2 1633\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_331.npz\n",
      "{'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 42, 50, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 42, 50, 38)} \n",
      "\n",
      "1 1850\n",
      "2 1995\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_288.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 49, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 49, 35)} \n",
      "\n",
      "1 1282\n",
      "2 1456\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_289.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 49, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 49, 35)} \n",
      "\n",
      "1 1459\n",
      "2 1708\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_290.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 52, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 52, 38)} \n",
      "\n",
      "1 1911\n",
      "2 1568\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_292.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 44, 44, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 44, 44, 35)} \n",
      "\n",
      "1 1746\n",
      "2 1502\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_294.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 53, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 53, 35)} \n",
      "\n",
      "1 1907\n",
      "2 1721\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_295.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 54, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 54, 35)} \n",
      "\n",
      "1 2098\n",
      "2 1820\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_296.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 30, 51, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 30, 51, 34)} \n",
      "\n",
      "1 1551\n",
      "2 1235\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_297.npz\n",
      "{'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 50, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 50, 33)} \n",
      "\n",
      "1 1458\n",
      "2 1719\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_229.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 49, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 49, 34)} \n",
      "\n",
      "1 1556\n",
      "2 1609\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_230.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 42, 47, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 42, 47, 33)} \n",
      "\n",
      "1 1179\n",
      "2 1468\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_231.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 43, 44, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 43, 44, 36)} \n",
      "\n",
      "1 1514\n",
      "2 1349\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_232.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 51, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 51, 33)} \n",
      "\n",
      "1 1593\n",
      "2 1574\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_233.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 49, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 49, 38)} \n",
      "\n",
      "1 1549\n",
      "2 1667\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_234.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 58, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 58, 37)} \n",
      "\n",
      "1 1479\n",
      "2 1561\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_235.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 57, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 57, 37)} \n",
      "\n",
      "1 1595\n",
      "2 1494\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_236.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 52, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 52, 35)} \n",
      "\n",
      "1 1803\n",
      "2 1524\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_332.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 46, 33)} \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 46, 33)} \n",
      "\n",
      "1 1192\n",
      "2 1443\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_333.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 47, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 47, 34)} \n",
      "\n",
      "1 1242\n",
      "2 1436\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_334.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 41, 47, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 41, 47, 32)} \n",
      "\n",
      "1 1263\n",
      "2 1269\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_335.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 43, 47, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 43, 47, 34)} \n",
      "\n",
      "1 1298\n",
      "2 1295\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_336.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 41, 44, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 41, 44, 33)} \n",
      "\n",
      "1 1551\n",
      "2 1702\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_337.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 43, 43, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 43, 43, 37)} \n",
      "\n",
      "1 2007\n",
      "2 1616\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_338.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 46, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 46, 35)} \n",
      "\n",
      "1 1592\n",
      "2 1618\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_340.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 48, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 48, 34)} \n",
      "\n",
      "1 1331\n",
      "2 1257\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_341.npz\n",
      "{'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 49, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 49, 35)} \n",
      "\n",
      "1 1725\n",
      "2 1714\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_269.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 40, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 40, 35)} \n",
      "\n",
      "1 1491\n",
      "2 1174\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_274.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 50, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 50, 35)} \n",
      "\n",
      "1 2056\n",
      "2 1587\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_276.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 29, 59, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 29, 59, 33)} \n",
      "\n",
      "1 1695\n",
      "2 1609\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_277.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 50, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 50, 34)} \n",
      "\n",
      "1 1261\n",
      "2 1121\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_279.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 47, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 47, 37)} \n",
      "\n",
      "1 1367\n",
      "2 1246\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_280.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 52, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 52, 37)} \n",
      "\n",
      "1 1133\n",
      "2 1283\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_282.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 46, 45, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 46, 45, 37)} \n",
      "\n",
      "1 1562\n",
      "2 1610\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_286.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 51, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 51, 36)} \n",
      "\n",
      "1 1863\n",
      "2 1633\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_356.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 50, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 50, 35)} \n",
      "\n",
      "1 1519\n",
      "2 1368\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_358.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 49, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 49, 35)} \n",
      "\n",
      "1 1262\n",
      "2 1372\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_359.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 49, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 49, 34)} \n",
      "\n",
      "1 1298\n",
      "2 1633\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_360.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 50, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 50, 36)} \n",
      "\n",
      "1 1733\n",
      "2 1372\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_361.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 52, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 52, 38)} \n",
      "\n",
      "1 1838\n",
      "2 1668\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_363.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 47, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 47, 37)} \n",
      "\n",
      "1 2482\n",
      "2 1497\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_366.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 57, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 57, 36)} \n",
      "\n",
      "1 2212\n",
      "2 1939\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_367.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 55, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 55, 38)} \n",
      "\n",
      "1 2593\n",
      "2 1808\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_368.npz\n",
      "{'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 31, 51, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 31, 51, 34)} \n",
      "\n",
      "1 2343\n",
      "2 1480\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_253.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 51, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 51, 34)} \n",
      "\n",
      "1 1188\n",
      "2 1675\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_257.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 28, 51, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 28, 51, 33)} \n",
      "\n",
      "1 1338\n",
      "2 1582\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_259.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 29, 53, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 29, 53, 35)} \n",
      "\n",
      "1 1379\n",
      "2 1718\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_260.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 58, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 58, 36)} \n",
      "\n",
      "1 2399\n",
      "2 1672\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_261.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 51, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 51, 36)} \n",
      "\n",
      "1 1647\n",
      "2 1887\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_263.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 51, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 51, 38)} \n",
      "\n",
      "1 1934\n",
      "2 1908\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_264.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 54, 31)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 54, 31)} \n",
      "\n",
      "1 1455\n",
      "2 1654\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_265.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 45, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 45, 32)} \n",
      "\n",
      "1 1067\n",
      "2 1551\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_343.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 30, 49, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 30, 49, 32)} \n",
      "\n",
      "1 1685\n",
      "2 1295\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_345.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 50, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 50, 34)} \n",
      "\n",
      "1 1217\n",
      "2 1373\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_349.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 49, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 49, 35)} \n",
      "\n",
      "1 1475\n",
      "2 1467\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_350.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 51, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 51, 35)} \n",
      "\n",
      "1 1822\n",
      "2 1902\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_351.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 51, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 51, 38)} \n",
      "\n",
      "1 1966\n",
      "2 1713\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_352.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 31, 51, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 31, 51, 32)} \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 1415\n",
      "2 1340\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_353.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 50, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 50, 36)} \n",
      "\n",
      "1 1529\n",
      "2 1383\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_354.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 47, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 47, 33)} \n",
      "\n",
      "1 1819\n",
      "2 1516\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_355.npz\n",
      "{'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 52, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 52, 38)} \n",
      "\n",
      "1 2477\n",
      "2 1906\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_242.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 24, 53, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 24, 53, 34)} \n",
      "\n",
      "1 1421\n",
      "2 1535\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_243.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 30, 53, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 30, 53, 38)} \n",
      "\n",
      "1 1697\n",
      "2 1511\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_244.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 42, 48, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 42, 48, 35)} \n",
      "\n",
      "1 1630\n",
      "2 1695\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_245.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 50, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 50, 36)} \n",
      "\n",
      "1 1887\n",
      "2 1551\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_248.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 52, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 52, 32)} \n",
      "\n",
      "1 1784\n",
      "2 1565\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_249.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 51, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 51, 35)} \n",
      "\n",
      "1 1899\n",
      "2 1532\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_250.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 28, 58, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 28, 58, 36)} \n",
      "\n",
      "1 2221\n",
      "2 1354\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_251.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 50, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 50, 35)} \n",
      "\n",
      "1 1597\n",
      "2 1801\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_370.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 50, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 50, 36)} \n",
      "\n",
      "1 1751\n",
      "2 1732\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_372.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 49, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 49, 34)} \n",
      "\n",
      "1 1882\n",
      "2 1807\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_373.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 39, 48, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 39, 48, 38)} \n",
      "\n",
      "1 2123\n",
      "2 1754\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_374.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 54, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 54, 32)} \n",
      "\n",
      "1 1686\n",
      "2 1536\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_375.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 55, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 55, 35)} \n",
      "\n",
      "1 1625\n",
      "2 1956\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_376.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 52, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 52, 35)} \n",
      "\n",
      "1 1180\n",
      "2 1577\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_378.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 42, 46, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 42, 46, 35)} \n",
      "\n",
      "1 1730\n",
      "2 1705\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_380.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 49, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 49, 33)} \n",
      "\n",
      "1 1550\n",
      "2 1602\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_stage0/hippocampus_381.npz\n",
      "not using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalization? OrderedDict([(0, False)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the median shape of the dataset is  [36. 50. 35.]\n",
      "the max shape in the dataset is  [47. 59. 43.]\n",
      "the min shape in the dataset is  [24. 40. 31.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [36. 50. 35.]\n",
      "[{'batch_size': 366, 'num_pool_per_axis': [3, 3], 'patch_size': array([56, 40]), 'median_patient_size_in_voxels': array([36, 50, 35]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /media/arvid/ssd1tb/prj/nnUNet/nnUNet_raw_data_base/nnUNet_cropped_data/Task004_Hippocampus\n",
      "output_folder: /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 48, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 48, 36)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1246\n",
      "2 1622\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_045.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 49, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 49, 36)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1611\n",
      "2 1681\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_046.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 29, 52, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 29, 52, 38)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1957\n",
      "2 1315\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_048.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 51, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 51, 35)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1908\n",
      "2 1820\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_049.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 49, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 49, 38)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2023\n",
      "2 1808\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_050.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 39, 54, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 39, 54, 33)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1521\n",
      "2 1588\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_051.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 52, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 52, 34)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1847\n",
      "2 1514\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_052.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 51, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 51, 37)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1650\n",
      "2 1869\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_053.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 42, 47, 41)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 42, 47, 41)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1965\n",
      "2 1768\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_056.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 42, 46, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 42, 46, 32)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1171\n",
      "2 1363\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_138.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 42, 44, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 42, 44, 33)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1235\n",
      "2 1479\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_141.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 41, 43, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 41, 43, 38)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1322\n",
      "2 1375\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_142.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 41, 45, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 41, 45, 32)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1193\n",
      "2 1204\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_143.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 43, 45, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 43, 45, 34)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1227\n",
      "2 1244\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_144.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 53, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 33, 53, 36)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2074\n",
      "2 1462\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_145.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 51, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 51, 36)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2017\n",
      "2 1505\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_146.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 48, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 48, 34)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1689\n",
      "2 1256\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_148.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 49, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 49, 33)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1620\n",
      "2 1523\n",
      "saving:  no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 41, 47, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 41, 47, 32)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1222\n",
      "2 1826\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_075.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 45, 47, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 45, 47, 35)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1984\n",
      "2 1734\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_077.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 52, 33)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 52, 33)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1650\n",
      "2 1721\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_083.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 52, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 52, 34)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1390\n",
      "2 1760\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_084.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 55, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 55, 35)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1933\n",
      "2 1774\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_087.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 52, 40)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 52, 40)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2110\n",
      "2 1768\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_088.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 51, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 51, 34)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1725\n",
      "2 1961\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_089.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 50, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 50, 37)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2044\n",
      "2 1957\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_090.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 29, 51, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 29, 51, 36)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1389\n",
      "2 1672\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_091.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 49, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 49, 37)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1605\n",
      "2 1483\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_150.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 53, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 53, 36)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2121\n",
      "2 1873\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_152.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 42, 46, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 42, 46, 35)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1599\n",
      "2 1658\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_154.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 53, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 53, 34)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2046\n",
      "2 1509\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_155.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 52, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 52, 36)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2102\n",
      "2 1498\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_156.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 51, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 51, 36)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1444\n",
      "2 1908\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_157.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 52, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 52, 38)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1874\n",
      "2 1538\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_158.npz\n",
      "no resampling necessary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 26, 51, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 26, 51, 34)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1682\n",
      "2 1464\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_160.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 36, 51, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 36, 51, 35)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1775\n",
      "2 1942\n",
      "saving:  no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 51, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 51, 35)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1324\n",
      "2 1624\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_001.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 52, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 52, 34)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1550\n",
      "2 1803\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_003.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 52, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 52, 36)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1832\n",
      "2 1866\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_004.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 52, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 52, 35)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2314\n",
      "2 1949\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_006.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 47, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 47, 34)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1842\n",
      "2 1530\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_007.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 48, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 48, 36)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1725\n",
      "2 1523\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_008.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 31, 50, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 31, 50, 36)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1912\n",
      "2 1544\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_011.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 50, 39)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 50, 39)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2017\n",
      "2 1605\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_014.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 28, 51, 42)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 28, 51, 42)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1511\n",
      "2 1308\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_015.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 41, 55, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 41, 55, 35)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1606\n",
      "2 1531\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_124.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 39, 42, 43)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 39, 42, 43)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1657\n",
      "2 1069\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_125.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 43, 44, 39)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 43, 44, 39)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1650\n",
      "2 1495\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_126.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 31, 55, 38)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 31, 55, 38)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2094\n",
      "2 1655\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_127.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 49, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 49, 35)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1705\n",
      "2 1580\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_130.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 40, 50, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 40, 50, 36)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1572\n",
      "2 1679\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_132.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 42, 41, 39)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 42, 41, 39)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1899\n",
      "2 1510\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_133.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 38, 49, 32)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 38, 49, 32)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1363\n",
      "2 1266\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_135.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 41, 49, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 41, 49, 34)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1445\n",
      "2 1368\n",
      "saving:  no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 47, 35)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 47, 35)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1867\n",
      "2 1583\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_035.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 39, 47, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 39, 47, 36)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1849\n",
      "2 1660\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_036.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 32, 51, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 32, 51, 34)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1578\n",
      "2 1617\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_037.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 35, 51, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 35, 51, 37)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1837\n",
      "2 1721\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_038.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 53, 34)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 53, 34)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 2038\n",
      "2 1620\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_039.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 37, 52, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 37, 52, 36)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1906\n",
      "2 1539\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_040.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 51, 36)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 51, 36)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1777\n",
      "2 1986\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_041.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 34, 52, 37)} \n",
      "after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 34, 52, 37)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1871\n",
      "2 1976\n",
      "saving:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1_2D_stage0/hippocampus_042.npz\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 33, 48, 38)} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Prepare the Execution of nnU-Net for Task 4 - this is the Hippocampus Dataset here (taking 1-2 minutes)\n",
    "nnUNet_plan_and_preprocess -t 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Training nnU-Net\n",
    "here we will train a 3D nnU-Net on Full Resolution for 2 epochs.\n",
    "\n",
    "To run a normal training use: ```nnUNetTrainerV2``` instead of ```nnUNetTrainerV2_2epochs```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 476973,
     "status": "ok",
     "timestamp": 1643126067709,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "WSU2kFfh5GKP",
    "outputId": "0a00d105-2174-4f07-f5c8-fff233413348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.benchmarking.nnUNetTrainerV2_2epochs.nnUNetTrainerV2_2epochs'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  2\n",
      "modalities:  {0: 'MRI'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 9, 'num_pool_per_axis': [3, 3, 3], 'patch_size': array([40, 56, 40]), 'median_patient_size_in_voxels': array([36, 50, 35]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2022-11-27 18:15:56.514681: Creating new 5-fold cross-validation split...\n",
      "2022-11-27 18:15:56.515431: Desired fold for training: 0\n",
      "2022-11-27 18:15:56.515484: This split has 208 training and 52 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2022-11-27 18:15:57.854055: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2022-11-27 18:16:00.792737: Unable to plot network architecture:\n",
      "2022-11-27 18:16:00.793375: module 'torch.onnx' has no attribute '_optimize_trace'\n",
      "2022-11-27 18:16:00.793486: \n",
      "printing the network instead:\n",
      "\n",
      "2022-11-27 18:16:00.793574: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (1): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(128, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2022-11-27 18:16:00.796594: \n",
      "\n",
      "2022-11-27 18:16:00.812403: \n",
      "epoch:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 18:16:16.847933: train loss : -0.3256\n",
      "2022-11-27 18:16:17.846839: validation loss: -0.7603\n",
      "2022-11-27 18:16:17.847240: Average global foreground Dice: [0.8304, 0.8261]\n",
      "2022-11-27 18:16:17.847411: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:16:18.148060: lr: 0.005359\n",
      "2022-11-27 18:16:18.148168: This epoch took 17.335112 s\n",
      "\n",
      "2022-11-27 18:16:18.148202: \n",
      "epoch:  1\n",
      "2022-11-27 18:16:31.962916: train loss : -0.7655\n",
      "2022-11-27 18:16:32.949237: validation loss: -0.8072\n",
      "2022-11-27 18:16:32.949570: Average global foreground Dice: [0.8646, 0.8518]\n",
      "2022-11-27 18:16:32.949633: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:16:33.287308: lr: 0.0\n",
      "2022-11-27 18:16:33.287433: This epoch took 15.139205 s\n",
      "\n",
      "CPU times: user 822 ms, sys: 164 ms, total: 987 ms\n",
      "Wall time: 39.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train the 3d nnUnet on the Full Resolution with Task 4 and Cross Validation Split 0\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_2epochs 4 0\n",
    "\n",
    "# training the Full Model will take quite a while - therefore it is advised to interrupt the training after some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNet_variants.benchmarking.nnUNetTrainerV2_2epochs.nnUNetTrainerV2_2epochs'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  2\n",
      "modalities:  {0: 'MRI'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 9, 'num_pool_per_axis': [3, 3, 3], 'patch_size': array([40, 56, 40]), 'median_patient_size_in_voxels': array([36, 50, 35]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2022-11-27 18:17:02.470145: Using splits from existing split file: /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/splits_final.pkl\n",
      "2022-11-27 18:17:02.470346: The split file contains 5 splits.\n",
      "2022-11-27 18:17:02.470395: Desired fold for training: 5\n",
      "2022-11-27 18:17:02.470417: INFO: You requested fold 5 for training but splits contain only 5 folds. I am now creating a random (but seeded) 80:20 split!\n",
      "2022-11-27 18:17:02.471361: This random 80:20 split has 208 training and 52 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2022-11-27 18:17:03.706695: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2022-11-27 18:17:06.782837: Unable to plot network architecture:\n",
      "2022-11-27 18:17:06.783139: module 'torch.onnx' has no attribute '_optimize_trace'\n",
      "2022-11-27 18:17:06.783187: \n",
      "printing the network instead:\n",
      "\n",
      "2022-11-27 18:17:06.783219: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (1): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(128, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2022-11-27 18:17:06.784450: \n",
      "\n",
      "2022-11-27 18:17:06.799056: \n",
      "epoch:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 18:17:22.692904: train loss : -0.3435\n",
      "2022-11-27 18:17:23.655557: validation loss: -0.7734\n",
      "2022-11-27 18:17:23.655916: Average global foreground Dice: [0.8352, 0.8282]\n",
      "2022-11-27 18:17:23.655993: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:17:23.950674: lr: 0.005359\n",
      "2022-11-27 18:17:23.950794: This epoch took 17.151290 s\n",
      "\n",
      "2022-11-27 18:17:23.950829: \n",
      "epoch:  1\n",
      "2022-11-27 18:17:37.816166: train loss : -0.7672\n",
      "2022-11-27 18:17:38.787227: validation loss: -0.8030\n",
      "2022-11-27 18:17:38.787559: Average global foreground Dice: [0.859, 0.8438]\n",
      "2022-11-27 18:17:38.787620: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:17:39.155139: lr: 0.0\n",
      "2022-11-27 18:17:39.155268: This epoch took 15.204412 s\n",
      "\n",
      "CPU times: user 799 ms, sys: 129 ms, total: 928 ms\n",
      "Wall time: 39.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train the 3d nnUnet on the Full Resolution with Task 4 and Cross Validation Split 5\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2_2epochs 4 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  2\n",
      "modalities:  {0: 'MRI'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 9, 'num_pool_per_axis': [3, 3, 3], 'patch_size': array([40, 56, 40]), 'median_patient_size_in_voxels': array([36, 50, 35]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2022-11-27 18:21:46.771323: Using splits from existing split file: /media/arvid/ssd1tb/prj/nnUNet/nnUNet_preprocessed/Task004_Hippocampus/splits_final.pkl\n",
      "2022-11-27 18:21:46.771554: The split file contains 5 splits.\n",
      "2022-11-27 18:21:46.771590: Desired fold for training: 5\n",
      "2022-11-27 18:21:46.771612: INFO: You requested fold 5 for training but splits contain only 5 folds. I am now creating a random (but seeded) 80:20 split!\n",
      "2022-11-27 18:21:46.772546: This random 80:20 split has 208 training and 52 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2022-11-27 18:21:47.983305: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2022-11-27 18:21:51.166957: Unable to plot network architecture:\n",
      "2022-11-27 18:21:51.167467: module 'torch.onnx' has no attribute '_optimize_trace'\n",
      "2022-11-27 18:21:51.167562: \n",
      "printing the network instead:\n",
      "\n",
      "2022-11-27 18:21:51.167632: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (1): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(128, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2022-11-27 18:21:51.169440: \n",
      "\n",
      "2022-11-27 18:21:51.181413: \n",
      "epoch:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 18:22:07.288141: train loss : -0.3374\n",
      "2022-11-27 18:22:08.296944: validation loss: -0.7432\n",
      "2022-11-27 18:22:08.297430: Average global foreground Dice: [0.8286, 0.8181]\n",
      "2022-11-27 18:22:08.297539: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:22:08.593130: lr: 0.009991\n",
      "2022-11-27 18:22:08.593246: This epoch took 17.411450 s\n",
      "\n",
      "2022-11-27 18:22:08.593287: \n",
      "epoch:  1\n",
      "2022-11-27 18:22:22.225094: train loss : -0.7709\n",
      "2022-11-27 18:22:23.227793: validation loss: -0.8064\n",
      "2022-11-27 18:22:23.228387: Average global foreground Dice: [0.8658, 0.8451]\n",
      "2022-11-27 18:22:23.228457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:22:23.571707: lr: 0.009982\n",
      "2022-11-27 18:22:23.575788: saving checkpoint...\n",
      "2022-11-27 18:22:23.615697: done, saving took 0.04 seconds\n",
      "2022-11-27 18:22:23.617497: This epoch took 15.024061 s\n",
      "\n",
      "2022-11-27 18:22:23.617559: \n",
      "epoch:  2\n",
      "2022-11-27 18:22:37.370542: train loss : -0.7971\n",
      "2022-11-27 18:22:38.348503: validation loss: -0.8242\n",
      "2022-11-27 18:22:38.348897: Average global foreground Dice: [0.8762, 0.8601]\n",
      "2022-11-27 18:22:38.348986: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:22:38.693780: lr: 0.009973\n",
      "2022-11-27 18:22:38.697824: saving checkpoint...\n",
      "2022-11-27 18:22:38.753269: done, saving took 0.06 seconds\n",
      "2022-11-27 18:22:38.758373: This epoch took 15.140778 s\n",
      "\n",
      "2022-11-27 18:22:38.758530: \n",
      "epoch:  3\n",
      "2022-11-27 18:22:52.629729: train loss : -0.8122\n",
      "2022-11-27 18:22:53.612446: validation loss: -0.8300\n",
      "2022-11-27 18:22:53.612813: Average global foreground Dice: [0.8821, 0.8648]\n",
      "2022-11-27 18:22:53.612868: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:22:54.042250: lr: 0.009964\n",
      "2022-11-27 18:22:54.046234: saving checkpoint...\n",
      "2022-11-27 18:22:54.100904: done, saving took 0.06 seconds\n",
      "2022-11-27 18:22:54.102754: This epoch took 15.344129 s\n",
      "\n",
      "2022-11-27 18:22:54.102818: \n",
      "epoch:  4\n",
      "2022-11-27 18:23:08.005437: train loss : -0.8187\n",
      "2022-11-27 18:23:08.990935: validation loss: -0.8302\n",
      "2022-11-27 18:23:08.991302: Average global foreground Dice: [0.8802, 0.8645]\n",
      "2022-11-27 18:23:08.991360: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:23:09.324371: lr: 0.009955\n",
      "2022-11-27 18:23:09.328439: saving checkpoint...\n",
      "2022-11-27 18:23:09.384671: done, saving took 0.06 seconds\n",
      "2022-11-27 18:23:09.386458: This epoch took 15.283583 s\n",
      "\n",
      "2022-11-27 18:23:09.386526: \n",
      "epoch:  5\n",
      "2022-11-27 18:23:23.555274: train loss : -0.8249\n",
      "2022-11-27 18:23:24.568691: validation loss: -0.8316\n",
      "2022-11-27 18:23:24.569069: Average global foreground Dice: [0.8815, 0.8658]\n",
      "2022-11-27 18:23:24.569126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:23:24.904403: lr: 0.009946\n",
      "2022-11-27 18:23:24.908479: saving checkpoint...\n",
      "2022-11-27 18:23:24.964844: done, saving took 0.06 seconds\n",
      "2022-11-27 18:23:24.966648: This epoch took 15.580090 s\n",
      "\n",
      "2022-11-27 18:23:24.966705: \n",
      "epoch:  6\n",
      "2022-11-27 18:23:39.105755: train loss : -0.8322\n",
      "2022-11-27 18:23:40.116231: validation loss: -0.8390\n",
      "2022-11-27 18:23:40.116759: Average global foreground Dice: [0.8862, 0.8724]\n",
      "2022-11-27 18:23:40.117083: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:23:40.483778: lr: 0.009937\n",
      "2022-11-27 18:23:40.487839: saving checkpoint...\n",
      "2022-11-27 18:23:40.545307: done, saving took 0.06 seconds\n",
      "2022-11-27 18:23:40.549454: This epoch took 15.582715 s\n",
      "\n",
      "2022-11-27 18:23:40.549584: \n",
      "epoch:  7\n",
      "2022-11-27 18:23:54.949760: train loss : -0.8359\n",
      "2022-11-27 18:23:55.962489: validation loss: -0.8346\n",
      "2022-11-27 18:23:55.962811: Average global foreground Dice: [0.8854, 0.867]\n",
      "2022-11-27 18:23:55.962867: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:23:56.319902: lr: 0.009928\n",
      "2022-11-27 18:23:56.323931: saving checkpoint...\n",
      "2022-11-27 18:23:56.384618: done, saving took 0.06 seconds\n",
      "2022-11-27 18:23:56.387078: This epoch took 15.837417 s\n",
      "\n",
      "2022-11-27 18:23:56.387159: \n",
      "epoch:  8\n",
      "2022-11-27 18:24:10.777663: train loss : -0.8367\n",
      "2022-11-27 18:24:11.808072: validation loss: -0.8407\n",
      "2022-11-27 18:24:11.808461: Average global foreground Dice: [0.8886, 0.8719]\n",
      "2022-11-27 18:24:11.808530: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:24:12.146886: lr: 0.009919\n",
      "2022-11-27 18:24:12.150865: saving checkpoint...\n",
      "2022-11-27 18:24:12.206701: done, saving took 0.06 seconds\n",
      "2022-11-27 18:24:12.208524: This epoch took 15.821318 s\n",
      "\n",
      "2022-11-27 18:24:12.208583: \n",
      "epoch:  9\n",
      "2022-11-27 18:24:26.620028: train loss : -0.8394\n",
      "2022-11-27 18:24:27.669177: validation loss: -0.8428\n",
      "2022-11-27 18:24:27.669562: Average global foreground Dice: [0.8921, 0.8737]\n",
      "2022-11-27 18:24:27.669618: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:24:28.001680: lr: 0.00991\n",
      "2022-11-27 18:24:28.005919: saving checkpoint...\n",
      "2022-11-27 18:24:28.061443: done, saving took 0.06 seconds\n",
      "2022-11-27 18:24:28.063222: This epoch took 15.854609 s\n",
      "\n",
      "2022-11-27 18:24:28.063287: \n",
      "epoch:  10\n",
      "2022-11-27 18:24:42.418079: train loss : -0.8440\n",
      "2022-11-27 18:24:43.430486: validation loss: -0.8484\n",
      "2022-11-27 18:24:43.430818: Average global foreground Dice: [0.8954, 0.8773]\n",
      "2022-11-27 18:24:43.430872: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:24:43.776495: lr: 0.009901\n",
      "2022-11-27 18:24:43.780410: saving checkpoint...\n",
      "2022-11-27 18:24:43.836118: done, saving took 0.06 seconds\n",
      "2022-11-27 18:24:43.838094: This epoch took 15.774776 s\n",
      "\n",
      "2022-11-27 18:24:43.838152: \n",
      "epoch:  11\n",
      "2022-11-27 18:24:58.328482: train loss : -0.8458\n",
      "2022-11-27 18:24:59.335397: validation loss: -0.8471\n",
      "2022-11-27 18:24:59.335757: Average global foreground Dice: [0.8933, 0.8762]\n",
      "2022-11-27 18:24:59.335817: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:24:59.689634: lr: 0.009892\n",
      "2022-11-27 18:24:59.693649: saving checkpoint...\n",
      "2022-11-27 18:24:59.751432: done, saving took 0.06 seconds\n",
      "2022-11-27 18:24:59.753195: This epoch took 15.915013 s\n",
      "\n",
      "2022-11-27 18:24:59.753322: \n",
      "epoch:  12\n",
      "2022-11-27 18:25:14.126055: train loss : -0.8452\n",
      "2022-11-27 18:25:15.147288: validation loss: -0.8398\n",
      "2022-11-27 18:25:15.147723: Average global foreground Dice: [0.8873, 0.8714]\n",
      "2022-11-27 18:25:15.147816: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:25:15.495699: lr: 0.009883\n",
      "2022-11-27 18:25:15.499796: saving checkpoint...\n",
      "2022-11-27 18:25:15.555912: done, saving took 0.06 seconds\n",
      "2022-11-27 18:25:15.557711: This epoch took 15.804357 s\n",
      "\n",
      "2022-11-27 18:25:15.557770: \n",
      "epoch:  13\n",
      "2022-11-27 18:25:29.938661: train loss : -0.8480\n",
      "2022-11-27 18:25:30.946527: validation loss: -0.8490\n",
      "2022-11-27 18:25:30.946860: Average global foreground Dice: [0.8959, 0.8781]\n",
      "2022-11-27 18:25:30.946917: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:25:31.292503: lr: 0.009874\n",
      "2022-11-27 18:25:31.296543: saving checkpoint...\n",
      "2022-11-27 18:25:31.355430: done, saving took 0.06 seconds\n",
      "2022-11-27 18:25:31.357161: This epoch took 15.799360 s\n",
      "\n",
      "2022-11-27 18:25:31.357220: \n",
      "epoch:  14\n",
      "2022-11-27 18:25:45.812265: train loss : -0.8492\n",
      "2022-11-27 18:25:46.802643: validation loss: -0.8423\n",
      "2022-11-27 18:25:46.802991: Average global foreground Dice: [0.8898, 0.8713]\n",
      "2022-11-27 18:25:46.803047: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:25:47.259473: lr: 0.009865\n",
      "2022-11-27 18:25:47.263576: saving checkpoint...\n",
      "2022-11-27 18:25:47.321495: done, saving took 0.06 seconds\n",
      "2022-11-27 18:25:47.324068: This epoch took 15.966818 s\n",
      "\n",
      "2022-11-27 18:25:47.324129: \n",
      "epoch:  15\n",
      "2022-11-27 18:26:01.776912: train loss : -0.8533\n",
      "2022-11-27 18:26:02.776596: validation loss: -0.8536\n",
      "2022-11-27 18:26:02.776965: Average global foreground Dice: [0.8976, 0.8821]\n",
      "2022-11-27 18:26:02.777023: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 18:26:03.116805: lr: 0.009856\n",
      "2022-11-27 18:26:03.120856: saving checkpoint...\n",
      "2022-11-27 18:26:03.179607: done, saving took 0.06 seconds\n",
      "2022-11-27 18:26:03.182980: This epoch took 15.858821 s\n",
      "\n",
      "2022-11-27 18:26:03.183051: \n",
      "epoch:  16\n",
      "2022-11-27 18:26:17.620273: train loss : -0.8519\n",
      "2022-11-27 18:26:18.627231: validation loss: -0.8443\n",
      "2022-11-27 18:26:18.627556: Average global foreground Dice: [0.8924, 0.8727]\n",
      "2022-11-27 18:26:18.627614: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:26:18.970357: lr: 0.009847\n",
      "2022-11-27 18:26:18.974536: saving checkpoint...\n",
      "2022-11-27 18:26:19.039243: done, saving took 0.07 seconds\n",
      "2022-11-27 18:26:19.041223: This epoch took 15.858141 s\n",
      "\n",
      "2022-11-27 18:26:19.041281: \n",
      "epoch:  17\n",
      "2022-11-27 18:26:33.435211: train loss : -0.8529\n",
      "2022-11-27 18:26:34.443187: validation loss: -0.8479\n",
      "2022-11-27 18:26:34.443566: Average global foreground Dice: [0.8939, 0.8765]\n",
      "2022-11-27 18:26:34.443641: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:26:34.784676: lr: 0.009838\n",
      "2022-11-27 18:26:34.788840: saving checkpoint...\n",
      "2022-11-27 18:26:34.848068: done, saving took 0.06 seconds\n",
      "2022-11-27 18:26:34.849971: This epoch took 15.808644 s\n",
      "\n",
      "2022-11-27 18:26:34.850033: \n",
      "epoch:  18\n",
      "2022-11-27 18:26:49.360356: train loss : -0.8536\n",
      "2022-11-27 18:26:50.386701: validation loss: -0.8498\n",
      "2022-11-27 18:26:50.387083: Average global foreground Dice: [0.8956, 0.8773]\n",
      "2022-11-27 18:26:50.387141: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:26:50.728536: lr: 0.009829\n",
      "2022-11-27 18:26:50.732724: saving checkpoint...\n",
      "2022-11-27 18:26:50.793074: done, saving took 0.06 seconds\n",
      "2022-11-27 18:26:50.794975: This epoch took 15.944911 s\n",
      "\n",
      "2022-11-27 18:26:50.795030: \n",
      "epoch:  19\n",
      "2022-11-27 18:27:05.211413: train loss : -0.8545\n",
      "2022-11-27 18:27:06.213460: validation loss: -0.8462\n",
      "2022-11-27 18:27:06.213789: Average global foreground Dice: [0.8909, 0.8777]\n",
      "2022-11-27 18:27:06.213844: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:27:06.554432: lr: 0.00982\n",
      "2022-11-27 18:27:06.558371: saving checkpoint...\n",
      "2022-11-27 18:27:06.617277: done, saving took 0.06 seconds\n",
      "2022-11-27 18:27:06.619062: This epoch took 15.824001 s\n",
      "\n",
      "2022-11-27 18:27:06.619119: \n",
      "epoch:  20\n",
      "2022-11-27 18:27:21.048523: train loss : -0.8576\n",
      "2022-11-27 18:27:22.081579: validation loss: -0.8474\n",
      "2022-11-27 18:27:22.081917: Average global foreground Dice: [0.8941, 0.8764]\n",
      "2022-11-27 18:27:22.081976: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:27:22.424067: lr: 0.009811\n",
      "2022-11-27 18:27:22.428245: saving checkpoint...\n",
      "2022-11-27 18:27:22.487897: done, saving took 0.06 seconds\n",
      "2022-11-27 18:27:22.489764: This epoch took 15.870601 s\n",
      "\n",
      "2022-11-27 18:27:22.489832: \n",
      "epoch:  21\n",
      "2022-11-27 18:27:36.990435: train loss : -0.8581\n",
      "2022-11-27 18:27:38.020243: validation loss: -0.8460\n",
      "2022-11-27 18:27:38.024406: Average global foreground Dice: [0.8924, 0.8757]\n",
      "2022-11-27 18:27:38.024605: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:27:38.379664: lr: 0.009802\n",
      "2022-11-27 18:27:38.383778: saving checkpoint...\n",
      "2022-11-27 18:27:38.442163: done, saving took 0.06 seconds\n",
      "2022-11-27 18:27:38.444094: This epoch took 15.954232 s\n",
      "\n",
      "2022-11-27 18:27:38.444168: \n",
      "epoch:  22\n",
      "2022-11-27 18:27:52.850643: train loss : -0.8601\n",
      "2022-11-27 18:27:53.849495: validation loss: -0.8515\n",
      "2022-11-27 18:27:53.849827: Average global foreground Dice: [0.8961, 0.8788]\n",
      "2022-11-27 18:27:53.850174: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:27:54.189152: lr: 0.009793\n",
      "2022-11-27 18:27:54.193082: saving checkpoint...\n",
      "2022-11-27 18:27:54.252383: done, saving took 0.06 seconds\n",
      "2022-11-27 18:27:54.257461: This epoch took 15.813258 s\n",
      "\n",
      "2022-11-27 18:27:54.257618: \n",
      "epoch:  23\n",
      "2022-11-27 18:28:08.675790: train loss : -0.8582\n",
      "2022-11-27 18:28:09.685042: validation loss: -0.8486\n",
      "2022-11-27 18:28:09.685388: Average global foreground Dice: [0.8947, 0.8764]\n",
      "2022-11-27 18:28:09.685445: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:28:10.020826: lr: 0.009784\n",
      "2022-11-27 18:28:10.024838: saving checkpoint...\n",
      "2022-11-27 18:28:10.083432: done, saving took 0.06 seconds\n",
      "2022-11-27 18:28:10.088448: This epoch took 15.830732 s\n",
      "\n",
      "2022-11-27 18:28:10.088603: \n",
      "epoch:  24\n",
      "2022-11-27 18:28:24.523217: train loss : -0.8609\n",
      "2022-11-27 18:28:25.557014: validation loss: -0.8508\n",
      "2022-11-27 18:28:25.557358: Average global foreground Dice: [0.898, 0.8776]\n",
      "2022-11-27 18:28:25.557412: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:28:26.007919: lr: 0.009775\n",
      "2022-11-27 18:28:26.011895: saving checkpoint...\n",
      "2022-11-27 18:28:26.079628: done, saving took 0.07 seconds\n",
      "2022-11-27 18:28:26.082554: This epoch took 15.993855 s\n",
      "\n",
      "2022-11-27 18:28:26.082637: \n",
      "epoch:  25\n",
      "2022-11-27 18:28:40.454850: train loss : -0.8601\n",
      "2022-11-27 18:28:41.475105: validation loss: -0.8510\n",
      "2022-11-27 18:28:41.475486: Average global foreground Dice: [0.8964, 0.879]\n",
      "2022-11-27 18:28:41.475597: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:28:41.814488: lr: 0.009766\n",
      "2022-11-27 18:28:41.818446: saving checkpoint...\n",
      "2022-11-27 18:28:41.878741: done, saving took 0.06 seconds\n",
      "2022-11-27 18:28:41.883893: This epoch took 15.801201 s\n",
      "\n",
      "2022-11-27 18:28:41.884047: \n",
      "epoch:  26\n",
      "2022-11-27 18:28:56.369858: train loss : -0.8635\n",
      "2022-11-27 18:28:57.394564: validation loss: -0.8518\n",
      "2022-11-27 18:28:57.394949: Average global foreground Dice: [0.8963, 0.8809]\n",
      "2022-11-27 18:28:57.395084: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:28:57.734548: lr: 0.009757\n",
      "2022-11-27 18:28:57.738519: saving checkpoint...\n",
      "2022-11-27 18:28:57.798599: done, saving took 0.06 seconds\n",
      "2022-11-27 18:28:57.800603: This epoch took 15.916461 s\n",
      "\n",
      "2022-11-27 18:28:57.800671: \n",
      "epoch:  27\n",
      "2022-11-27 18:29:12.272050: train loss : -0.8615\n",
      "2022-11-27 18:29:13.304276: validation loss: -0.8473\n",
      "2022-11-27 18:29:13.304646: Average global foreground Dice: [0.8945, 0.8752]\n",
      "2022-11-27 18:29:13.304723: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:29:13.640526: lr: 0.009748\n",
      "2022-11-27 18:29:13.644592: saving checkpoint...\n",
      "2022-11-27 18:29:13.703378: done, saving took 0.06 seconds\n",
      "2022-11-27 18:29:13.708898: This epoch took 15.908188 s\n",
      "\n",
      "2022-11-27 18:29:13.709075: \n",
      "epoch:  28\n",
      "2022-11-27 18:29:28.193241: train loss : -0.8628\n",
      "2022-11-27 18:29:29.224721: validation loss: -0.8499\n",
      "2022-11-27 18:29:29.225101: Average global foreground Dice: [0.8946, 0.8798]\n",
      "2022-11-27 18:29:29.225160: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:29:29.586014: lr: 0.009739\n",
      "2022-11-27 18:29:29.590172: saving checkpoint...\n",
      "2022-11-27 18:29:29.649888: done, saving took 0.06 seconds\n",
      "2022-11-27 18:29:29.651858: This epoch took 15.942679 s\n",
      "\n",
      "2022-11-27 18:29:29.651908: \n",
      "epoch:  29\n",
      "2022-11-27 18:29:44.020546: train loss : -0.8619\n",
      "2022-11-27 18:29:45.039073: validation loss: -0.8468\n",
      "2022-11-27 18:29:45.039568: Average global foreground Dice: [0.892, 0.8747]\n",
      "2022-11-27 18:29:45.039739: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:29:45.378399: lr: 0.00973\n",
      "2022-11-27 18:29:45.382466: saving checkpoint...\n",
      "2022-11-27 18:29:45.441847: done, saving took 0.06 seconds\n",
      "2022-11-27 18:29:45.443754: This epoch took 15.791801 s\n",
      "\n",
      "2022-11-27 18:29:45.443813: \n",
      "epoch:  30\n",
      "2022-11-27 18:29:59.722022: train loss : -0.8652\n",
      "2022-11-27 18:30:00.713738: validation loss: -0.8506\n",
      "2022-11-27 18:30:00.714151: Average global foreground Dice: [0.8932, 0.8805]\n",
      "2022-11-27 18:30:00.714215: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:30:01.072110: lr: 0.009721\n",
      "2022-11-27 18:30:01.076173: saving checkpoint...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 18:30:01.135885: done, saving took 0.06 seconds\n",
      "2022-11-27 18:30:01.137800: This epoch took 15.693958 s\n",
      "\n",
      "2022-11-27 18:30:01.137870: \n",
      "epoch:  31\n",
      "2022-11-27 18:30:15.337688: train loss : -0.8661\n",
      "2022-11-27 18:30:16.338706: validation loss: -0.8452\n",
      "2022-11-27 18:30:16.339033: Average global foreground Dice: [0.8916, 0.8747]\n",
      "2022-11-27 18:30:16.339088: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:30:16.747509: lr: 0.009712\n",
      "2022-11-27 18:30:16.751483: saving checkpoint...\n",
      "2022-11-27 18:30:16.811215: done, saving took 0.06 seconds\n",
      "2022-11-27 18:30:16.813140: This epoch took 15.675233 s\n",
      "\n",
      "2022-11-27 18:30:16.813194: \n",
      "epoch:  32\n",
      "2022-11-27 18:30:31.074351: train loss : -0.8648\n",
      "2022-11-27 18:30:32.076210: validation loss: -0.8550\n",
      "2022-11-27 18:30:32.076543: Average global foreground Dice: [0.8984, 0.882]\n",
      "2022-11-27 18:30:32.076599: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:30:32.414889: lr: 0.009703\n",
      "2022-11-27 18:30:32.418947: saving checkpoint...\n",
      "2022-11-27 18:30:32.478065: done, saving took 0.06 seconds\n",
      "2022-11-27 18:30:32.480014: This epoch took 15.666791 s\n",
      "\n",
      "2022-11-27 18:30:32.480070: \n",
      "epoch:  33\n",
      "2022-11-27 18:30:46.718686: train loss : -0.8675\n",
      "2022-11-27 18:30:47.704627: validation loss: -0.8494\n",
      "2022-11-27 18:30:47.705012: Average global foreground Dice: [0.8948, 0.8761]\n",
      "2022-11-27 18:30:47.705070: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:30:48.045004: lr: 0.009693\n",
      "2022-11-27 18:30:48.049066: saving checkpoint...\n",
      "2022-11-27 18:30:48.112402: done, saving took 0.07 seconds\n",
      "2022-11-27 18:30:48.114354: This epoch took 15.634238 s\n",
      "\n",
      "2022-11-27 18:30:48.114418: \n",
      "epoch:  34\n",
      "2022-11-27 18:31:02.335469: train loss : -0.8693\n",
      "2022-11-27 18:31:03.347045: validation loss: -0.8489\n",
      "2022-11-27 18:31:03.347378: Average global foreground Dice: [0.8929, 0.8792]\n",
      "2022-11-27 18:31:03.347431: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:31:03.807363: lr: 0.009684\n",
      "2022-11-27 18:31:03.811424: saving checkpoint...\n",
      "2022-11-27 18:31:03.871187: done, saving took 0.06 seconds\n",
      "2022-11-27 18:31:03.873007: This epoch took 15.758559 s\n",
      "\n",
      "2022-11-27 18:31:03.873064: \n",
      "epoch:  35\n",
      "2022-11-27 18:31:18.184352: train loss : -0.8695\n",
      "2022-11-27 18:31:19.173968: validation loss: -0.8497\n",
      "2022-11-27 18:31:19.174438: Average global foreground Dice: [0.8951, 0.8783]\n",
      "2022-11-27 18:31:19.174529: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:31:19.516081: lr: 0.009675\n",
      "2022-11-27 18:31:19.520156: saving checkpoint...\n",
      "2022-11-27 18:31:19.579803: done, saving took 0.06 seconds\n",
      "2022-11-27 18:31:19.584911: This epoch took 15.711812 s\n",
      "\n",
      "2022-11-27 18:31:19.585065: \n",
      "epoch:  36\n",
      "2022-11-27 18:31:33.861802: train loss : -0.8693\n",
      "2022-11-27 18:31:34.891676: validation loss: -0.8524\n",
      "2022-11-27 18:31:34.892056: Average global foreground Dice: [0.8957, 0.883]\n",
      "2022-11-27 18:31:34.892112: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:31:35.229875: lr: 0.009666\n",
      "2022-11-27 18:31:35.233826: saving checkpoint...\n",
      "2022-11-27 18:31:35.293555: done, saving took 0.06 seconds\n",
      "2022-11-27 18:31:35.298390: This epoch took 15.713229 s\n",
      "\n",
      "2022-11-27 18:31:35.298500: \n",
      "epoch:  37\n",
      "2022-11-27 18:31:49.554750: train loss : -0.8682\n",
      "2022-11-27 18:31:50.577880: validation loss: -0.8482\n",
      "2022-11-27 18:31:50.578223: Average global foreground Dice: [0.8928, 0.8793]\n",
      "2022-11-27 18:31:50.578282: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:31:50.919961: lr: 0.009657\n",
      "2022-11-27 18:31:50.924029: saving checkpoint...\n",
      "2022-11-27 18:31:50.982820: done, saving took 0.06 seconds\n",
      "2022-11-27 18:31:50.984749: This epoch took 15.686184 s\n",
      "\n",
      "2022-11-27 18:31:50.984810: \n",
      "epoch:  38\n",
      "2022-11-27 18:32:05.197521: train loss : -0.8710\n",
      "2022-11-27 18:32:06.191934: validation loss: -0.8442\n",
      "2022-11-27 18:32:06.192270: Average global foreground Dice: [0.891, 0.8742]\n",
      "2022-11-27 18:32:06.192326: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:32:06.553941: lr: 0.009648\n",
      "2022-11-27 18:32:06.554048: This epoch took 15.569194 s\n",
      "\n",
      "2022-11-27 18:32:06.554077: \n",
      "epoch:  39\n",
      "2022-11-27 18:32:20.746122: train loss : -0.8706\n",
      "2022-11-27 18:32:21.738021: validation loss: -0.8501\n",
      "2022-11-27 18:32:21.738399: Average global foreground Dice: [0.8963, 0.8788]\n",
      "2022-11-27 18:32:21.738459: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:32:22.081707: lr: 0.009639\n",
      "2022-11-27 18:32:22.085814: saving checkpoint...\n",
      "2022-11-27 18:32:22.144481: done, saving took 0.06 seconds\n",
      "2022-11-27 18:32:22.148828: This epoch took 15.594710 s\n",
      "\n",
      "2022-11-27 18:32:22.148996: \n",
      "epoch:  40\n",
      "2022-11-27 18:32:36.371386: train loss : -0.8688\n",
      "2022-11-27 18:32:37.368450: validation loss: -0.8508\n",
      "2022-11-27 18:32:37.368779: Average global foreground Dice: [0.8959, 0.8782]\n",
      "2022-11-27 18:32:37.368834: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:32:37.707842: lr: 0.00963\n",
      "2022-11-27 18:32:37.711803: saving checkpoint...\n",
      "2022-11-27 18:32:37.769774: done, saving took 0.06 seconds\n",
      "2022-11-27 18:32:37.771835: This epoch took 15.622742 s\n",
      "\n",
      "2022-11-27 18:32:37.771914: \n",
      "epoch:  41\n",
      "2022-11-27 18:32:52.025574: train loss : -0.8733\n",
      "2022-11-27 18:32:53.046223: validation loss: -0.8474\n",
      "2022-11-27 18:32:53.046607: Average global foreground Dice: [0.893, 0.8776]\n",
      "2022-11-27 18:32:53.046667: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:32:53.385271: lr: 0.009621\n",
      "2022-11-27 18:32:53.389361: saving checkpoint...\n",
      "2022-11-27 18:32:53.445416: done, saving took 0.06 seconds\n",
      "2022-11-27 18:32:53.447325: This epoch took 15.675380 s\n",
      "\n",
      "2022-11-27 18:32:53.447390: \n",
      "epoch:  42\n",
      "2022-11-27 18:33:07.697636: train loss : -0.8739\n",
      "2022-11-27 18:33:08.706568: validation loss: -0.8513\n",
      "2022-11-27 18:33:08.706947: Average global foreground Dice: [0.8967, 0.8799]\n",
      "2022-11-27 18:33:08.707007: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:33:09.062788: lr: 0.009612\n",
      "2022-11-27 18:33:09.066888: saving checkpoint...\n",
      "2022-11-27 18:33:09.125618: done, saving took 0.06 seconds\n",
      "2022-11-27 18:33:09.127557: This epoch took 15.680132 s\n",
      "\n",
      "2022-11-27 18:33:09.127617: \n",
      "epoch:  43\n",
      "2022-11-27 18:33:23.383876: train loss : -0.8739\n",
      "2022-11-27 18:33:24.379276: validation loss: -0.8469\n",
      "2022-11-27 18:33:24.379613: Average global foreground Dice: [0.8931, 0.8771]\n",
      "2022-11-27 18:33:24.379670: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:33:24.721541: lr: 0.009603\n",
      "2022-11-27 18:33:24.721645: This epoch took 15.593999 s\n",
      "\n",
      "2022-11-27 18:33:24.721674: \n",
      "epoch:  44\n",
      "2022-11-27 18:33:39.007009: train loss : -0.8747\n",
      "2022-11-27 18:33:40.004960: validation loss: -0.8475\n",
      "2022-11-27 18:33:40.005295: Average global foreground Dice: [0.895, 0.8756]\n",
      "2022-11-27 18:33:40.005353: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:33:40.462088: lr: 0.009594\n",
      "2022-11-27 18:33:40.462198: This epoch took 15.740497 s\n",
      "\n",
      "2022-11-27 18:33:40.462233: \n",
      "epoch:  45\n",
      "2022-11-27 18:33:54.700326: train loss : -0.8745\n",
      "2022-11-27 18:33:55.704639: validation loss: -0.8493\n",
      "2022-11-27 18:33:55.705040: Average global foreground Dice: [0.8937, 0.8784]\n",
      "2022-11-27 18:33:55.705119: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:33:56.045136: lr: 0.009585\n",
      "2022-11-27 18:33:56.049248: saving checkpoint...\n",
      "2022-11-27 18:33:56.108103: done, saving took 0.06 seconds\n",
      "2022-11-27 18:33:56.113438: This epoch took 15.651171 s\n",
      "\n",
      "2022-11-27 18:33:56.113611: \n",
      "epoch:  46\n",
      "2022-11-27 18:34:10.343002: train loss : -0.8742\n",
      "2022-11-27 18:34:11.344620: validation loss: -0.8523\n",
      "2022-11-27 18:34:11.344956: Average global foreground Dice: [0.8984, 0.8801]\n",
      "2022-11-27 18:34:11.345014: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 18:34:11.685046: lr: 0.009576\n",
      "2022-11-27 18:34:11.689146: saving checkpoint...\n",
      "2022-11-27 18:34:11.747655: done, saving took 0.06 seconds\n",
      "2022-11-27 18:34:11.749624: This epoch took 15.635901 s\n",
      "\n",
      "2022-11-27 18:34:11.749700: \n",
      "epoch:  47\n",
      "2022-11-27 18:34:25.982498: train loss : -0.8750\n",
      "2022-11-27 18:34:26.981996: validation loss: -0.8488\n",
      "2022-11-27 18:34:26.982376: Average global foreground Dice: [0.8943, 0.8782]\n",
      "2022-11-27 18:34:26.982435: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:34:27.343235: lr: 0.009567\n",
      "2022-11-27 18:34:27.347224: saving checkpoint...\n",
      "2022-11-27 18:34:27.406688: done, saving took 0.06 seconds\n",
      "2022-11-27 18:34:27.408534: This epoch took 15.658803 s\n",
      "\n",
      "2022-11-27 18:34:27.408591: \n",
      "epoch:  48\n",
      "2022-11-27 18:34:41.676630: train loss : -0.8776\n",
      "2022-11-27 18:34:42.677400: validation loss: -0.8502\n",
      "2022-11-27 18:34:42.677728: Average global foreground Dice: [0.896, 0.8805]\n",
      "2022-11-27 18:34:42.677782: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:34:43.017052: lr: 0.009558\n",
      "2022-11-27 18:34:43.021132: saving checkpoint...\n",
      "2022-11-27 18:34:43.080053: done, saving took 0.06 seconds\n",
      "2022-11-27 18:34:43.084725: This epoch took 15.676100 s\n",
      "\n",
      "2022-11-27 18:34:43.084859: \n",
      "epoch:  49\n",
      "2022-11-27 18:34:57.393512: train loss : -0.8776\n",
      "2022-11-27 18:34:58.396335: validation loss: -0.8424\n",
      "2022-11-27 18:34:58.396716: Average global foreground Dice: [0.8912, 0.872]\n",
      "2022-11-27 18:34:58.396775: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:34:58.759099: lr: 0.009549\n",
      "2022-11-27 18:34:58.759203: saving scheduled checkpoint file...\n",
      "2022-11-27 18:34:58.763118: saving checkpoint...\n",
      "2022-11-27 18:34:58.801303: done, saving took 0.04 seconds\n",
      "2022-11-27 18:34:58.803086: done\n",
      "2022-11-27 18:34:58.803165: This epoch took 15.718229 s\n",
      "\n",
      "2022-11-27 18:34:58.803213: \n",
      "epoch:  50\n",
      "2022-11-27 18:35:13.055725: train loss : -0.8768\n",
      "2022-11-27 18:35:14.060528: validation loss: -0.8460\n",
      "2022-11-27 18:35:14.060864: Average global foreground Dice: [0.8917, 0.8762]\n",
      "2022-11-27 18:35:14.060919: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:35:14.407513: lr: 0.00954\n",
      "2022-11-27 18:35:14.407632: This epoch took 15.604377 s\n",
      "\n",
      "2022-11-27 18:35:14.407662: \n",
      "epoch:  51\n",
      "2022-11-27 18:35:28.647358: train loss : -0.8757\n",
      "2022-11-27 18:35:29.647639: validation loss: -0.8491\n",
      "2022-11-27 18:35:29.647952: Average global foreground Dice: [0.8944, 0.8786]\n",
      "2022-11-27 18:35:29.648007: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:35:29.987013: lr: 0.009531\n",
      "2022-11-27 18:35:29.987120: This epoch took 15.579432 s\n",
      "\n",
      "2022-11-27 18:35:29.987150: \n",
      "epoch:  52\n",
      "2022-11-27 18:35:44.257206: train loss : -0.8774\n",
      "2022-11-27 18:35:45.258252: validation loss: -0.8452\n",
      "2022-11-27 18:35:45.258642: Average global foreground Dice: [0.8932, 0.8749]\n",
      "2022-11-27 18:35:45.258703: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:35:45.599702: lr: 0.009522\n",
      "2022-11-27 18:35:45.599808: This epoch took 15.612631 s\n",
      "\n",
      "2022-11-27 18:35:45.599836: \n",
      "epoch:  53\n",
      "2022-11-27 18:35:59.830161: train loss : -0.8782\n",
      "2022-11-27 18:36:00.832512: validation loss: -0.8457\n",
      "2022-11-27 18:36:00.833091: Average global foreground Dice: [0.8923, 0.8756]\n",
      "2022-11-27 18:36:00.833182: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:36:01.177671: lr: 0.009513\n",
      "2022-11-27 18:36:01.177776: This epoch took 15.577913 s\n",
      "\n",
      "2022-11-27 18:36:01.177806: \n",
      "epoch:  54\n",
      "2022-11-27 18:36:15.409974: train loss : -0.8784\n",
      "2022-11-27 18:36:16.424483: validation loss: -0.8484\n",
      "2022-11-27 18:36:16.424823: Average global foreground Dice: [0.8932, 0.8784]\n",
      "2022-11-27 18:36:16.424937: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:36:16.866656: lr: 0.009504\n",
      "2022-11-27 18:36:16.866764: This epoch took 15.688927 s\n",
      "\n",
      "2022-11-27 18:36:16.866795: \n",
      "epoch:  55\n",
      "2022-11-27 18:36:31.139195: train loss : -0.8804\n",
      "2022-11-27 18:36:32.141443: validation loss: -0.8450\n",
      "2022-11-27 18:36:32.141767: Average global foreground Dice: [0.8911, 0.876]\n",
      "2022-11-27 18:36:32.141821: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:36:32.493126: lr: 0.009495\n",
      "2022-11-27 18:36:32.493245: This epoch took 15.626408 s\n",
      "\n",
      "2022-11-27 18:36:32.493277: \n",
      "epoch:  56\n",
      "2022-11-27 18:36:46.737631: train loss : -0.8795\n",
      "2022-11-27 18:36:47.720650: validation loss: -0.8457\n",
      "2022-11-27 18:36:47.721183: Average global foreground Dice: [0.8931, 0.8784]\n",
      "2022-11-27 18:36:47.721275: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:36:48.060548: lr: 0.009486\n",
      "2022-11-27 18:36:48.060654: This epoch took 15.567351 s\n",
      "\n",
      "2022-11-27 18:36:48.060681: \n",
      "epoch:  57\n",
      "2022-11-27 18:37:02.399429: train loss : -0.8797\n",
      "2022-11-27 18:37:03.408574: validation loss: -0.8508\n",
      "2022-11-27 18:37:03.408906: Average global foreground Dice: [0.8968, 0.8797]\n",
      "2022-11-27 18:37:03.408962: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:37:03.742853: lr: 0.009476\n",
      "2022-11-27 18:37:03.742959: This epoch took 15.682253 s\n",
      "\n",
      "2022-11-27 18:37:03.743003: \n",
      "epoch:  58\n",
      "2022-11-27 18:37:17.995412: train loss : -0.8800\n",
      "2022-11-27 18:37:19.040200: validation loss: -0.8510\n",
      "2022-11-27 18:37:19.040539: Average global foreground Dice: [0.8952, 0.8822]\n",
      "2022-11-27 18:37:19.040594: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:37:19.382703: lr: 0.009467\n",
      "2022-11-27 18:37:19.382813: This epoch took 15.639784 s\n",
      "\n",
      "2022-11-27 18:37:19.382844: \n",
      "epoch:  59\n",
      "2022-11-27 18:37:33.609034: train loss : -0.8818\n",
      "2022-11-27 18:37:34.615096: validation loss: -0.8503\n",
      "2022-11-27 18:37:34.615472: Average global foreground Dice: [0.8964, 0.88]\n",
      "2022-11-27 18:37:34.615541: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:37:34.954003: lr: 0.009458\n",
      "2022-11-27 18:37:34.954111: This epoch took 15.571242 s\n",
      "\n",
      "2022-11-27 18:37:34.954139: \n",
      "epoch:  60\n",
      "2022-11-27 18:37:49.187982: train loss : -0.8818\n",
      "2022-11-27 18:37:50.196162: validation loss: -0.8498\n",
      "2022-11-27 18:37:50.196491: Average global foreground Dice: [0.8938, 0.8807]\n",
      "2022-11-27 18:37:50.196546: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:37:50.541763: lr: 0.009449\n",
      "2022-11-27 18:37:50.545865: saving checkpoint...\n",
      "2022-11-27 18:37:50.605913: done, saving took 0.06 seconds\n",
      "2022-11-27 18:37:50.607738: This epoch took 15.653572 s\n",
      "\n",
      "2022-11-27 18:37:50.607793: \n",
      "epoch:  61\n",
      "2022-11-27 18:38:04.871324: train loss : -0.8822\n",
      "2022-11-27 18:38:05.862116: validation loss: -0.8412\n",
      "2022-11-27 18:38:05.862451: Average global foreground Dice: [0.8895, 0.8734]\n",
      "2022-11-27 18:38:05.862504: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:38:06.204097: lr: 0.00944\n",
      "2022-11-27 18:38:06.204204: This epoch took 15.596382 s\n",
      "\n",
      "2022-11-27 18:38:06.204232: \n",
      "epoch:  62\n",
      "2022-11-27 18:38:20.476379: train loss : -0.8819\n",
      "2022-11-27 18:38:21.478616: validation loss: -0.8497\n",
      "2022-11-27 18:38:21.478989: Average global foreground Dice: [0.8969, 0.8787]\n",
      "2022-11-27 18:38:21.479049: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:38:21.825315: lr: 0.009431\n",
      "2022-11-27 18:38:21.825421: This epoch took 15.621161 s\n",
      "\n",
      "2022-11-27 18:38:21.825454: \n",
      "epoch:  63\n",
      "2022-11-27 18:38:36.071315: train loss : -0.8835\n",
      "2022-11-27 18:38:37.081842: validation loss: -0.8490\n",
      "2022-11-27 18:38:37.082221: Average global foreground Dice: [0.8938, 0.88]\n",
      "2022-11-27 18:38:37.082290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:38:37.420800: lr: 0.009422\n",
      "2022-11-27 18:38:37.420898: This epoch took 15.595412 s\n",
      "\n",
      "2022-11-27 18:38:37.420925: \n",
      "epoch:  64\n",
      "2022-11-27 18:38:51.712703: train loss : -0.8838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 18:38:52.710279: validation loss: -0.8442\n",
      "2022-11-27 18:38:52.710614: Average global foreground Dice: [0.8929, 0.8753]\n",
      "2022-11-27 18:38:52.710667: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:38:53.070303: lr: 0.009413\n",
      "2022-11-27 18:38:53.070408: This epoch took 15.649454 s\n",
      "\n",
      "2022-11-27 18:38:53.070436: \n",
      "epoch:  65\n",
      "2022-11-27 18:39:07.299846: train loss : -0.8835\n",
      "2022-11-27 18:39:08.281000: validation loss: -0.8583\n",
      "2022-11-27 18:39:08.281328: Average global foreground Dice: [0.9007, 0.8878]\n",
      "2022-11-27 18:39:08.281590: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:39:08.767496: lr: 0.009404\n",
      "2022-11-27 18:39:08.771639: saving checkpoint...\n",
      "2022-11-27 18:39:08.832532: done, saving took 0.06 seconds\n",
      "2022-11-27 18:39:08.834978: This epoch took 15.764515 s\n",
      "\n",
      "2022-11-27 18:39:08.835037: \n",
      "epoch:  66\n",
      "2022-11-27 18:39:23.120836: train loss : -0.8843\n",
      "2022-11-27 18:39:24.149743: validation loss: -0.8533\n",
      "2022-11-27 18:39:24.150071: Average global foreground Dice: [0.8975, 0.8831]\n",
      "2022-11-27 18:39:24.150129: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:39:24.495954: lr: 0.009395\n",
      "2022-11-27 18:39:24.499947: saving checkpoint...\n",
      "2022-11-27 18:39:24.559449: done, saving took 0.06 seconds\n",
      "2022-11-27 18:39:24.561403: This epoch took 15.726338 s\n",
      "\n",
      "2022-11-27 18:39:24.561466: \n",
      "epoch:  67\n",
      "2022-11-27 18:39:38.884825: train loss : -0.8845\n",
      "2022-11-27 18:39:39.894532: validation loss: -0.8517\n",
      "2022-11-27 18:39:39.894903: Average global foreground Dice: [0.8968, 0.8798]\n",
      "2022-11-27 18:39:39.894964: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:39:40.251575: lr: 0.009386\n",
      "2022-11-27 18:39:40.255892: saving checkpoint...\n",
      "2022-11-27 18:39:40.320078: done, saving took 0.07 seconds\n",
      "2022-11-27 18:39:40.322021: This epoch took 15.760525 s\n",
      "\n",
      "2022-11-27 18:39:40.322088: \n",
      "epoch:  68\n",
      "2022-11-27 18:39:54.564339: train loss : -0.8846\n",
      "2022-11-27 18:39:55.622603: validation loss: -0.8446\n",
      "2022-11-27 18:39:55.623002: Average global foreground Dice: [0.8921, 0.8764]\n",
      "2022-11-27 18:39:55.623068: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:39:55.990467: lr: 0.009377\n",
      "2022-11-27 18:39:55.990575: This epoch took 15.668453 s\n",
      "\n",
      "2022-11-27 18:39:55.990605: \n",
      "epoch:  69\n",
      "2022-11-27 18:40:10.212444: train loss : -0.8859\n",
      "2022-11-27 18:40:11.237778: validation loss: -0.8483\n",
      "2022-11-27 18:40:11.238164: Average global foreground Dice: [0.8941, 0.8796]\n",
      "2022-11-27 18:40:11.238247: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:40:11.586486: lr: 0.009368\n",
      "2022-11-27 18:40:11.586591: This epoch took 15.595960 s\n",
      "\n",
      "2022-11-27 18:40:11.586621: \n",
      "epoch:  70\n",
      "2022-11-27 18:40:25.819891: train loss : -0.8866\n",
      "2022-11-27 18:40:26.846742: validation loss: -0.8477\n",
      "2022-11-27 18:40:26.847118: Average global foreground Dice: [0.8938, 0.8773]\n",
      "2022-11-27 18:40:26.847187: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:40:27.202490: lr: 0.009359\n",
      "2022-11-27 18:40:27.202597: This epoch took 15.615950 s\n",
      "\n",
      "2022-11-27 18:40:27.202626: \n",
      "epoch:  71\n",
      "2022-11-27 18:40:41.408677: train loss : -0.8885\n",
      "2022-11-27 18:40:42.402302: validation loss: -0.8483\n",
      "2022-11-27 18:40:42.402695: Average global foreground Dice: [0.8937, 0.8804]\n",
      "2022-11-27 18:40:42.402755: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:40:42.750902: lr: 0.00935\n",
      "2022-11-27 18:40:42.751006: This epoch took 15.548353 s\n",
      "\n",
      "2022-11-27 18:40:42.751036: \n",
      "epoch:  72\n",
      "2022-11-27 18:40:57.047353: train loss : -0.8852\n",
      "2022-11-27 18:40:58.066311: validation loss: -0.8451\n",
      "2022-11-27 18:40:58.066697: Average global foreground Dice: [0.8914, 0.877]\n",
      "2022-11-27 18:40:58.066755: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:40:58.415404: lr: 0.009341\n",
      "2022-11-27 18:40:58.415509: This epoch took 15.664447 s\n",
      "\n",
      "2022-11-27 18:40:58.415552: \n",
      "epoch:  73\n",
      "2022-11-27 18:41:12.670966: train loss : -0.8879\n",
      "2022-11-27 18:41:13.669149: validation loss: -0.8510\n",
      "2022-11-27 18:41:13.669548: Average global foreground Dice: [0.8971, 0.8801]\n",
      "2022-11-27 18:41:13.669616: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:41:14.031089: lr: 0.009331\n",
      "2022-11-27 18:41:14.031193: This epoch took 15.615615 s\n",
      "\n",
      "2022-11-27 18:41:14.031222: \n",
      "epoch:  74\n",
      "2022-11-27 18:41:28.257629: train loss : -0.8868\n",
      "2022-11-27 18:41:29.239439: validation loss: -0.8495\n",
      "2022-11-27 18:41:29.239779: Average global foreground Dice: [0.8967, 0.8795]\n",
      "2022-11-27 18:41:29.239836: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:41:29.601598: lr: 0.009322\n",
      "2022-11-27 18:41:29.601712: This epoch took 15.570463 s\n",
      "\n",
      "2022-11-27 18:41:29.601743: \n",
      "epoch:  75\n",
      "2022-11-27 18:41:43.826818: train loss : -0.8874\n",
      "2022-11-27 18:41:44.827993: validation loss: -0.8443\n",
      "2022-11-27 18:41:44.828407: Average global foreground Dice: [0.8915, 0.8766]\n",
      "2022-11-27 18:41:44.828521: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:41:45.300698: lr: 0.009313\n",
      "2022-11-27 18:41:45.300801: This epoch took 15.699031 s\n",
      "\n",
      "2022-11-27 18:41:45.300846: \n",
      "epoch:  76\n",
      "2022-11-27 18:41:59.614666: train loss : -0.8869\n",
      "2022-11-27 18:42:00.598925: validation loss: -0.8486\n",
      "2022-11-27 18:42:00.599264: Average global foreground Dice: [0.8956, 0.8798]\n",
      "2022-11-27 18:42:00.599322: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:42:00.948168: lr: 0.009304\n",
      "2022-11-27 18:42:00.948286: This epoch took 15.647413 s\n",
      "\n",
      "2022-11-27 18:42:00.948316: \n",
      "epoch:  77\n",
      "2022-11-27 18:42:15.232195: train loss : -0.8887\n",
      "2022-11-27 18:42:16.225814: validation loss: -0.8485\n",
      "2022-11-27 18:42:16.226216: Average global foreground Dice: [0.8935, 0.8806]\n",
      "2022-11-27 18:42:16.226290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:42:16.574611: lr: 0.009295\n",
      "2022-11-27 18:42:16.574716: This epoch took 15.626374 s\n",
      "\n",
      "2022-11-27 18:42:16.574744: \n",
      "epoch:  78\n",
      "2022-11-27 18:42:30.800128: train loss : -0.8887\n",
      "2022-11-27 18:42:31.785541: validation loss: -0.8448\n",
      "2022-11-27 18:42:31.785929: Average global foreground Dice: [0.8935, 0.8743]\n",
      "2022-11-27 18:42:31.785991: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:42:32.157925: lr: 0.009286\n",
      "2022-11-27 18:42:32.158035: This epoch took 15.583264 s\n",
      "\n",
      "2022-11-27 18:42:32.158067: \n",
      "epoch:  79\n",
      "2022-11-27 18:42:46.424200: train loss : -0.8900\n",
      "2022-11-27 18:42:47.431145: validation loss: -0.8515\n",
      "2022-11-27 18:42:47.431515: Average global foreground Dice: [0.8972, 0.8809]\n",
      "2022-11-27 18:42:47.431571: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:42:47.793046: lr: 0.009277\n",
      "2022-11-27 18:42:47.793167: This epoch took 15.635055 s\n",
      "\n",
      "2022-11-27 18:42:47.793198: \n",
      "epoch:  80\n",
      "2022-11-27 18:43:02.024694: train loss : -0.8875\n",
      "2022-11-27 18:43:03.011492: validation loss: -0.8455\n",
      "2022-11-27 18:43:03.011861: Average global foreground Dice: [0.8931, 0.8751]\n",
      "2022-11-27 18:43:03.012089: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:43:03.382955: lr: 0.009268\n",
      "2022-11-27 18:43:03.383079: This epoch took 15.589854 s\n",
      "\n",
      "2022-11-27 18:43:03.383134: \n",
      "epoch:  81\n",
      "2022-11-27 18:43:17.626351: train loss : -0.8884\n",
      "2022-11-27 18:43:18.623371: validation loss: -0.8496\n",
      "2022-11-27 18:43:18.623772: Average global foreground Dice: [0.8967, 0.8795]\n",
      "2022-11-27 18:43:18.623935: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:43:19.002039: lr: 0.009259\n",
      "2022-11-27 18:43:19.002142: This epoch took 15.618965 s\n",
      "\n",
      "2022-11-27 18:43:19.002172: \n",
      "epoch:  82\n",
      "2022-11-27 18:43:33.209039: train loss : -0.8899\n",
      "2022-11-27 18:43:34.234219: validation loss: -0.8486\n",
      "2022-11-27 18:43:34.234627: Average global foreground Dice: [0.8935, 0.8805]\n",
      "2022-11-27 18:43:34.234694: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 18:43:34.600084: lr: 0.00925\n",
      "2022-11-27 18:43:34.600187: This epoch took 15.597987 s\n",
      "\n",
      "2022-11-27 18:43:34.600214: \n",
      "epoch:  83\n",
      "2022-11-27 18:43:48.868217: train loss : -0.8898\n",
      "2022-11-27 18:43:49.862771: validation loss: -0.8490\n",
      "2022-11-27 18:43:49.863161: Average global foreground Dice: [0.8955, 0.8798]\n",
      "2022-11-27 18:43:49.863220: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:43:50.228618: lr: 0.009241\n",
      "2022-11-27 18:43:50.228736: This epoch took 15.628476 s\n",
      "\n",
      "2022-11-27 18:43:50.228767: \n",
      "epoch:  84\n",
      "2022-11-27 18:44:04.553143: train loss : -0.8899\n",
      "2022-11-27 18:44:05.555754: validation loss: -0.8463\n",
      "2022-11-27 18:44:05.556148: Average global foreground Dice: [0.8945, 0.877]\n",
      "2022-11-27 18:44:05.556221: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:44:05.897433: lr: 0.009232\n",
      "2022-11-27 18:44:05.897534: This epoch took 15.668740 s\n",
      "\n",
      "2022-11-27 18:44:05.897560: \n",
      "epoch:  85\n",
      "2022-11-27 18:44:20.215594: train loss : -0.8897\n",
      "2022-11-27 18:44:21.210729: validation loss: -0.8439\n",
      "2022-11-27 18:44:21.211065: Average global foreground Dice: [0.8908, 0.8754]\n",
      "2022-11-27 18:44:21.211121: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:44:21.672568: lr: 0.009223\n",
      "2022-11-27 18:44:21.672673: This epoch took 15.775082 s\n",
      "\n",
      "2022-11-27 18:44:21.672701: \n",
      "epoch:  86\n",
      "2022-11-27 18:44:35.971681: train loss : -0.8906\n",
      "2022-11-27 18:44:37.007458: validation loss: -0.8446\n",
      "2022-11-27 18:44:37.007816: Average global foreground Dice: [0.8925, 0.8753]\n",
      "2022-11-27 18:44:37.007888: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:44:37.351564: lr: 0.009213\n",
      "2022-11-27 18:44:37.351688: This epoch took 15.678962 s\n",
      "\n",
      "2022-11-27 18:44:37.351717: \n",
      "epoch:  87\n",
      "2022-11-27 18:44:51.707335: train loss : -0.8895\n",
      "2022-11-27 18:44:52.706351: validation loss: -0.8532\n",
      "2022-11-27 18:44:52.706684: Average global foreground Dice: [0.8974, 0.8831]\n",
      "2022-11-27 18:44:52.706738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:44:53.059389: lr: 0.009204\n",
      "2022-11-27 18:44:53.059494: This epoch took 15.707745 s\n",
      "\n",
      "2022-11-27 18:44:53.059523: \n",
      "epoch:  88\n",
      "2022-11-27 18:45:07.292349: train loss : -0.8900\n",
      "2022-11-27 18:45:08.313711: validation loss: -0.8507\n",
      "2022-11-27 18:45:08.314070: Average global foreground Dice: [0.898, 0.8791]\n",
      "2022-11-27 18:45:08.314127: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:45:08.681243: lr: 0.009195\n",
      "2022-11-27 18:45:08.681360: This epoch took 15.621795 s\n",
      "\n",
      "2022-11-27 18:45:08.681391: \n",
      "epoch:  89\n",
      "2022-11-27 18:45:22.958966: train loss : -0.8891\n",
      "2022-11-27 18:45:23.993172: validation loss: -0.8500\n",
      "2022-11-27 18:45:23.993546: Average global foreground Dice: [0.8971, 0.8795]\n",
      "2022-11-27 18:45:23.993602: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:45:24.336564: lr: 0.009186\n",
      "2022-11-27 18:45:24.336681: This epoch took 15.655248 s\n",
      "\n",
      "2022-11-27 18:45:24.336712: \n",
      "epoch:  90\n",
      "2022-11-27 18:45:38.594070: train loss : -0.8899\n",
      "2022-11-27 18:45:39.592748: validation loss: -0.8477\n",
      "2022-11-27 18:45:39.593152: Average global foreground Dice: [0.8965, 0.8776]\n",
      "2022-11-27 18:45:39.593214: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:45:39.942040: lr: 0.009177\n",
      "2022-11-27 18:45:39.942145: This epoch took 15.605406 s\n",
      "\n",
      "2022-11-27 18:45:39.942174: \n",
      "epoch:  91\n",
      "2022-11-27 18:45:54.233884: train loss : -0.8909\n",
      "2022-11-27 18:45:55.237713: validation loss: -0.8425\n",
      "2022-11-27 18:45:55.238053: Average global foreground Dice: [0.8914, 0.8764]\n",
      "2022-11-27 18:45:55.238113: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:45:55.582165: lr: 0.009168\n",
      "2022-11-27 18:45:55.582273: This epoch took 15.640072 s\n",
      "\n",
      "2022-11-27 18:45:55.582302: \n",
      "epoch:  92\n",
      "2022-11-27 18:46:09.827960: train loss : -0.8910\n",
      "2022-11-27 18:46:10.830182: validation loss: -0.8490\n",
      "2022-11-27 18:46:10.830524: Average global foreground Dice: [0.8953, 0.8808]\n",
      "2022-11-27 18:46:10.830578: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:46:11.172009: lr: 0.009159\n",
      "2022-11-27 18:46:11.172228: This epoch took 15.589899 s\n",
      "\n",
      "2022-11-27 18:46:11.172257: \n",
      "epoch:  93\n",
      "2022-11-27 18:46:25.584048: train loss : -0.8910\n",
      "2022-11-27 18:46:26.621384: validation loss: -0.8430\n",
      "2022-11-27 18:46:26.621878: Average global foreground Dice: [0.8917, 0.8751]\n",
      "2022-11-27 18:46:26.621996: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:46:26.990998: lr: 0.00915\n",
      "2022-11-27 18:46:26.991214: This epoch took 15.818929 s\n",
      "\n",
      "2022-11-27 18:46:26.991244: \n",
      "epoch:  94\n",
      "2022-11-27 18:46:41.533819: train loss : -0.8916\n",
      "2022-11-27 18:46:42.529518: validation loss: -0.8511\n",
      "2022-11-27 18:46:42.529865: Average global foreground Dice: [0.8963, 0.8817]\n",
      "2022-11-27 18:46:42.529959: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:46:42.883644: lr: 0.009141\n",
      "2022-11-27 18:46:42.883745: This epoch took 15.892474 s\n",
      "\n",
      "2022-11-27 18:46:42.883772: \n",
      "epoch:  95\n",
      "2022-11-27 18:46:57.195101: train loss : -0.8933\n",
      "2022-11-27 18:46:58.223517: validation loss: -0.8482\n",
      "2022-11-27 18:46:58.223915: Average global foreground Dice: [0.895, 0.8794]\n",
      "2022-11-27 18:46:58.223975: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:46:58.671535: lr: 0.009132\n",
      "2022-11-27 18:46:58.671655: This epoch took 15.787843 s\n",
      "\n",
      "2022-11-27 18:46:58.671686: \n",
      "epoch:  96\n",
      "2022-11-27 18:47:13.012905: train loss : -0.8931\n",
      "2022-11-27 18:47:14.025656: validation loss: -0.8461\n",
      "2022-11-27 18:47:14.026033: Average global foreground Dice: [0.895, 0.8771]\n",
      "2022-11-27 18:47:14.026094: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:47:14.365910: lr: 0.009123\n",
      "2022-11-27 18:47:14.366038: This epoch took 15.694325 s\n",
      "\n",
      "2022-11-27 18:47:14.366067: \n",
      "epoch:  97\n",
      "2022-11-27 18:47:28.731612: train loss : -0.8924\n",
      "2022-11-27 18:47:29.763571: validation loss: -0.8490\n",
      "2022-11-27 18:47:29.763952: Average global foreground Dice: [0.8968, 0.8792]\n",
      "2022-11-27 18:47:29.764006: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:47:30.116154: lr: 0.009114\n",
      "2022-11-27 18:47:30.116273: This epoch took 15.750179 s\n",
      "\n",
      "2022-11-27 18:47:30.116302: \n",
      "epoch:  98\n",
      "2022-11-27 18:47:44.717949: train loss : -0.8937\n",
      "2022-11-27 18:47:45.714996: validation loss: -0.8482\n",
      "2022-11-27 18:47:45.715346: Average global foreground Dice: [0.8949, 0.8797]\n",
      "2022-11-27 18:47:45.715465: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:47:46.063339: lr: 0.009104\n",
      "2022-11-27 18:47:46.063458: This epoch took 15.947129 s\n",
      "\n",
      "2022-11-27 18:47:46.063488: \n",
      "epoch:  99\n",
      "2022-11-27 18:48:00.794978: train loss : -0.8935\n",
      "2022-11-27 18:48:01.875037: validation loss: -0.8430\n",
      "2022-11-27 18:48:01.875425: Average global foreground Dice: [0.8911, 0.8751]\n",
      "2022-11-27 18:48:01.875494: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:48:02.218625: lr: 0.009095\n",
      "2022-11-27 18:48:02.218737: saving scheduled checkpoint file...\n",
      "2022-11-27 18:48:02.222670: saving checkpoint...\n",
      "2022-11-27 18:48:02.280247: done, saving took 0.06 seconds\n",
      "2022-11-27 18:48:02.282140: done\n",
      "2022-11-27 18:48:02.282217: This epoch took 16.218702 s\n",
      "\n",
      "2022-11-27 18:48:02.282252: \n",
      "epoch:  100\n",
      "2022-11-27 18:48:17.293865: train loss : -0.8934\n",
      "2022-11-27 18:48:18.356227: validation loss: -0.8534\n",
      "2022-11-27 18:48:18.356589: Average global foreground Dice: [0.8985, 0.8835]\n",
      "2022-11-27 18:48:18.356661: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:48:18.698350: lr: 0.009086\n",
      "2022-11-27 18:48:18.698460: This epoch took 16.416180 s\n",
      "\n",
      "2022-11-27 18:48:18.698490: \n",
      "epoch:  101\n",
      "2022-11-27 18:48:33.721212: train loss : -0.8939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 18:48:34.738292: validation loss: -0.8502\n",
      "2022-11-27 18:48:34.738680: Average global foreground Dice: [0.8975, 0.8804]\n",
      "2022-11-27 18:48:34.738739: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:48:35.080236: lr: 0.009077\n",
      "2022-11-27 18:48:35.080348: This epoch took 16.381831 s\n",
      "\n",
      "2022-11-27 18:48:35.080381: \n",
      "epoch:  102\n",
      "2022-11-27 18:48:49.812759: train loss : -0.8935\n",
      "2022-11-27 18:48:50.864359: validation loss: -0.8431\n",
      "2022-11-27 18:48:50.864709: Average global foreground Dice: [0.8911, 0.8759]\n",
      "2022-11-27 18:48:50.864782: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:48:51.218823: lr: 0.009068\n",
      "2022-11-27 18:48:51.218943: This epoch took 16.138531 s\n",
      "\n",
      "2022-11-27 18:48:51.218974: \n",
      "epoch:  103\n",
      "2022-11-27 18:49:06.323264: train loss : -0.8937\n",
      "2022-11-27 18:49:07.322815: validation loss: -0.8416\n",
      "2022-11-27 18:49:07.323200: Average global foreground Dice: [0.8895, 0.8751]\n",
      "2022-11-27 18:49:07.323263: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:49:07.670172: lr: 0.009059\n",
      "2022-11-27 18:49:07.670289: This epoch took 16.451288 s\n",
      "\n",
      "2022-11-27 18:49:07.670319: \n",
      "epoch:  104\n",
      "2022-11-27 18:49:22.499738: train loss : -0.8933\n",
      "2022-11-27 18:49:23.479123: validation loss: -0.8503\n",
      "2022-11-27 18:49:23.479650: Average global foreground Dice: [0.8967, 0.8813]\n",
      "2022-11-27 18:49:23.479745: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:49:23.830369: lr: 0.00905\n",
      "2022-11-27 18:49:23.830487: This epoch took 16.160140 s\n",
      "\n",
      "2022-11-27 18:49:23.830523: \n",
      "epoch:  105\n",
      "2022-11-27 18:49:38.250360: train loss : -0.8937\n",
      "2022-11-27 18:49:39.244629: validation loss: -0.8461\n",
      "2022-11-27 18:49:39.244974: Average global foreground Dice: [0.8939, 0.8786]\n",
      "2022-11-27 18:49:39.245032: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:49:39.590114: lr: 0.009041\n",
      "2022-11-27 18:49:39.590228: This epoch took 15.759676 s\n",
      "\n",
      "2022-11-27 18:49:39.590259: \n",
      "epoch:  106\n",
      "2022-11-27 18:49:53.993577: train loss : -0.8946\n",
      "2022-11-27 18:49:54.998961: validation loss: -0.8470\n",
      "2022-11-27 18:49:54.999291: Average global foreground Dice: [0.8934, 0.8787]\n",
      "2022-11-27 18:49:54.999347: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:49:55.472200: lr: 0.009032\n",
      "2022-11-27 18:49:55.472310: This epoch took 15.882024 s\n",
      "\n",
      "2022-11-27 18:49:55.472336: \n",
      "epoch:  107\n",
      "2022-11-27 18:50:09.846031: train loss : -0.8932\n",
      "2022-11-27 18:50:10.827435: validation loss: -0.8398\n",
      "2022-11-27 18:50:10.827760: Average global foreground Dice: [0.8918, 0.8725]\n",
      "2022-11-27 18:50:10.827814: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:50:11.179399: lr: 0.009023\n",
      "2022-11-27 18:50:11.179518: This epoch took 15.707156 s\n",
      "\n",
      "2022-11-27 18:50:11.179545: \n",
      "epoch:  108\n",
      "2022-11-27 18:50:25.654319: train loss : -0.8961\n",
      "2022-11-27 18:50:26.689178: validation loss: -0.8444\n",
      "2022-11-27 18:50:26.689512: Average global foreground Dice: [0.8921, 0.8776]\n",
      "2022-11-27 18:50:26.689570: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:50:27.057631: lr: 0.009013\n",
      "2022-11-27 18:50:27.057747: This epoch took 15.878177 s\n",
      "\n",
      "2022-11-27 18:50:27.057778: \n",
      "epoch:  109\n",
      "2022-11-27 18:50:41.451620: train loss : -0.8950\n",
      "2022-11-27 18:50:42.440751: validation loss: -0.8510\n",
      "2022-11-27 18:50:42.441125: Average global foreground Dice: [0.8964, 0.8819]\n",
      "2022-11-27 18:50:42.441185: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:50:42.797879: lr: 0.009004\n",
      "2022-11-27 18:50:42.797998: This epoch took 15.740194 s\n",
      "\n",
      "2022-11-27 18:50:42.798028: \n",
      "epoch:  110\n",
      "2022-11-27 18:50:57.507757: train loss : -0.8956\n",
      "2022-11-27 18:50:58.496094: validation loss: -0.8446\n",
      "2022-11-27 18:50:58.496458: Average global foreground Dice: [0.8917, 0.8781]\n",
      "2022-11-27 18:50:58.496519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:50:58.848887: lr: 0.008995\n",
      "2022-11-27 18:50:58.849000: This epoch took 16.050945 s\n",
      "\n",
      "2022-11-27 18:50:58.849028: \n",
      "epoch:  111\n",
      "2022-11-27 18:51:13.341489: train loss : -0.8960\n",
      "2022-11-27 18:51:14.319756: validation loss: -0.8476\n",
      "2022-11-27 18:51:14.320313: Average global foreground Dice: [0.8953, 0.8797]\n",
      "2022-11-27 18:51:14.320438: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:51:14.675636: lr: 0.008986\n",
      "2022-11-27 18:51:14.675740: This epoch took 15.826672 s\n",
      "\n",
      "2022-11-27 18:51:14.675769: \n",
      "epoch:  112\n",
      "2022-11-27 18:51:28.929946: train loss : -0.8950\n",
      "2022-11-27 18:51:29.939070: validation loss: -0.8433\n",
      "2022-11-27 18:51:29.939408: Average global foreground Dice: [0.8934, 0.876]\n",
      "2022-11-27 18:51:29.939466: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:51:30.287850: lr: 0.008977\n",
      "2022-11-27 18:51:30.287970: This epoch took 15.612174 s\n",
      "\n",
      "2022-11-27 18:51:30.287999: \n",
      "epoch:  113\n",
      "2022-11-27 18:51:44.511834: train loss : -0.8966\n",
      "2022-11-27 18:51:45.530319: validation loss: -0.8485\n",
      "2022-11-27 18:51:45.530708: Average global foreground Dice: [0.8971, 0.8784]\n",
      "2022-11-27 18:51:45.530766: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:51:45.878457: lr: 0.008968\n",
      "2022-11-27 18:51:45.878564: This epoch took 15.590537 s\n",
      "\n",
      "2022-11-27 18:51:45.878595: \n",
      "epoch:  114\n",
      "2022-11-27 18:52:00.084099: train loss : -0.8961\n",
      "2022-11-27 18:52:01.130449: validation loss: -0.8466\n",
      "2022-11-27 18:52:01.130795: Average global foreground Dice: [0.8943, 0.8767]\n",
      "2022-11-27 18:52:01.131053: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:52:01.502897: lr: 0.008959\n",
      "2022-11-27 18:52:01.502997: This epoch took 15.624377 s\n",
      "\n",
      "2022-11-27 18:52:01.503046: \n",
      "epoch:  115\n",
      "2022-11-27 18:52:15.730911: train loss : -0.8976\n",
      "2022-11-27 18:52:16.729235: validation loss: -0.8461\n",
      "2022-11-27 18:52:16.729621: Average global foreground Dice: [0.8929, 0.8779]\n",
      "2022-11-27 18:52:16.729680: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:52:17.086663: lr: 0.00895\n",
      "2022-11-27 18:52:17.086768: This epoch took 15.583695 s\n",
      "\n",
      "2022-11-27 18:52:17.086799: \n",
      "epoch:  116\n",
      "2022-11-27 18:52:31.334808: train loss : -0.8957\n",
      "2022-11-27 18:52:32.364726: validation loss: -0.8488\n",
      "2022-11-27 18:52:32.365062: Average global foreground Dice: [0.8963, 0.8793]\n",
      "2022-11-27 18:52:32.365122: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:52:32.840791: lr: 0.008941\n",
      "2022-11-27 18:52:32.840913: This epoch took 15.754071 s\n",
      "\n",
      "2022-11-27 18:52:32.840952: \n",
      "epoch:  117\n",
      "2022-11-27 18:52:47.065635: train loss : -0.8973\n",
      "2022-11-27 18:52:48.067637: validation loss: -0.8481\n",
      "2022-11-27 18:52:48.068013: Average global foreground Dice: [0.896, 0.8775]\n",
      "2022-11-27 18:52:48.068083: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:52:48.422156: lr: 0.008931\n",
      "2022-11-27 18:52:48.422268: This epoch took 15.581275 s\n",
      "\n",
      "2022-11-27 18:52:48.422302: \n",
      "epoch:  118\n",
      "2022-11-27 18:53:02.703819: train loss : -0.8971\n",
      "2022-11-27 18:53:03.705408: validation loss: -0.8405\n",
      "2022-11-27 18:53:03.705794: Average global foreground Dice: [0.8916, 0.8739]\n",
      "2022-11-27 18:53:03.705853: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:53:04.054539: lr: 0.008922\n",
      "2022-11-27 18:53:04.054651: This epoch took 15.632319 s\n",
      "\n",
      "2022-11-27 18:53:04.054680: \n",
      "epoch:  119\n",
      "2022-11-27 18:53:18.276951: train loss : -0.8975\n",
      "2022-11-27 18:53:19.279215: validation loss: -0.8458\n",
      "2022-11-27 18:53:19.279551: Average global foreground Dice: [0.8939, 0.8775]\n",
      "2022-11-27 18:53:19.279603: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:53:19.631109: lr: 0.008913\n",
      "2022-11-27 18:53:19.631213: This epoch took 15.576506 s\n",
      "\n",
      "2022-11-27 18:53:19.631241: \n",
      "epoch:  120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 18:53:33.864373: train loss : -0.8974\n",
      "2022-11-27 18:53:34.873934: validation loss: -0.8463\n",
      "2022-11-27 18:53:34.874366: Average global foreground Dice: [0.8935, 0.8785]\n",
      "2022-11-27 18:53:34.874448: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:53:35.221747: lr: 0.008904\n",
      "2022-11-27 18:53:35.221869: This epoch took 15.590586 s\n",
      "\n",
      "2022-11-27 18:53:35.221907: \n",
      "epoch:  121\n",
      "2022-11-27 18:53:49.465795: train loss : -0.8975\n",
      "2022-11-27 18:53:50.470002: validation loss: -0.8462\n",
      "2022-11-27 18:53:50.470476: Average global foreground Dice: [0.8954, 0.8791]\n",
      "2022-11-27 18:53:50.470704: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:53:50.826278: lr: 0.008895\n",
      "2022-11-27 18:53:50.826389: This epoch took 15.604444 s\n",
      "\n",
      "2022-11-27 18:53:50.826417: \n",
      "epoch:  122\n",
      "2022-11-27 18:54:05.032300: train loss : -0.8977\n",
      "2022-11-27 18:54:06.033720: validation loss: -0.8468\n",
      "2022-11-27 18:54:06.034124: Average global foreground Dice: [0.8946, 0.8814]\n",
      "2022-11-27 18:54:06.034268: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:54:06.407322: lr: 0.008886\n",
      "2022-11-27 18:54:06.407427: This epoch took 15.580983 s\n",
      "\n",
      "2022-11-27 18:54:06.407455: \n",
      "epoch:  123\n",
      "2022-11-27 18:54:20.599523: train loss : -0.8968\n",
      "2022-11-27 18:54:21.608324: validation loss: -0.8519\n",
      "2022-11-27 18:54:21.608662: Average global foreground Dice: [0.8966, 0.8833]\n",
      "2022-11-27 18:54:21.608719: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:54:21.957823: lr: 0.008877\n",
      "2022-11-27 18:54:21.957948: This epoch took 15.550467 s\n",
      "\n",
      "2022-11-27 18:54:21.957981: \n",
      "epoch:  124\n",
      "2022-11-27 18:54:36.197110: train loss : -0.8991\n",
      "2022-11-27 18:54:37.191158: validation loss: -0.8438\n",
      "2022-11-27 18:54:37.191543: Average global foreground Dice: [0.8938, 0.8749]\n",
      "2022-11-27 18:54:37.191599: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:54:37.556356: lr: 0.008868\n",
      "2022-11-27 18:54:37.556458: This epoch took 15.598450 s\n",
      "\n",
      "2022-11-27 18:54:37.556484: \n",
      "epoch:  125\n",
      "2022-11-27 18:54:51.859129: train loss : -0.8979\n",
      "2022-11-27 18:54:52.858607: validation loss: -0.8464\n",
      "2022-11-27 18:54:52.859153: Average global foreground Dice: [0.896, 0.8782]\n",
      "2022-11-27 18:54:52.859317: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:54:53.234808: lr: 0.008859\n",
      "2022-11-27 18:54:53.234915: This epoch took 15.678406 s\n",
      "\n",
      "2022-11-27 18:54:53.234945: \n",
      "epoch:  126\n",
      "2022-11-27 18:55:07.489315: train loss : -0.8974\n",
      "2022-11-27 18:55:08.512802: validation loss: -0.8461\n",
      "2022-11-27 18:55:08.513146: Average global foreground Dice: [0.8943, 0.8786]\n",
      "2022-11-27 18:55:08.513204: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:55:08.965428: lr: 0.008849\n",
      "2022-11-27 18:55:08.965585: This epoch took 15.730613 s\n",
      "\n",
      "2022-11-27 18:55:08.965704: \n",
      "epoch:  127\n",
      "2022-11-27 18:55:23.205056: train loss : -0.8975\n",
      "2022-11-27 18:55:24.222573: validation loss: -0.8445\n",
      "2022-11-27 18:55:24.222898: Average global foreground Dice: [0.8925, 0.8766]\n",
      "2022-11-27 18:55:24.222954: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:55:24.585308: lr: 0.00884\n",
      "2022-11-27 18:55:24.585446: This epoch took 15.619696 s\n",
      "\n",
      "2022-11-27 18:55:24.585487: \n",
      "epoch:  128\n",
      "2022-11-27 18:55:38.800745: train loss : -0.8993\n",
      "2022-11-27 18:55:39.809531: validation loss: -0.8479\n",
      "2022-11-27 18:55:39.809931: Average global foreground Dice: [0.8959, 0.8787]\n",
      "2022-11-27 18:55:39.809997: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:55:40.152753: lr: 0.008831\n",
      "2022-11-27 18:55:40.152858: This epoch took 15.567330 s\n",
      "\n",
      "2022-11-27 18:55:40.152888: \n",
      "epoch:  129\n",
      "2022-11-27 18:55:54.370522: train loss : -0.8977\n",
      "2022-11-27 18:55:55.351906: validation loss: -0.8483\n",
      "2022-11-27 18:55:55.352231: Average global foreground Dice: [0.8962, 0.8785]\n",
      "2022-11-27 18:55:55.352359: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:55:55.693879: lr: 0.008822\n",
      "2022-11-27 18:55:55.693993: This epoch took 15.541078 s\n",
      "\n",
      "2022-11-27 18:55:55.694022: \n",
      "epoch:  130\n",
      "2022-11-27 18:56:09.937458: train loss : -0.8989\n",
      "2022-11-27 18:56:10.963926: validation loss: -0.8463\n",
      "2022-11-27 18:56:10.964339: Average global foreground Dice: [0.8968, 0.8773]\n",
      "2022-11-27 18:56:10.964538: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:56:11.338943: lr: 0.008813\n",
      "2022-11-27 18:56:11.339050: This epoch took 15.645002 s\n",
      "\n",
      "2022-11-27 18:56:11.339078: \n",
      "epoch:  131\n",
      "2022-11-27 18:56:25.610555: train loss : -0.8991\n",
      "2022-11-27 18:56:26.608462: validation loss: -0.8487\n",
      "2022-11-27 18:56:26.608793: Average global foreground Dice: [0.8951, 0.8799]\n",
      "2022-11-27 18:56:26.608846: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:56:26.994534: lr: 0.008804\n",
      "2022-11-27 18:56:26.994637: This epoch took 15.655525 s\n",
      "\n",
      "2022-11-27 18:56:26.994665: \n",
      "epoch:  132\n",
      "2022-11-27 18:56:41.241789: train loss : -0.8987\n",
      "2022-11-27 18:56:42.217199: validation loss: -0.8416\n",
      "2022-11-27 18:56:42.217542: Average global foreground Dice: [0.8911, 0.8748]\n",
      "2022-11-27 18:56:42.217601: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:56:42.561338: lr: 0.008795\n",
      "2022-11-27 18:56:42.561449: This epoch took 15.566758 s\n",
      "\n",
      "2022-11-27 18:56:42.561476: \n",
      "epoch:  133\n",
      "2022-11-27 18:56:56.824163: train loss : -0.9003\n",
      "2022-11-27 18:56:57.807346: validation loss: -0.8486\n",
      "2022-11-27 18:56:57.807697: Average global foreground Dice: [0.8976, 0.8804]\n",
      "2022-11-27 18:56:57.807752: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:56:58.160390: lr: 0.008785\n",
      "2022-11-27 18:56:58.160497: This epoch took 15.598994 s\n",
      "\n",
      "2022-11-27 18:56:58.160527: \n",
      "epoch:  134\n",
      "2022-11-27 18:57:12.405369: train loss : -0.8993\n",
      "2022-11-27 18:57:13.403923: validation loss: -0.8438\n",
      "2022-11-27 18:57:13.404368: Average global foreground Dice: [0.8918, 0.878]\n",
      "2022-11-27 18:57:13.404462: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:57:13.763526: lr: 0.008776\n",
      "2022-11-27 18:57:13.763630: This epoch took 15.603077 s\n",
      "\n",
      "2022-11-27 18:57:13.763659: \n",
      "epoch:  135\n",
      "2022-11-27 18:57:27.979452: train loss : -0.8975\n",
      "2022-11-27 18:57:28.967641: validation loss: -0.8452\n",
      "2022-11-27 18:57:28.968005: Average global foreground Dice: [0.896, 0.8773]\n",
      "2022-11-27 18:57:28.968079: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:57:29.314009: lr: 0.008767\n",
      "2022-11-27 18:57:29.314118: This epoch took 15.550432 s\n",
      "\n",
      "2022-11-27 18:57:29.314156: \n",
      "epoch:  136\n",
      "2022-11-27 18:57:43.544044: train loss : -0.8990\n",
      "2022-11-27 18:57:44.540826: validation loss: -0.8466\n",
      "2022-11-27 18:57:44.541203: Average global foreground Dice: [0.8934, 0.8803]\n",
      "2022-11-27 18:57:44.541260: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:57:45.001578: lr: 0.008758\n",
      "2022-11-27 18:57:45.001699: This epoch took 15.687513 s\n",
      "\n",
      "2022-11-27 18:57:45.001733: \n",
      "epoch:  137\n",
      "2022-11-27 18:57:59.223938: train loss : -0.9008\n",
      "2022-11-27 18:58:00.257032: validation loss: -0.8436\n",
      "2022-11-27 18:58:00.257387: Average global foreground Dice: [0.8931, 0.8766]\n",
      "2022-11-27 18:58:00.257450: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:58:00.601472: lr: 0.008749\n",
      "2022-11-27 18:58:00.601697: This epoch took 15.599935 s\n",
      "\n",
      "2022-11-27 18:58:00.601729: \n",
      "epoch:  138\n",
      "2022-11-27 18:58:14.821126: train loss : -0.8997\n",
      "2022-11-27 18:58:15.828782: validation loss: -0.8464\n",
      "2022-11-27 18:58:15.829224: Average global foreground Dice: [0.8937, 0.8778]\n",
      "2022-11-27 18:58:15.829324: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:58:16.176724: lr: 0.00874\n",
      "2022-11-27 18:58:16.176831: This epoch took 15.575076 s\n",
      "\n",
      "2022-11-27 18:58:16.176877: \n",
      "epoch:  139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 18:58:30.465250: train loss : -0.8988\n",
      "2022-11-27 18:58:31.468525: validation loss: -0.8455\n",
      "2022-11-27 18:58:31.468854: Average global foreground Dice: [0.8935, 0.8769]\n",
      "2022-11-27 18:58:31.468909: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:58:31.811692: lr: 0.008731\n",
      "2022-11-27 18:58:31.811910: This epoch took 15.635007 s\n",
      "\n",
      "2022-11-27 18:58:31.811940: \n",
      "epoch:  140\n",
      "2022-11-27 18:58:46.022823: train loss : -0.9002\n",
      "2022-11-27 18:58:47.016346: validation loss: -0.8458\n",
      "2022-11-27 18:58:47.016679: Average global foreground Dice: [0.8967, 0.8769]\n",
      "2022-11-27 18:58:47.016734: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:58:47.367844: lr: 0.008722\n",
      "2022-11-27 18:58:47.367953: This epoch took 15.555986 s\n",
      "\n",
      "2022-11-27 18:58:47.367983: \n",
      "epoch:  141\n",
      "2022-11-27 18:59:01.610549: train loss : -0.9013\n",
      "2022-11-27 18:59:02.599113: validation loss: -0.8469\n",
      "2022-11-27 18:59:02.599494: Average global foreground Dice: [0.8957, 0.8785]\n",
      "2022-11-27 18:59:02.599552: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:59:02.946186: lr: 0.008712\n",
      "2022-11-27 18:59:02.946292: This epoch took 15.578284 s\n",
      "\n",
      "2022-11-27 18:59:02.946321: \n",
      "epoch:  142\n",
      "2022-11-27 18:59:17.183573: train loss : -0.8995\n",
      "2022-11-27 18:59:18.174489: validation loss: -0.8450\n",
      "2022-11-27 18:59:18.174872: Average global foreground Dice: [0.8936, 0.8779]\n",
      "2022-11-27 18:59:18.174930: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:59:18.526642: lr: 0.008703\n",
      "2022-11-27 18:59:18.526746: This epoch took 15.580398 s\n",
      "\n",
      "2022-11-27 18:59:18.526774: \n",
      "epoch:  143\n",
      "2022-11-27 18:59:32.754321: train loss : -0.8993\n",
      "2022-11-27 18:59:33.745775: validation loss: -0.8463\n",
      "2022-11-27 18:59:33.746189: Average global foreground Dice: [0.8939, 0.8796]\n",
      "2022-11-27 18:59:33.746269: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:59:34.087018: lr: 0.008694\n",
      "2022-11-27 18:59:34.087125: This epoch took 15.560325 s\n",
      "\n",
      "2022-11-27 18:59:34.087154: \n",
      "epoch:  144\n",
      "2022-11-27 18:59:48.335972: train loss : -0.9000\n",
      "2022-11-27 18:59:49.348055: validation loss: -0.8438\n",
      "2022-11-27 18:59:49.348410: Average global foreground Dice: [0.8944, 0.8751]\n",
      "2022-11-27 18:59:49.348471: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 18:59:49.697282: lr: 0.008685\n",
      "2022-11-27 18:59:49.697382: This epoch took 15.610201 s\n",
      "\n",
      "2022-11-27 18:59:49.697409: \n",
      "epoch:  145\n",
      "2022-11-27 19:00:03.947588: train loss : -0.9014\n",
      "2022-11-27 19:00:04.965633: validation loss: -0.8409\n",
      "2022-11-27 19:00:04.965993: Average global foreground Dice: [0.8924, 0.8732]\n",
      "2022-11-27 19:00:04.966054: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:00:05.349494: lr: 0.008676\n",
      "2022-11-27 19:00:05.349600: This epoch took 15.652166 s\n",
      "\n",
      "2022-11-27 19:00:05.349628: \n",
      "epoch:  146\n",
      "2022-11-27 19:00:19.651712: train loss : -0.9009\n",
      "2022-11-27 19:00:20.657962: validation loss: -0.8394\n",
      "2022-11-27 19:00:20.658472: Average global foreground Dice: [0.8915, 0.8738]\n",
      "2022-11-27 19:00:20.658622: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:00:21.116786: lr: 0.008667\n",
      "2022-11-27 19:00:21.116894: This epoch took 15.767240 s\n",
      "\n",
      "2022-11-27 19:00:21.116946: \n",
      "epoch:  147\n",
      "2022-11-27 19:00:35.343658: train loss : -0.9029\n",
      "2022-11-27 19:00:36.362825: validation loss: -0.8440\n",
      "2022-11-27 19:00:36.363189: Average global foreground Dice: [0.8941, 0.8768]\n",
      "2022-11-27 19:00:36.363250: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:00:36.708637: lr: 0.008658\n",
      "2022-11-27 19:00:36.708757: This epoch took 15.591764 s\n",
      "\n",
      "2022-11-27 19:00:36.708787: \n",
      "epoch:  148\n",
      "2022-11-27 19:00:51.048637: train loss : -0.9024\n",
      "2022-11-27 19:00:52.051084: validation loss: -0.8402\n",
      "2022-11-27 19:00:52.051465: Average global foreground Dice: [0.8927, 0.8734]\n",
      "2022-11-27 19:00:52.051526: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:00:52.395986: lr: 0.008648\n",
      "2022-11-27 19:00:52.396107: This epoch took 15.687279 s\n",
      "\n",
      "2022-11-27 19:00:52.396137: \n",
      "epoch:  149\n",
      "2022-11-27 19:01:06.656258: train loss : -0.9003\n",
      "2022-11-27 19:01:07.674168: validation loss: -0.8475\n",
      "2022-11-27 19:01:07.674772: Average global foreground Dice: [0.8965, 0.8799]\n",
      "2022-11-27 19:01:07.674855: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:01:08.042539: lr: 0.008639\n",
      "2022-11-27 19:01:08.042637: saving scheduled checkpoint file...\n",
      "2022-11-27 19:01:08.046681: saving checkpoint...\n",
      "2022-11-27 19:01:08.106415: done, saving took 0.06 seconds\n",
      "2022-11-27 19:01:08.108295: done\n",
      "2022-11-27 19:01:08.108366: This epoch took 15.712203 s\n",
      "\n",
      "2022-11-27 19:01:08.108393: \n",
      "epoch:  150\n",
      "2022-11-27 19:01:22.348224: train loss : -0.9008\n",
      "2022-11-27 19:01:23.351609: validation loss: -0.8483\n",
      "2022-11-27 19:01:23.351985: Average global foreground Dice: [0.8963, 0.8817]\n",
      "2022-11-27 19:01:23.352145: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:01:23.713815: lr: 0.00863\n",
      "2022-11-27 19:01:23.713928: This epoch took 15.605508 s\n",
      "\n",
      "2022-11-27 19:01:23.713960: \n",
      "epoch:  151\n",
      "2022-11-27 19:01:37.968052: train loss : -0.9012\n",
      "2022-11-27 19:01:38.972319: validation loss: -0.8489\n",
      "2022-11-27 19:01:38.972648: Average global foreground Dice: [0.8961, 0.8797]\n",
      "2022-11-27 19:01:38.972701: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:01:39.315967: lr: 0.008621\n",
      "2022-11-27 19:01:39.316072: This epoch took 15.602081 s\n",
      "\n",
      "2022-11-27 19:01:39.316103: \n",
      "epoch:  152\n",
      "2022-11-27 19:01:53.647789: train loss : -0.8998\n",
      "2022-11-27 19:01:54.646731: validation loss: -0.8476\n",
      "2022-11-27 19:01:54.647073: Average global foreground Dice: [0.8955, 0.8778]\n",
      "2022-11-27 19:01:54.647130: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:01:55.001289: lr: 0.008612\n",
      "2022-11-27 19:01:55.001395: This epoch took 15.685266 s\n",
      "\n",
      "2022-11-27 19:01:55.001424: \n",
      "epoch:  153\n",
      "2022-11-27 19:02:09.287457: train loss : -0.9018\n",
      "2022-11-27 19:02:10.287605: validation loss: -0.8466\n",
      "2022-11-27 19:02:10.287924: Average global foreground Dice: [0.8956, 0.8792]\n",
      "2022-11-27 19:02:10.287977: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:02:10.633156: lr: 0.008603\n",
      "2022-11-27 19:02:10.633263: This epoch took 15.631812 s\n",
      "\n",
      "2022-11-27 19:02:10.633295: \n",
      "epoch:  154\n",
      "2022-11-27 19:02:24.855247: train loss : -0.9021\n",
      "2022-11-27 19:02:25.849160: validation loss: -0.8505\n",
      "2022-11-27 19:02:25.849537: Average global foreground Dice: [0.899, 0.8817]\n",
      "2022-11-27 19:02:25.849595: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:02:26.193221: lr: 0.008594\n",
      "2022-11-27 19:02:26.193328: This epoch took 15.560006 s\n",
      "\n",
      "2022-11-27 19:02:26.193357: \n",
      "epoch:  155\n",
      "2022-11-27 19:02:40.382311: train loss : -0.9020\n",
      "2022-11-27 19:02:41.389380: validation loss: -0.8430\n",
      "2022-11-27 19:02:41.389756: Average global foreground Dice: [0.8936, 0.8769]\n",
      "2022-11-27 19:02:41.389815: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:02:41.734830: lr: 0.008584\n",
      "2022-11-27 19:02:41.734946: This epoch took 15.541545 s\n",
      "\n",
      "2022-11-27 19:02:41.734976: \n",
      "epoch:  156\n",
      "2022-11-27 19:02:56.005301: train loss : -0.9009\n",
      "2022-11-27 19:02:57.001889: validation loss: -0.8373\n",
      "2022-11-27 19:02:57.002288: Average global foreground Dice: [0.8904, 0.8724]\n",
      "2022-11-27 19:02:57.002348: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:02:57.461177: lr: 0.008575\n",
      "2022-11-27 19:02:57.461285: This epoch took 15.726283 s\n",
      "\n",
      "2022-11-27 19:02:57.461314: \n",
      "epoch:  157\n",
      "2022-11-27 19:03:11.732359: train loss : -0.8998\n",
      "2022-11-27 19:03:12.729854: validation loss: -0.8489\n",
      "2022-11-27 19:03:12.730236: Average global foreground Dice: [0.8966, 0.8793]\n",
      "2022-11-27 19:03:12.730294: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 19:03:13.085636: lr: 0.008566\n",
      "2022-11-27 19:03:13.085743: This epoch took 15.624403 s\n",
      "\n",
      "2022-11-27 19:03:13.085769: \n",
      "epoch:  158\n",
      "2022-11-27 19:03:27.316688: train loss : -0.9017\n",
      "2022-11-27 19:03:28.303991: validation loss: -0.8430\n",
      "2022-11-27 19:03:28.304355: Average global foreground Dice: [0.8953, 0.8755]\n",
      "2022-11-27 19:03:28.304409: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:03:28.652265: lr: 0.008557\n",
      "2022-11-27 19:03:28.652367: This epoch took 15.566573 s\n",
      "\n",
      "2022-11-27 19:03:28.652393: \n",
      "epoch:  159\n",
      "2022-11-27 19:03:42.940704: train loss : -0.9018\n",
      "2022-11-27 19:03:43.980948: validation loss: -0.8455\n",
      "2022-11-27 19:03:43.981348: Average global foreground Dice: [0.8955, 0.8783]\n",
      "2022-11-27 19:03:43.981442: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:03:44.341642: lr: 0.008548\n",
      "2022-11-27 19:03:44.341759: This epoch took 15.689325 s\n",
      "\n",
      "2022-11-27 19:03:44.341792: \n",
      "epoch:  160\n",
      "2022-11-27 19:03:58.583042: train loss : -0.9012\n",
      "2022-11-27 19:03:59.580130: validation loss: -0.8453\n",
      "2022-11-27 19:03:59.580524: Average global foreground Dice: [0.8926, 0.8775]\n",
      "2022-11-27 19:03:59.580613: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:03:59.934221: lr: 0.008539\n",
      "2022-11-27 19:03:59.934330: This epoch took 15.592512 s\n",
      "\n",
      "2022-11-27 19:03:59.934358: \n",
      "epoch:  161\n",
      "2022-11-27 19:04:14.166302: train loss : -0.9030\n",
      "2022-11-27 19:04:15.181813: validation loss: -0.8427\n",
      "2022-11-27 19:04:15.182163: Average global foreground Dice: [0.8931, 0.8758]\n",
      "2022-11-27 19:04:15.182220: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:04:15.526232: lr: 0.008529\n",
      "2022-11-27 19:04:15.526344: This epoch took 15.591959 s\n",
      "\n",
      "2022-11-27 19:04:15.526377: \n",
      "epoch:  162\n",
      "2022-11-27 19:04:29.765298: train loss : -0.9031\n",
      "2022-11-27 19:04:30.759698: validation loss: -0.8471\n",
      "2022-11-27 19:04:30.760076: Average global foreground Dice: [0.8965, 0.8789]\n",
      "2022-11-27 19:04:30.760135: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:04:31.104240: lr: 0.00852\n",
      "2022-11-27 19:04:31.104362: This epoch took 15.577938 s\n",
      "\n",
      "2022-11-27 19:04:31.104391: \n",
      "epoch:  163\n",
      "2022-11-27 19:04:45.327427: train loss : -0.9036\n",
      "2022-11-27 19:04:46.317429: validation loss: -0.8470\n",
      "2022-11-27 19:04:46.317791: Average global foreground Dice: [0.8949, 0.8802]\n",
      "2022-11-27 19:04:46.317847: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:04:46.662596: lr: 0.008511\n",
      "2022-11-27 19:04:46.662703: This epoch took 15.558285 s\n",
      "\n",
      "2022-11-27 19:04:46.662732: \n",
      "epoch:  164\n",
      "2022-11-27 19:05:00.961149: train loss : -0.9032\n",
      "2022-11-27 19:05:02.005591: validation loss: -0.8480\n",
      "2022-11-27 19:05:02.006001: Average global foreground Dice: [0.8958, 0.8793]\n",
      "2022-11-27 19:05:02.006088: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:05:02.352712: lr: 0.008502\n",
      "2022-11-27 19:05:02.352829: This epoch took 15.690055 s\n",
      "\n",
      "2022-11-27 19:05:02.352860: \n",
      "epoch:  165\n",
      "2022-11-27 19:05:16.592923: train loss : -0.9034\n",
      "2022-11-27 19:05:17.585333: validation loss: -0.8420\n",
      "2022-11-27 19:05:17.585710: Average global foreground Dice: [0.8935, 0.8756]\n",
      "2022-11-27 19:05:17.585768: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:05:17.926882: lr: 0.008493\n",
      "2022-11-27 19:05:17.926986: This epoch took 15.574090 s\n",
      "\n",
      "2022-11-27 19:05:17.927014: \n",
      "epoch:  166\n",
      "2022-11-27 19:05:32.205240: train loss : -0.9035\n",
      "2022-11-27 19:05:33.213734: validation loss: -0.8432\n",
      "2022-11-27 19:05:33.214151: Average global foreground Dice: [0.893, 0.8773]\n",
      "2022-11-27 19:05:33.214228: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:05:33.668709: lr: 0.008484\n",
      "2022-11-27 19:05:33.668817: This epoch took 15.741777 s\n",
      "\n",
      "2022-11-27 19:05:33.668848: \n",
      "epoch:  167\n",
      "2022-11-27 19:05:47.928059: train loss : -0.9033\n",
      "2022-11-27 19:05:48.938438: validation loss: -0.8473\n",
      "2022-11-27 19:05:48.938760: Average global foreground Dice: [0.8975, 0.8779]\n",
      "2022-11-27 19:05:48.938817: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:05:49.287356: lr: 0.008474\n",
      "2022-11-27 19:05:49.287465: This epoch took 15.618590 s\n",
      "\n",
      "2022-11-27 19:05:49.287492: \n",
      "epoch:  168\n",
      "2022-11-27 19:06:03.559315: train loss : -0.9028\n",
      "2022-11-27 19:06:04.565075: validation loss: -0.8503\n",
      "2022-11-27 19:06:04.565445: Average global foreground Dice: [0.8986, 0.8808]\n",
      "2022-11-27 19:06:04.565504: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:06:04.924906: lr: 0.008465\n",
      "2022-11-27 19:06:04.925034: This epoch took 15.637485 s\n",
      "\n",
      "2022-11-27 19:06:04.925064: \n",
      "epoch:  169\n",
      "2022-11-27 19:06:19.152596: train loss : -0.9048\n",
      "2022-11-27 19:06:20.170333: validation loss: -0.8434\n",
      "2022-11-27 19:06:20.170765: Average global foreground Dice: [0.8938, 0.8768]\n",
      "2022-11-27 19:06:20.170842: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:06:20.517747: lr: 0.008456\n",
      "2022-11-27 19:06:20.517872: This epoch took 15.592767 s\n",
      "\n",
      "2022-11-27 19:06:20.517913: \n",
      "epoch:  170\n",
      "2022-11-27 19:06:34.754934: train loss : -0.9033\n",
      "2022-11-27 19:06:35.750049: validation loss: -0.8399\n",
      "2022-11-27 19:06:35.750427: Average global foreground Dice: [0.8909, 0.8741]\n",
      "2022-11-27 19:06:35.750486: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:06:36.096898: lr: 0.008447\n",
      "2022-11-27 19:06:36.097005: This epoch took 15.579063 s\n",
      "\n",
      "2022-11-27 19:06:36.097034: \n",
      "epoch:  171\n",
      "2022-11-27 19:06:50.359206: train loss : -0.9025\n",
      "2022-11-27 19:06:51.366491: validation loss: -0.8421\n",
      "2022-11-27 19:06:51.366866: Average global foreground Dice: [0.8928, 0.8775]\n",
      "2022-11-27 19:06:51.366926: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:06:51.727155: lr: 0.008438\n",
      "2022-11-27 19:06:51.727264: This epoch took 15.630203 s\n",
      "\n",
      "2022-11-27 19:06:51.727314: \n",
      "epoch:  172\n",
      "2022-11-27 19:07:05.975083: train loss : -0.9047\n",
      "2022-11-27 19:07:06.959908: validation loss: -0.8439\n",
      "2022-11-27 19:07:06.960248: Average global foreground Dice: [0.8945, 0.8764]\n",
      "2022-11-27 19:07:06.960312: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:07:07.309151: lr: 0.008429\n",
      "2022-11-27 19:07:07.309268: This epoch took 15.581908 s\n",
      "\n",
      "2022-11-27 19:07:07.309298: \n",
      "epoch:  173\n",
      "2022-11-27 19:07:21.575848: train loss : -0.9047\n",
      "2022-11-27 19:07:22.571437: validation loss: -0.8441\n",
      "2022-11-27 19:07:22.571816: Average global foreground Dice: [0.8932, 0.8793]\n",
      "2022-11-27 19:07:22.571872: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:07:22.917107: lr: 0.008419\n",
      "2022-11-27 19:07:22.917238: This epoch took 15.607898 s\n",
      "\n",
      "2022-11-27 19:07:22.917269: \n",
      "epoch:  174\n",
      "2022-11-27 19:07:37.184857: train loss : -0.9043\n",
      "2022-11-27 19:07:38.191447: validation loss: -0.8449\n",
      "2022-11-27 19:07:38.191832: Average global foreground Dice: [0.8935, 0.8779]\n",
      "2022-11-27 19:07:38.191893: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:07:38.536894: lr: 0.00841\n",
      "2022-11-27 19:07:38.537003: This epoch took 15.619707 s\n",
      "\n",
      "2022-11-27 19:07:38.537032: \n",
      "epoch:  175\n",
      "2022-11-27 19:07:52.850707: train loss : -0.9050\n",
      "2022-11-27 19:07:53.843974: validation loss: -0.8394\n",
      "2022-11-27 19:07:53.844360: Average global foreground Dice: [0.8914, 0.8737]\n",
      "2022-11-27 19:07:53.844418: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:07:54.188676: lr: 0.008401\n",
      "2022-11-27 19:07:54.188779: This epoch took 15.651721 s\n",
      "\n",
      "2022-11-27 19:07:54.188809: \n",
      "epoch:  176\n",
      "2022-11-27 19:08:08.425455: train loss : -0.9051\n",
      "2022-11-27 19:08:09.417996: validation loss: -0.8422\n",
      "2022-11-27 19:08:09.418460: Average global foreground Dice: [0.8933, 0.8764]\n",
      "2022-11-27 19:08:09.418534: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 19:08:09.883680: lr: 0.008392\n",
      "2022-11-27 19:08:09.883800: This epoch took 15.694944 s\n",
      "\n",
      "2022-11-27 19:08:09.883831: \n",
      "epoch:  177\n",
      "2022-11-27 19:08:24.126325: train loss : -0.9033\n",
      "2022-11-27 19:08:25.134546: validation loss: -0.8485\n",
      "2022-11-27 19:08:25.134918: Average global foreground Dice: [0.8988, 0.88]\n",
      "2022-11-27 19:08:25.134978: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:08:25.485323: lr: 0.008383\n",
      "2022-11-27 19:08:25.485438: This epoch took 15.601580 s\n",
      "\n",
      "2022-11-27 19:08:25.485478: \n",
      "epoch:  178\n",
      "2022-11-27 19:08:39.719319: train loss : -0.9056\n",
      "2022-11-27 19:08:40.735883: validation loss: -0.8468\n",
      "2022-11-27 19:08:40.736255: Average global foreground Dice: [0.8958, 0.8794]\n",
      "2022-11-27 19:08:40.736311: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:08:41.087761: lr: 0.008374\n",
      "2022-11-27 19:08:41.087869: This epoch took 15.602364 s\n",
      "\n",
      "2022-11-27 19:08:41.087915: \n",
      "epoch:  179\n",
      "2022-11-27 19:08:55.445373: train loss : -0.9061\n",
      "2022-11-27 19:08:56.469384: validation loss: -0.8453\n",
      "2022-11-27 19:08:56.469916: Average global foreground Dice: [0.8957, 0.8767]\n",
      "2022-11-27 19:08:56.470017: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:08:56.854018: lr: 0.008364\n",
      "2022-11-27 19:08:56.854128: This epoch took 15.766187 s\n",
      "\n",
      "2022-11-27 19:08:56.854158: \n",
      "epoch:  180\n",
      "2022-11-27 19:09:11.140531: train loss : -0.9051\n",
      "2022-11-27 19:09:12.165863: validation loss: -0.8407\n",
      "2022-11-27 19:09:12.166206: Average global foreground Dice: [0.8917, 0.8747]\n",
      "2022-11-27 19:09:12.166478: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:09:12.532560: lr: 0.008355\n",
      "2022-11-27 19:09:12.532665: This epoch took 15.678481 s\n",
      "\n",
      "2022-11-27 19:09:12.532694: \n",
      "epoch:  181\n",
      "2022-11-27 19:09:26.799577: train loss : -0.9045\n",
      "2022-11-27 19:09:27.775803: validation loss: -0.8480\n",
      "2022-11-27 19:09:27.776140: Average global foreground Dice: [0.8962, 0.8806]\n",
      "2022-11-27 19:09:27.776198: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:09:28.122996: lr: 0.008346\n",
      "2022-11-27 19:09:28.123103: This epoch took 15.590383 s\n",
      "\n",
      "2022-11-27 19:09:28.123132: \n",
      "epoch:  182\n",
      "2022-11-27 19:09:42.369238: train loss : -0.9046\n",
      "2022-11-27 19:09:43.378426: validation loss: -0.8387\n",
      "2022-11-27 19:09:43.378824: Average global foreground Dice: [0.8917, 0.8748]\n",
      "2022-11-27 19:09:43.378880: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:09:43.730587: lr: 0.008337\n",
      "2022-11-27 19:09:43.730694: This epoch took 15.607535 s\n",
      "\n",
      "2022-11-27 19:09:43.730725: \n",
      "epoch:  183\n",
      "2022-11-27 19:09:58.040367: train loss : -0.9050\n",
      "2022-11-27 19:09:59.029720: validation loss: -0.8411\n",
      "2022-11-27 19:09:59.030105: Average global foreground Dice: [0.8923, 0.8755]\n",
      "2022-11-27 19:09:59.030211: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:09:59.406306: lr: 0.008328\n",
      "2022-11-27 19:09:59.406413: This epoch took 15.675661 s\n",
      "\n",
      "2022-11-27 19:09:59.406441: \n",
      "epoch:  184\n",
      "2022-11-27 19:10:13.650518: train loss : -0.9059\n",
      "2022-11-27 19:10:14.652814: validation loss: -0.8433\n",
      "2022-11-27 19:10:14.653218: Average global foreground Dice: [0.8959, 0.877]\n",
      "2022-11-27 19:10:14.653302: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:10:15.000904: lr: 0.008318\n",
      "2022-11-27 19:10:15.001010: This epoch took 15.594542 s\n",
      "\n",
      "2022-11-27 19:10:15.001039: \n",
      "epoch:  185\n",
      "2022-11-27 19:10:29.235640: train loss : -0.9056\n",
      "2022-11-27 19:10:30.275069: validation loss: -0.8419\n",
      "2022-11-27 19:10:30.275463: Average global foreground Dice: [0.894, 0.8736]\n",
      "2022-11-27 19:10:30.275522: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:10:30.619920: lr: 0.008309\n",
      "2022-11-27 19:10:30.620031: This epoch took 15.618966 s\n",
      "\n",
      "2022-11-27 19:10:30.620063: \n",
      "epoch:  186\n",
      "2022-11-27 19:10:44.875315: train loss : -0.9043\n",
      "2022-11-27 19:10:45.899900: validation loss: -0.8475\n",
      "2022-11-27 19:10:45.900236: Average global foreground Dice: [0.897, 0.8793]\n",
      "2022-11-27 19:10:45.900289: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:10:46.358285: lr: 0.0083\n",
      "2022-11-27 19:10:46.358398: This epoch took 15.738309 s\n",
      "\n",
      "2022-11-27 19:10:46.358427: \n",
      "epoch:  187\n",
      "2022-11-27 19:11:00.648909: train loss : -0.9053\n",
      "2022-11-27 19:11:01.647462: validation loss: -0.8457\n",
      "2022-11-27 19:11:01.647913: Average global foreground Dice: [0.8943, 0.8782]\n",
      "2022-11-27 19:11:01.648074: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:11:02.017850: lr: 0.008291\n",
      "2022-11-27 19:11:02.017970: This epoch took 15.659517 s\n",
      "\n",
      "2022-11-27 19:11:02.018020: \n",
      "epoch:  188\n",
      "2022-11-27 19:11:16.325808: train loss : -0.9055\n",
      "2022-11-27 19:11:17.346722: validation loss: -0.8495\n",
      "2022-11-27 19:11:17.347104: Average global foreground Dice: [0.8989, 0.8829]\n",
      "2022-11-27 19:11:17.347258: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:11:17.695904: lr: 0.008282\n",
      "2022-11-27 19:11:17.696013: This epoch took 15.677964 s\n",
      "\n",
      "2022-11-27 19:11:17.696056: \n",
      "epoch:  189\n",
      "2022-11-27 19:11:31.961173: train loss : -0.9060\n",
      "2022-11-27 19:11:32.959496: validation loss: -0.8468\n",
      "2022-11-27 19:11:32.959869: Average global foreground Dice: [0.8952, 0.8784]\n",
      "2022-11-27 19:11:32.959929: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:11:33.309931: lr: 0.008272\n",
      "2022-11-27 19:11:33.310061: This epoch took 15.613973 s\n",
      "\n",
      "2022-11-27 19:11:33.310090: \n",
      "epoch:  190\n",
      "2022-11-27 19:11:47.531158: train loss : -0.9045\n",
      "2022-11-27 19:11:48.550998: validation loss: -0.8438\n",
      "2022-11-27 19:11:48.551317: Average global foreground Dice: [0.8935, 0.878]\n",
      "2022-11-27 19:11:48.551369: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:11:48.897113: lr: 0.008263\n",
      "2022-11-27 19:11:48.897220: This epoch took 15.587104 s\n",
      "\n",
      "2022-11-27 19:11:48.897253: \n",
      "epoch:  191\n",
      "2022-11-27 19:12:03.103343: train loss : -0.9059\n",
      "2022-11-27 19:12:04.114170: validation loss: -0.8477\n",
      "2022-11-27 19:12:04.114558: Average global foreground Dice: [0.896, 0.8808]\n",
      "2022-11-27 19:12:04.114627: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:12:04.461746: lr: 0.008254\n",
      "2022-11-27 19:12:04.461860: This epoch took 15.564580 s\n",
      "\n",
      "2022-11-27 19:12:04.461888: \n",
      "epoch:  192\n",
      "2022-11-27 19:12:18.648661: train loss : -0.9059\n",
      "2022-11-27 19:12:19.642587: validation loss: -0.8392\n",
      "2022-11-27 19:12:19.642963: Average global foreground Dice: [0.8916, 0.8746]\n",
      "2022-11-27 19:12:19.643021: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:12:19.989097: lr: 0.008245\n",
      "2022-11-27 19:12:19.989209: This epoch took 15.527287 s\n",
      "\n",
      "2022-11-27 19:12:19.989238: \n",
      "epoch:  193\n",
      "2022-11-27 19:12:34.216480: train loss : -0.9059\n",
      "2022-11-27 19:12:35.193613: validation loss: -0.8410\n",
      "2022-11-27 19:12:35.194079: Average global foreground Dice: [0.8933, 0.8738]\n",
      "2022-11-27 19:12:35.194197: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:12:35.548394: lr: 0.008236\n",
      "2022-11-27 19:12:35.548499: This epoch took 15.559235 s\n",
      "\n",
      "2022-11-27 19:12:35.548527: \n",
      "epoch:  194\n",
      "2022-11-27 19:12:49.852856: train loss : -0.9060\n",
      "2022-11-27 19:12:50.877233: validation loss: -0.8457\n",
      "2022-11-27 19:12:50.877612: Average global foreground Dice: [0.8958, 0.8791]\n",
      "2022-11-27 19:12:50.877666: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:12:51.227309: lr: 0.008227\n",
      "2022-11-27 19:12:51.227413: This epoch took 15.678860 s\n",
      "\n",
      "2022-11-27 19:12:51.227442: \n",
      "epoch:  195\n",
      "2022-11-27 19:13:05.462798: train loss : -0.9052\n",
      "2022-11-27 19:13:06.527461: validation loss: -0.8437\n",
      "2022-11-27 19:13:06.527810: Average global foreground Dice: [0.8944, 0.8766]\n",
      "2022-11-27 19:13:06.527866: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 19:13:06.872408: lr: 0.008217\n",
      "2022-11-27 19:13:06.872516: This epoch took 15.645048 s\n",
      "\n",
      "2022-11-27 19:13:06.872549: \n",
      "epoch:  196\n",
      "2022-11-27 19:13:21.148610: train loss : -0.9054\n",
      "2022-11-27 19:13:22.161943: validation loss: -0.8437\n",
      "2022-11-27 19:13:22.162331: Average global foreground Dice: [0.896, 0.8752]\n",
      "2022-11-27 19:13:22.162459: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:13:22.629822: lr: 0.008208\n",
      "2022-11-27 19:13:22.629940: This epoch took 15.757359 s\n",
      "\n",
      "2022-11-27 19:13:22.629971: \n",
      "epoch:  197\n",
      "2022-11-27 19:13:36.904049: train loss : -0.9061\n",
      "2022-11-27 19:13:37.882270: validation loss: -0.8478\n",
      "2022-11-27 19:13:37.882601: Average global foreground Dice: [0.8967, 0.8786]\n",
      "2022-11-27 19:13:37.882658: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:13:38.231305: lr: 0.008199\n",
      "2022-11-27 19:13:38.231415: This epoch took 15.601417 s\n",
      "\n",
      "2022-11-27 19:13:38.231447: \n",
      "epoch:  198\n",
      "2022-11-27 19:13:52.427271: train loss : -0.9053\n",
      "2022-11-27 19:13:53.433002: validation loss: -0.8463\n",
      "2022-11-27 19:13:53.433347: Average global foreground Dice: [0.8979, 0.8781]\n",
      "2022-11-27 19:13:53.433402: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:13:53.781048: lr: 0.00819\n",
      "2022-11-27 19:13:53.781156: This epoch took 15.549683 s\n",
      "\n",
      "2022-11-27 19:13:53.781189: \n",
      "epoch:  199\n",
      "2022-11-27 19:14:07.981535: train loss : -0.9051\n",
      "2022-11-27 19:14:09.004458: validation loss: -0.8442\n",
      "2022-11-27 19:14:09.004841: Average global foreground Dice: [0.8963, 0.8779]\n",
      "2022-11-27 19:14:09.004898: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:14:09.368215: lr: 0.008181\n",
      "2022-11-27 19:14:09.368313: saving scheduled checkpoint file...\n",
      "2022-11-27 19:14:09.372399: saving checkpoint...\n",
      "2022-11-27 19:14:09.431886: done, saving took 0.06 seconds\n",
      "2022-11-27 19:14:09.433796: done\n",
      "2022-11-27 19:14:09.433877: This epoch took 15.652644 s\n",
      "\n",
      "2022-11-27 19:14:09.433912: \n",
      "epoch:  200\n",
      "2022-11-27 19:14:23.746054: train loss : -0.9060\n",
      "2022-11-27 19:14:24.801387: validation loss: -0.8411\n",
      "2022-11-27 19:14:24.801836: Average global foreground Dice: [0.893, 0.8754]\n",
      "2022-11-27 19:14:24.802146: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:14:25.151076: lr: 0.008171\n",
      "2022-11-27 19:14:25.151178: This epoch took 15.717239 s\n",
      "\n",
      "2022-11-27 19:14:25.151206: \n",
      "epoch:  201\n",
      "2022-11-27 19:14:39.389839: train loss : -0.9062\n",
      "2022-11-27 19:14:40.378243: validation loss: -0.8388\n",
      "2022-11-27 19:14:40.378650: Average global foreground Dice: [0.8917, 0.8717]\n",
      "2022-11-27 19:14:40.378724: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:14:40.740619: lr: 0.008162\n",
      "2022-11-27 19:14:40.740724: This epoch took 15.589492 s\n",
      "\n",
      "2022-11-27 19:14:40.740752: \n",
      "epoch:  202\n",
      "2022-11-27 19:14:55.003653: train loss : -0.9061\n",
      "2022-11-27 19:14:55.996170: validation loss: -0.8507\n",
      "2022-11-27 19:14:55.996498: Average global foreground Dice: [0.8994, 0.8809]\n",
      "2022-11-27 19:14:55.996552: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:14:56.356811: lr: 0.008153\n",
      "2022-11-27 19:14:56.356925: This epoch took 15.616131 s\n",
      "\n",
      "2022-11-27 19:14:56.356957: \n",
      "epoch:  203\n",
      "2022-11-27 19:15:10.611927: train loss : -0.9088\n",
      "2022-11-27 19:15:11.629114: validation loss: -0.8402\n",
      "2022-11-27 19:15:11.629494: Average global foreground Dice: [0.8924, 0.8728]\n",
      "2022-11-27 19:15:11.629549: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:15:11.976070: lr: 0.008144\n",
      "2022-11-27 19:15:11.976175: This epoch took 15.619192 s\n",
      "\n",
      "2022-11-27 19:15:11.976203: \n",
      "epoch:  204\n",
      "2022-11-27 19:15:26.164632: train loss : -0.9064\n",
      "2022-11-27 19:15:27.170303: validation loss: -0.8452\n",
      "2022-11-27 19:15:27.170663: Average global foreground Dice: [0.8966, 0.8762]\n",
      "2022-11-27 19:15:27.170742: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:15:27.518317: lr: 0.008134\n",
      "2022-11-27 19:15:27.518423: This epoch took 15.542188 s\n",
      "\n",
      "2022-11-27 19:15:27.518453: \n",
      "epoch:  205\n",
      "2022-11-27 19:15:41.806042: train loss : -0.9067\n",
      "2022-11-27 19:15:42.836218: validation loss: -0.8481\n",
      "2022-11-27 19:15:42.836585: Average global foreground Dice: [0.8978, 0.8803]\n",
      "2022-11-27 19:15:42.836660: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:15:43.186936: lr: 0.008125\n",
      "2022-11-27 19:15:43.187040: This epoch took 15.668561 s\n",
      "\n",
      "2022-11-27 19:15:43.187069: \n",
      "epoch:  206\n",
      "2022-11-27 19:15:57.442438: train loss : -0.9063\n",
      "2022-11-27 19:15:58.425742: validation loss: -0.8454\n",
      "2022-11-27 19:15:58.426091: Average global foreground Dice: [0.8935, 0.8791]\n",
      "2022-11-27 19:15:58.426148: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:15:58.882734: lr: 0.008116\n",
      "2022-11-27 19:15:58.882842: This epoch took 15.695747 s\n",
      "\n",
      "2022-11-27 19:15:58.882872: \n",
      "epoch:  207\n",
      "2022-11-27 19:16:13.138172: train loss : -0.9071\n",
      "2022-11-27 19:16:14.123875: validation loss: -0.8449\n",
      "2022-11-27 19:16:14.124431: Average global foreground Dice: [0.8971, 0.8783]\n",
      "2022-11-27 19:16:14.124549: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:16:14.506510: lr: 0.008107\n",
      "2022-11-27 19:16:14.506621: This epoch took 15.623721 s\n",
      "\n",
      "2022-11-27 19:16:14.506649: \n",
      "epoch:  208\n",
      "2022-11-27 19:16:28.772032: train loss : -0.9062\n",
      "2022-11-27 19:16:29.762406: validation loss: -0.8489\n",
      "2022-11-27 19:16:29.762788: Average global foreground Dice: [0.899, 0.8792]\n",
      "2022-11-27 19:16:29.762843: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:16:30.107167: lr: 0.008098\n",
      "2022-11-27 19:16:30.107272: This epoch took 15.600596 s\n",
      "\n",
      "2022-11-27 19:16:30.107298: \n",
      "epoch:  209\n",
      "2022-11-27 19:16:44.389789: train loss : -0.9063\n",
      "2022-11-27 19:16:45.431010: validation loss: -0.8453\n",
      "2022-11-27 19:16:45.431357: Average global foreground Dice: [0.8944, 0.8784]\n",
      "2022-11-27 19:16:45.431413: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:16:45.795835: lr: 0.008088\n",
      "2022-11-27 19:16:45.795949: This epoch took 15.688604 s\n",
      "\n",
      "2022-11-27 19:16:45.795982: \n",
      "epoch:  210\n",
      "2022-11-27 19:17:00.095158: train loss : -0.9061\n",
      "2022-11-27 19:17:01.091466: validation loss: -0.8413\n",
      "2022-11-27 19:17:01.091918: Average global foreground Dice: [0.8924, 0.8763]\n",
      "2022-11-27 19:17:01.091989: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:17:01.447696: lr: 0.008079\n",
      "2022-11-27 19:17:01.447804: This epoch took 15.651792 s\n",
      "\n",
      "2022-11-27 19:17:01.447830: \n",
      "epoch:  211\n",
      "2022-11-27 19:17:15.741053: train loss : -0.9066\n",
      "2022-11-27 19:17:16.740843: validation loss: -0.8422\n",
      "2022-11-27 19:17:16.741180: Average global foreground Dice: [0.893, 0.8755]\n",
      "2022-11-27 19:17:16.741235: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:17:17.112306: lr: 0.00807\n",
      "2022-11-27 19:17:17.112414: This epoch took 15.664559 s\n",
      "\n",
      "2022-11-27 19:17:17.112444: \n",
      "epoch:  212\n",
      "2022-11-27 19:17:31.356845: train loss : -0.9080\n",
      "2022-11-27 19:17:32.346386: validation loss: -0.8479\n",
      "2022-11-27 19:17:32.346721: Average global foreground Dice: [0.8979, 0.8805]\n",
      "2022-11-27 19:17:32.346782: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:17:32.686687: lr: 0.008061\n",
      "2022-11-27 19:17:32.686794: This epoch took 15.574317 s\n",
      "\n",
      "2022-11-27 19:17:32.686822: \n",
      "epoch:  213\n",
      "2022-11-27 19:17:46.952487: train loss : -0.9083\n",
      "2022-11-27 19:17:47.967293: validation loss: -0.8410\n",
      "2022-11-27 19:17:47.967632: Average global foreground Dice: [0.8925, 0.8771]\n",
      "2022-11-27 19:17:47.967688: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:17:48.307448: lr: 0.008052\n",
      "2022-11-27 19:17:48.307553: This epoch took 15.620705 s\n",
      "\n",
      "2022-11-27 19:17:48.307581: \n",
      "epoch:  214\n",
      "2022-11-27 19:18:02.585915: train loss : -0.9090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 19:18:03.595356: validation loss: -0.8419\n",
      "2022-11-27 19:18:03.595686: Average global foreground Dice: [0.8942, 0.8754]\n",
      "2022-11-27 19:18:03.595743: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:18:03.940629: lr: 0.008042\n",
      "2022-11-27 19:18:03.940840: This epoch took 15.633231 s\n",
      "\n",
      "2022-11-27 19:18:03.940873: \n",
      "epoch:  215\n",
      "2022-11-27 19:18:18.247943: train loss : -0.9094\n",
      "2022-11-27 19:18:19.248564: validation loss: -0.8502\n",
      "2022-11-27 19:18:19.248901: Average global foreground Dice: [0.8996, 0.8821]\n",
      "2022-11-27 19:18:19.248959: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:18:19.589821: lr: 0.008033\n",
      "2022-11-27 19:18:19.589929: This epoch took 15.649024 s\n",
      "\n",
      "2022-11-27 19:18:19.589960: \n",
      "epoch:  216\n",
      "2022-11-27 19:18:33.832843: train loss : -0.9085\n",
      "2022-11-27 19:18:34.842271: validation loss: -0.8482\n",
      "2022-11-27 19:18:34.842835: Average global foreground Dice: [0.8971, 0.8813]\n",
      "2022-11-27 19:18:34.842958: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:18:35.195506: lr: 0.008024\n",
      "2022-11-27 19:18:35.195613: This epoch took 15.605628 s\n",
      "\n",
      "2022-11-27 19:18:35.195642: \n",
      "epoch:  217\n",
      "2022-11-27 19:18:49.488597: train loss : -0.9070\n",
      "2022-11-27 19:18:50.490676: validation loss: -0.8428\n",
      "2022-11-27 19:18:50.491006: Average global foreground Dice: [0.8928, 0.8796]\n",
      "2022-11-27 19:18:50.491061: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:18:50.970901: lr: 0.008015\n",
      "2022-11-27 19:18:50.971014: This epoch took 15.775345 s\n",
      "\n",
      "2022-11-27 19:18:50.971044: \n",
      "epoch:  218\n",
      "2022-11-27 19:19:05.270507: train loss : -0.9073\n",
      "2022-11-27 19:19:06.259190: validation loss: -0.8415\n",
      "2022-11-27 19:19:06.259521: Average global foreground Dice: [0.8926, 0.8766]\n",
      "2022-11-27 19:19:06.259576: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:19:06.618372: lr: 0.008005\n",
      "2022-11-27 19:19:06.618478: This epoch took 15.647408 s\n",
      "\n",
      "2022-11-27 19:19:06.618505: \n",
      "epoch:  219\n",
      "2022-11-27 19:19:20.890815: train loss : -0.9074\n",
      "2022-11-27 19:19:21.906597: validation loss: -0.8459\n",
      "2022-11-27 19:19:21.906931: Average global foreground Dice: [0.8949, 0.8787]\n",
      "2022-11-27 19:19:21.906991: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:19:22.253312: lr: 0.007996\n",
      "2022-11-27 19:19:22.253431: This epoch took 15.634883 s\n",
      "\n",
      "2022-11-27 19:19:22.253461: \n",
      "epoch:  220\n",
      "2022-11-27 19:19:36.537656: train loss : -0.9077\n",
      "2022-11-27 19:19:37.526044: validation loss: -0.8391\n",
      "2022-11-27 19:19:37.526484: Average global foreground Dice: [0.8926, 0.8744]\n",
      "2022-11-27 19:19:37.526555: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:19:37.899905: lr: 0.007987\n",
      "2022-11-27 19:19:37.900027: This epoch took 15.646523 s\n",
      "\n",
      "2022-11-27 19:19:37.900060: \n",
      "epoch:  221\n",
      "2022-11-27 19:19:52.213582: train loss : -0.9081\n",
      "2022-11-27 19:19:53.210822: validation loss: -0.8455\n",
      "2022-11-27 19:19:53.211203: Average global foreground Dice: [0.8946, 0.8802]\n",
      "2022-11-27 19:19:53.211292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:19:53.556904: lr: 0.007978\n",
      "2022-11-27 19:19:53.557020: This epoch took 15.656918 s\n",
      "\n",
      "2022-11-27 19:19:53.557053: \n",
      "epoch:  222\n",
      "2022-11-27 19:20:07.784176: train loss : -0.9099\n",
      "2022-11-27 19:20:08.795570: validation loss: -0.8413\n",
      "2022-11-27 19:20:08.795903: Average global foreground Dice: [0.8921, 0.8772]\n",
      "2022-11-27 19:20:08.796200: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:20:09.153901: lr: 0.007969\n",
      "2022-11-27 19:20:09.154003: This epoch took 15.596925 s\n",
      "\n",
      "2022-11-27 19:20:09.154034: \n",
      "epoch:  223\n",
      "2022-11-27 19:20:23.407177: train loss : -0.9074\n",
      "2022-11-27 19:20:24.404523: validation loss: -0.8420\n",
      "2022-11-27 19:20:24.404856: Average global foreground Dice: [0.8933, 0.8783]\n",
      "2022-11-27 19:20:24.404911: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:20:24.751822: lr: 0.007959\n",
      "2022-11-27 19:20:24.751928: This epoch took 15.597867 s\n",
      "\n",
      "2022-11-27 19:20:24.751957: \n",
      "epoch:  224\n",
      "2022-11-27 19:20:39.003253: train loss : -0.9076\n",
      "2022-11-27 19:20:39.995271: validation loss: -0.8466\n",
      "2022-11-27 19:20:39.995609: Average global foreground Dice: [0.8968, 0.8808]\n",
      "2022-11-27 19:20:39.995662: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:20:40.348315: lr: 0.00795\n",
      "2022-11-27 19:20:40.348424: This epoch took 15.596441 s\n",
      "\n",
      "2022-11-27 19:20:40.348453: \n",
      "epoch:  225\n",
      "2022-11-27 19:20:54.682803: train loss : -0.9074\n",
      "2022-11-27 19:20:55.687757: validation loss: -0.8408\n",
      "2022-11-27 19:20:55.688092: Average global foreground Dice: [0.8928, 0.8748]\n",
      "2022-11-27 19:20:55.688150: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:20:56.056036: lr: 0.007941\n",
      "2022-11-27 19:20:56.056139: This epoch took 15.707659 s\n",
      "\n",
      "2022-11-27 19:20:56.056166: \n",
      "epoch:  226\n",
      "2022-11-27 19:21:10.324994: train loss : -0.9066\n",
      "2022-11-27 19:21:11.328449: validation loss: -0.8437\n",
      "2022-11-27 19:21:11.328865: Average global foreground Dice: [0.8955, 0.878]\n",
      "2022-11-27 19:21:11.328938: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:21:11.678237: lr: 0.007932\n",
      "2022-11-27 19:21:11.678344: This epoch took 15.622149 s\n",
      "\n",
      "2022-11-27 19:21:11.678372: \n",
      "epoch:  227\n",
      "2022-11-27 19:21:25.878830: train loss : -0.9077\n",
      "2022-11-27 19:21:26.874277: validation loss: -0.8444\n",
      "2022-11-27 19:21:26.874630: Average global foreground Dice: [0.8957, 0.8762]\n",
      "2022-11-27 19:21:26.874687: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:21:27.248392: lr: 0.007922\n",
      "2022-11-27 19:21:27.248492: This epoch took 15.570093 s\n",
      "\n",
      "2022-11-27 19:21:27.248518: \n",
      "epoch:  228\n",
      "2022-11-27 19:21:41.436460: train loss : -0.9074\n",
      "2022-11-27 19:21:42.434837: validation loss: -0.8428\n",
      "2022-11-27 19:21:42.435174: Average global foreground Dice: [0.8937, 0.8763]\n",
      "2022-11-27 19:21:42.435231: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:21:42.988647: lr: 0.007913\n",
      "2022-11-27 19:21:42.988755: This epoch took 15.740213 s\n",
      "\n",
      "2022-11-27 19:21:42.988781: \n",
      "epoch:  229\n",
      "2022-11-27 19:21:57.230718: train loss : -0.9071\n",
      "2022-11-27 19:21:58.227497: validation loss: -0.8442\n",
      "2022-11-27 19:21:58.227869: Average global foreground Dice: [0.8949, 0.8779]\n",
      "2022-11-27 19:21:58.227928: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:21:58.597912: lr: 0.007904\n",
      "2022-11-27 19:21:58.598110: This epoch took 15.609304 s\n",
      "\n",
      "2022-11-27 19:21:58.598140: \n",
      "epoch:  230\n",
      "2022-11-27 19:22:12.915199: train loss : -0.9085\n",
      "2022-11-27 19:22:13.944011: validation loss: -0.8441\n",
      "2022-11-27 19:22:13.944396: Average global foreground Dice: [0.8952, 0.8763]\n",
      "2022-11-27 19:22:13.944456: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:22:14.292863: lr: 0.007895\n",
      "2022-11-27 19:22:14.292985: This epoch took 15.694804 s\n",
      "\n",
      "2022-11-27 19:22:14.293019: \n",
      "epoch:  231\n",
      "2022-11-27 19:22:28.535425: train loss : -0.9077\n",
      "2022-11-27 19:22:29.587155: validation loss: -0.8454\n",
      "2022-11-27 19:22:29.587580: Average global foreground Dice: [0.897, 0.8782]\n",
      "2022-11-27 19:22:29.587818: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:22:29.938372: lr: 0.007885\n",
      "2022-11-27 19:22:29.938483: This epoch took 15.645437 s\n",
      "\n",
      "2022-11-27 19:22:29.938513: \n",
      "epoch:  232\n",
      "2022-11-27 19:22:44.174381: train loss : -0.9076\n",
      "2022-11-27 19:22:45.168571: validation loss: -0.8430\n",
      "2022-11-27 19:22:45.168940: Average global foreground Dice: [0.8936, 0.8769]\n",
      "2022-11-27 19:22:45.169053: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:22:45.523200: lr: 0.007876\n",
      "2022-11-27 19:22:45.523309: This epoch took 15.584770 s\n",
      "\n",
      "2022-11-27 19:22:45.523337: \n",
      "epoch:  233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 19:22:59.817967: train loss : -0.9100\n",
      "2022-11-27 19:23:00.822928: validation loss: -0.8461\n",
      "2022-11-27 19:23:00.823316: Average global foreground Dice: [0.8974, 0.8794]\n",
      "2022-11-27 19:23:00.823375: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:23:01.171807: lr: 0.007867\n",
      "2022-11-27 19:23:01.171915: This epoch took 15.648551 s\n",
      "\n",
      "2022-11-27 19:23:01.171944: \n",
      "epoch:  234\n",
      "2022-11-27 19:23:15.421565: train loss : -0.9105\n",
      "2022-11-27 19:23:16.429236: validation loss: -0.8438\n",
      "2022-11-27 19:23:16.429611: Average global foreground Dice: [0.8941, 0.8767]\n",
      "2022-11-27 19:23:16.429672: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:23:16.778977: lr: 0.007858\n",
      "2022-11-27 19:23:16.779090: This epoch took 15.607119 s\n",
      "\n",
      "2022-11-27 19:23:16.779120: \n",
      "epoch:  235\n",
      "2022-11-27 19:23:31.031716: train loss : -0.9094\n",
      "2022-11-27 19:23:32.042684: validation loss: -0.8432\n",
      "2022-11-27 19:23:32.043052: Average global foreground Dice: [0.8961, 0.877]\n",
      "2022-11-27 19:23:32.043131: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:23:32.389467: lr: 0.007848\n",
      "2022-11-27 19:23:32.389585: This epoch took 15.610423 s\n",
      "\n",
      "2022-11-27 19:23:32.389620: \n",
      "epoch:  236\n",
      "2022-11-27 19:23:46.668744: train loss : -0.9107\n",
      "2022-11-27 19:23:47.666979: validation loss: -0.8455\n",
      "2022-11-27 19:23:47.667312: Average global foreground Dice: [0.8963, 0.8793]\n",
      "2022-11-27 19:23:47.667365: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:23:48.024717: lr: 0.007839\n",
      "2022-11-27 19:23:48.024819: This epoch took 15.635172 s\n",
      "\n",
      "2022-11-27 19:23:48.024864: \n",
      "epoch:  237\n",
      "2022-11-27 19:24:02.293639: train loss : -0.9080\n",
      "2022-11-27 19:24:03.294508: validation loss: -0.8422\n",
      "2022-11-27 19:24:03.294938: Average global foreground Dice: [0.8906, 0.8775]\n",
      "2022-11-27 19:24:03.295004: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:24:03.643172: lr: 0.00783\n",
      "2022-11-27 19:24:03.643278: This epoch took 15.618388 s\n",
      "\n",
      "2022-11-27 19:24:03.643307: \n",
      "epoch:  238\n",
      "2022-11-27 19:24:17.868921: train loss : -0.9082\n",
      "2022-11-27 19:24:18.879509: validation loss: -0.8439\n",
      "2022-11-27 19:24:18.879982: Average global foreground Dice: [0.8954, 0.8792]\n",
      "2022-11-27 19:24:18.880078: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:24:19.339249: lr: 0.007821\n",
      "2022-11-27 19:24:19.339371: This epoch took 15.696022 s\n",
      "\n",
      "2022-11-27 19:24:19.339402: \n",
      "epoch:  239\n",
      "2022-11-27 19:24:33.630169: train loss : -0.9098\n",
      "2022-11-27 19:24:34.682758: validation loss: -0.8459\n",
      "2022-11-27 19:24:34.683132: Average global foreground Dice: [0.8964, 0.8783]\n",
      "2022-11-27 19:24:34.683186: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:24:35.055677: lr: 0.007811\n",
      "2022-11-27 19:24:35.055792: This epoch took 15.716365 s\n",
      "\n",
      "2022-11-27 19:24:35.055823: \n",
      "epoch:  240\n",
      "2022-11-27 19:24:49.229829: train loss : -0.9100\n",
      "2022-11-27 19:24:50.234329: validation loss: -0.8436\n",
      "2022-11-27 19:24:50.234659: Average global foreground Dice: [0.8945, 0.8774]\n",
      "2022-11-27 19:24:50.234824: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:24:50.578979: lr: 0.007802\n",
      "2022-11-27 19:24:50.579088: This epoch took 15.523239 s\n",
      "\n",
      "2022-11-27 19:24:50.579116: \n",
      "epoch:  241\n",
      "2022-11-27 19:25:04.873674: train loss : -0.9090\n",
      "2022-11-27 19:25:05.871355: validation loss: -0.8439\n",
      "2022-11-27 19:25:05.871709: Average global foreground Dice: [0.8928, 0.8789]\n",
      "2022-11-27 19:25:05.871763: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:25:06.212065: lr: 0.007793\n",
      "2022-11-27 19:25:06.212173: This epoch took 15.633030 s\n",
      "\n",
      "2022-11-27 19:25:06.212203: \n",
      "epoch:  242\n",
      "2022-11-27 19:25:20.513001: train loss : -0.9087\n",
      "2022-11-27 19:25:21.499514: validation loss: -0.8418\n",
      "2022-11-27 19:25:21.500041: Average global foreground Dice: [0.894, 0.8763]\n",
      "2022-11-27 19:25:21.500107: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:25:21.861014: lr: 0.007784\n",
      "2022-11-27 19:25:21.861117: This epoch took 15.648888 s\n",
      "\n",
      "2022-11-27 19:25:21.861145: \n",
      "epoch:  243\n",
      "2022-11-27 19:25:36.110754: train loss : -0.9092\n",
      "2022-11-27 19:25:37.109140: validation loss: -0.8489\n",
      "2022-11-27 19:25:37.109523: Average global foreground Dice: [0.8981, 0.8816]\n",
      "2022-11-27 19:25:37.109582: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:25:37.451825: lr: 0.007774\n",
      "2022-11-27 19:25:37.451949: This epoch took 15.590778 s\n",
      "\n",
      "2022-11-27 19:25:37.451977: \n",
      "epoch:  244\n",
      "2022-11-27 19:25:51.743108: train loss : -0.9099\n",
      "2022-11-27 19:25:52.757022: validation loss: -0.8397\n",
      "2022-11-27 19:25:52.757409: Average global foreground Dice: [0.8924, 0.8769]\n",
      "2022-11-27 19:25:52.757469: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:25:53.104854: lr: 0.007765\n",
      "2022-11-27 19:25:53.104963: This epoch took 15.652959 s\n",
      "\n",
      "2022-11-27 19:25:53.104995: \n",
      "epoch:  245\n",
      "2022-11-27 19:26:07.371351: train loss : -0.9112\n",
      "2022-11-27 19:26:08.366098: validation loss: -0.8467\n",
      "2022-11-27 19:26:08.366626: Average global foreground Dice: [0.8969, 0.8792]\n",
      "2022-11-27 19:26:08.366773: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:26:08.714499: lr: 0.007756\n",
      "2022-11-27 19:26:08.714604: This epoch took 15.609581 s\n",
      "\n",
      "2022-11-27 19:26:08.714633: \n",
      "epoch:  246\n",
      "2022-11-27 19:26:22.968717: train loss : -0.9086\n",
      "2022-11-27 19:26:23.973073: validation loss: -0.8424\n",
      "2022-11-27 19:26:23.973490: Average global foreground Dice: [0.8938, 0.8762]\n",
      "2022-11-27 19:26:23.973707: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:26:24.323776: lr: 0.007747\n",
      "2022-11-27 19:26:24.323882: This epoch took 15.609219 s\n",
      "\n",
      "2022-11-27 19:26:24.323911: \n",
      "epoch:  247\n",
      "2022-11-27 19:26:38.561436: train loss : -0.9102\n",
      "2022-11-27 19:26:39.558876: validation loss: -0.8429\n",
      "2022-11-27 19:26:39.559301: Average global foreground Dice: [0.8946, 0.8776]\n",
      "2022-11-27 19:26:39.559481: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:26:39.903031: lr: 0.007737\n",
      "2022-11-27 19:26:39.903141: This epoch took 15.579203 s\n",
      "\n",
      "2022-11-27 19:26:39.903186: \n",
      "epoch:  248\n",
      "2022-11-27 19:26:54.183935: train loss : -0.9094\n",
      "2022-11-27 19:26:55.176495: validation loss: -0.8446\n",
      "2022-11-27 19:26:55.176831: Average global foreground Dice: [0.8949, 0.8776]\n",
      "2022-11-27 19:26:55.176887: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:26:55.525840: lr: 0.007728\n",
      "2022-11-27 19:26:55.525952: This epoch took 15.622739 s\n",
      "\n",
      "2022-11-27 19:26:55.525982: \n",
      "epoch:  249\n",
      "2022-11-27 19:27:09.786144: train loss : -0.9094\n",
      "2022-11-27 19:27:10.793494: validation loss: -0.8434\n",
      "2022-11-27 19:27:10.793832: Average global foreground Dice: [0.895, 0.8772]\n",
      "2022-11-27 19:27:10.793893: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:27:11.279530: lr: 0.007719\n",
      "2022-11-27 19:27:11.279625: saving scheduled checkpoint file...\n",
      "2022-11-27 19:27:11.283550: saving checkpoint...\n",
      "2022-11-27 19:27:11.346546: done, saving took 0.07 seconds\n",
      "2022-11-27 19:27:11.353010: done\n",
      "2022-11-27 19:27:11.353187: This epoch took 15.827175 s\n",
      "\n",
      "2022-11-27 19:27:11.353279: \n",
      "epoch:  250\n",
      "2022-11-27 19:27:25.644319: train loss : -0.9102\n",
      "2022-11-27 19:27:26.652621: validation loss: -0.8398\n",
      "2022-11-27 19:27:26.653007: Average global foreground Dice: [0.8923, 0.8749]\n",
      "2022-11-27 19:27:26.653067: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:27:27.022501: lr: 0.00771\n",
      "2022-11-27 19:27:27.022627: This epoch took 15.669248 s\n",
      "\n",
      "2022-11-27 19:27:27.022658: \n",
      "epoch:  251\n",
      "2022-11-27 19:27:41.336344: train loss : -0.9101\n",
      "2022-11-27 19:27:42.327786: validation loss: -0.8491\n",
      "2022-11-27 19:27:42.328151: Average global foreground Dice: [0.8982, 0.8805]\n",
      "2022-11-27 19:27:42.328231: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 19:27:42.680158: lr: 0.0077\n",
      "2022-11-27 19:27:42.680276: This epoch took 15.657592 s\n",
      "\n",
      "2022-11-27 19:27:42.680305: \n",
      "epoch:  252\n",
      "2022-11-27 19:27:56.901220: train loss : -0.9105\n",
      "2022-11-27 19:27:57.892714: validation loss: -0.8427\n",
      "2022-11-27 19:27:57.893083: Average global foreground Dice: [0.8935, 0.8786]\n",
      "2022-11-27 19:27:57.893160: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:27:58.249969: lr: 0.007691\n",
      "2022-11-27 19:27:58.250079: This epoch took 15.569748 s\n",
      "\n",
      "2022-11-27 19:27:58.250107: \n",
      "epoch:  253\n",
      "2022-11-27 19:28:12.494392: train loss : -0.9101\n",
      "2022-11-27 19:28:13.481062: validation loss: -0.8404\n",
      "2022-11-27 19:28:13.481444: Average global foreground Dice: [0.8941, 0.8738]\n",
      "2022-11-27 19:28:13.481505: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:28:13.834014: lr: 0.007682\n",
      "2022-11-27 19:28:13.834128: This epoch took 15.583993 s\n",
      "\n",
      "2022-11-27 19:28:13.834158: \n",
      "epoch:  254\n",
      "2022-11-27 19:28:28.097448: train loss : -0.9111\n",
      "2022-11-27 19:28:29.095621: validation loss: -0.8442\n",
      "2022-11-27 19:28:29.095951: Average global foreground Dice: [0.8946, 0.8779]\n",
      "2022-11-27 19:28:29.096004: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:28:29.485276: lr: 0.007673\n",
      "2022-11-27 19:28:29.485400: This epoch took 15.651215 s\n",
      "\n",
      "2022-11-27 19:28:29.485434: \n",
      "epoch:  255\n",
      "2022-11-27 19:28:43.849113: train loss : -0.9090\n",
      "2022-11-27 19:28:44.849233: validation loss: -0.8408\n",
      "2022-11-27 19:28:44.849621: Average global foreground Dice: [0.8919, 0.8752]\n",
      "2022-11-27 19:28:44.849682: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:28:45.217679: lr: 0.007663\n",
      "2022-11-27 19:28:45.217797: This epoch took 15.732317 s\n",
      "\n",
      "2022-11-27 19:28:45.217832: \n",
      "epoch:  256\n",
      "2022-11-27 19:28:59.564718: train loss : -0.9106\n",
      "2022-11-27 19:29:00.568979: validation loss: -0.8438\n",
      "2022-11-27 19:29:00.569366: Average global foreground Dice: [0.8953, 0.8765]\n",
      "2022-11-27 19:29:00.569425: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:29:00.919312: lr: 0.007654\n",
      "2022-11-27 19:29:00.919422: This epoch took 15.701563 s\n",
      "\n",
      "2022-11-27 19:29:00.919451: \n",
      "epoch:  257\n",
      "2022-11-27 19:29:15.215118: train loss : -0.9105\n",
      "2022-11-27 19:29:16.236008: validation loss: -0.8381\n",
      "2022-11-27 19:29:16.236392: Average global foreground Dice: [0.8921, 0.8725]\n",
      "2022-11-27 19:29:16.236450: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:29:16.586800: lr: 0.007645\n",
      "2022-11-27 19:29:16.586904: This epoch took 15.667426 s\n",
      "\n",
      "2022-11-27 19:29:16.586934: \n",
      "epoch:  258\n",
      "2022-11-27 19:29:30.800750: train loss : -0.9099\n",
      "2022-11-27 19:29:31.811035: validation loss: -0.8483\n",
      "2022-11-27 19:29:31.811460: Average global foreground Dice: [0.8981, 0.8824]\n",
      "2022-11-27 19:29:31.811548: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:29:32.172857: lr: 0.007635\n",
      "2022-11-27 19:29:32.172958: This epoch took 15.585998 s\n",
      "\n",
      "2022-11-27 19:29:32.173002: \n",
      "epoch:  259\n",
      "2022-11-27 19:29:46.431784: train loss : -0.9114\n",
      "2022-11-27 19:29:47.438316: validation loss: -0.8421\n",
      "2022-11-27 19:29:47.438697: Average global foreground Dice: [0.894, 0.8774]\n",
      "2022-11-27 19:29:47.439095: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:29:47.922944: lr: 0.007626\n",
      "2022-11-27 19:29:47.923057: This epoch took 15.750028 s\n",
      "\n",
      "2022-11-27 19:29:47.923085: \n",
      "epoch:  260\n",
      "2022-11-27 19:30:02.190982: train loss : -0.9106\n",
      "2022-11-27 19:30:03.188602: validation loss: -0.8429\n",
      "2022-11-27 19:30:03.188975: Average global foreground Dice: [0.8936, 0.876]\n",
      "2022-11-27 19:30:03.189033: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:30:03.532129: lr: 0.007617\n",
      "2022-11-27 19:30:03.532245: This epoch took 15.609133 s\n",
      "\n",
      "2022-11-27 19:30:03.532276: \n",
      "epoch:  261\n",
      "2022-11-27 19:30:17.786718: train loss : -0.9117\n",
      "2022-11-27 19:30:18.799369: validation loss: -0.8349\n",
      "2022-11-27 19:30:18.799825: Average global foreground Dice: [0.8897, 0.871]\n",
      "2022-11-27 19:30:18.800026: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:30:19.164181: lr: 0.007608\n",
      "2022-11-27 19:30:19.164293: This epoch took 15.631990 s\n",
      "\n",
      "2022-11-27 19:30:19.164323: \n",
      "epoch:  262\n",
      "2022-11-27 19:30:33.388215: train loss : -0.9113\n",
      "2022-11-27 19:30:34.368810: validation loss: -0.8397\n",
      "2022-11-27 19:30:34.369182: Average global foreground Dice: [0.8909, 0.8757]\n",
      "2022-11-27 19:30:34.369263: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:30:34.713392: lr: 0.007598\n",
      "2022-11-27 19:30:34.713504: This epoch took 15.549155 s\n",
      "\n",
      "2022-11-27 19:30:34.713531: \n",
      "epoch:  263\n",
      "2022-11-27 19:30:48.991497: train loss : -0.9101\n",
      "2022-11-27 19:30:50.033973: validation loss: -0.8406\n",
      "2022-11-27 19:30:50.034302: Average global foreground Dice: [0.8932, 0.8752]\n",
      "2022-11-27 19:30:50.034427: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:30:50.397273: lr: 0.007589\n",
      "2022-11-27 19:30:50.397383: This epoch took 15.683825 s\n",
      "\n",
      "2022-11-27 19:30:50.397423: \n",
      "epoch:  264\n",
      "2022-11-27 19:31:04.674168: train loss : -0.9110\n",
      "2022-11-27 19:31:05.675311: validation loss: -0.8397\n",
      "2022-11-27 19:31:05.675803: Average global foreground Dice: [0.8948, 0.8749]\n",
      "2022-11-27 19:31:05.675987: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:31:06.030881: lr: 0.00758\n",
      "2022-11-27 19:31:06.030988: This epoch took 15.633531 s\n",
      "\n",
      "2022-11-27 19:31:06.031014: \n",
      "epoch:  265\n",
      "2022-11-27 19:31:20.351218: train loss : -0.9106\n",
      "2022-11-27 19:31:21.344057: validation loss: -0.8416\n",
      "2022-11-27 19:31:21.344445: Average global foreground Dice: [0.8914, 0.877]\n",
      "2022-11-27 19:31:21.344503: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:31:21.711051: lr: 0.007571\n",
      "2022-11-27 19:31:21.711161: This epoch took 15.680121 s\n",
      "\n",
      "2022-11-27 19:31:21.711205: \n",
      "epoch:  266\n",
      "2022-11-27 19:31:35.933944: train loss : -0.9095\n",
      "2022-11-27 19:31:36.912829: validation loss: -0.8409\n",
      "2022-11-27 19:31:36.913227: Average global foreground Dice: [0.8918, 0.8781]\n",
      "2022-11-27 19:31:36.913326: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:31:37.258054: lr: 0.007561\n",
      "2022-11-27 19:31:37.258163: This epoch took 15.546931 s\n",
      "\n",
      "2022-11-27 19:31:37.258191: \n",
      "epoch:  267\n",
      "2022-11-27 19:31:51.539544: train loss : -0.9089\n",
      "2022-11-27 19:31:52.536119: validation loss: -0.8395\n",
      "2022-11-27 19:31:52.536710: Average global foreground Dice: [0.8908, 0.8769]\n",
      "2022-11-27 19:31:52.536901: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:31:52.917635: lr: 0.007552\n",
      "2022-11-27 19:31:52.917745: This epoch took 15.659526 s\n",
      "\n",
      "2022-11-27 19:31:52.917774: \n",
      "epoch:  268\n",
      "2022-11-27 19:32:07.203579: train loss : -0.9106\n",
      "2022-11-27 19:32:08.206405: validation loss: -0.8441\n",
      "2022-11-27 19:32:08.206798: Average global foreground Dice: [0.8948, 0.8792]\n",
      "2022-11-27 19:32:08.206859: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:32:08.567823: lr: 0.007543\n",
      "2022-11-27 19:32:08.567926: This epoch took 15.650125 s\n",
      "\n",
      "2022-11-27 19:32:08.567955: \n",
      "epoch:  269\n",
      "2022-11-27 19:32:22.807829: train loss : -0.9099\n",
      "2022-11-27 19:32:23.828365: validation loss: -0.8449\n",
      "2022-11-27 19:32:23.828746: Average global foreground Dice: [0.8946, 0.8781]\n",
      "2022-11-27 19:32:23.828803: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:32:24.178377: lr: 0.007533\n",
      "2022-11-27 19:32:24.178492: This epoch took 15.610495 s\n",
      "\n",
      "2022-11-27 19:32:24.178525: \n",
      "epoch:  270\n",
      "2022-11-27 19:32:38.429191: train loss : -0.9109\n",
      "2022-11-27 19:32:39.443263: validation loss: -0.8456\n",
      "2022-11-27 19:32:39.443788: Average global foreground Dice: [0.8945, 0.8774]\n",
      "2022-11-27 19:32:39.444015: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 19:32:39.928993: lr: 0.007524\n",
      "2022-11-27 19:32:39.929104: This epoch took 15.750553 s\n",
      "\n",
      "2022-11-27 19:32:39.929134: \n",
      "epoch:  271\n",
      "2022-11-27 19:32:54.243735: train loss : -0.9110\n",
      "2022-11-27 19:32:55.236877: validation loss: -0.8469\n",
      "2022-11-27 19:32:55.237277: Average global foreground Dice: [0.8988, 0.8807]\n",
      "2022-11-27 19:32:55.237446: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:32:55.595509: lr: 0.007515\n",
      "2022-11-27 19:32:55.595618: This epoch took 15.666457 s\n",
      "\n",
      "2022-11-27 19:32:55.595648: \n",
      "epoch:  272\n",
      "2022-11-27 19:33:09.850487: train loss : -0.9103\n",
      "2022-11-27 19:33:10.859191: validation loss: -0.8414\n",
      "2022-11-27 19:33:10.859525: Average global foreground Dice: [0.8921, 0.878]\n",
      "2022-11-27 19:33:10.859582: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:33:11.229973: lr: 0.007506\n",
      "2022-11-27 19:33:11.230097: This epoch took 15.634407 s\n",
      "\n",
      "2022-11-27 19:33:11.230128: \n",
      "epoch:  273\n",
      "2022-11-27 19:33:25.525024: train loss : -0.9114\n",
      "2022-11-27 19:33:26.526453: validation loss: -0.8450\n",
      "2022-11-27 19:33:26.526793: Average global foreground Dice: [0.8955, 0.88]\n",
      "2022-11-27 19:33:26.526845: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:33:26.875833: lr: 0.007496\n",
      "2022-11-27 19:33:26.875941: This epoch took 15.645787 s\n",
      "\n",
      "2022-11-27 19:33:26.875969: \n",
      "epoch:  274\n",
      "2022-11-27 19:33:41.182151: train loss : -0.9121\n",
      "2022-11-27 19:33:42.186496: validation loss: -0.8461\n",
      "2022-11-27 19:33:42.186891: Average global foreground Dice: [0.8963, 0.8802]\n",
      "2022-11-27 19:33:42.187077: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:33:42.541309: lr: 0.007487\n",
      "2022-11-27 19:33:42.541523: This epoch took 15.665528 s\n",
      "\n",
      "2022-11-27 19:33:42.541554: \n",
      "epoch:  275\n",
      "2022-11-27 19:33:56.826032: train loss : -0.9126\n",
      "2022-11-27 19:33:57.815250: validation loss: -0.8478\n",
      "2022-11-27 19:33:57.815749: Average global foreground Dice: [0.8978, 0.8807]\n",
      "2022-11-27 19:33:57.815940: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:33:58.183345: lr: 0.007478\n",
      "2022-11-27 19:33:58.183447: This epoch took 15.641865 s\n",
      "\n",
      "2022-11-27 19:33:58.183496: \n",
      "epoch:  276\n",
      "2022-11-27 19:34:12.420139: train loss : -0.9104\n",
      "2022-11-27 19:34:13.441973: validation loss: -0.8418\n",
      "2022-11-27 19:34:13.443148: Average global foreground Dice: [0.8917, 0.8778]\n",
      "2022-11-27 19:34:13.443343: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:34:13.796888: lr: 0.007468\n",
      "2022-11-27 19:34:13.796989: This epoch took 15.613467 s\n",
      "\n",
      "2022-11-27 19:34:13.797037: \n",
      "epoch:  277\n",
      "2022-11-27 19:34:28.027889: train loss : -0.9110\n",
      "2022-11-27 19:34:29.082467: validation loss: -0.8390\n",
      "2022-11-27 19:34:29.082917: Average global foreground Dice: [0.8903, 0.8752]\n",
      "2022-11-27 19:34:29.083011: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:34:29.433820: lr: 0.007459\n",
      "2022-11-27 19:34:29.433926: This epoch took 15.636860 s\n",
      "\n",
      "2022-11-27 19:34:29.433973: \n",
      "epoch:  278\n",
      "2022-11-27 19:34:43.740865: train loss : -0.9113\n",
      "2022-11-27 19:34:44.804611: validation loss: -0.8427\n",
      "2022-11-27 19:34:44.804949: Average global foreground Dice: [0.8946, 0.8765]\n",
      "2022-11-27 19:34:44.805000: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:34:45.151184: lr: 0.00745\n",
      "2022-11-27 19:34:45.151285: This epoch took 15.717287 s\n",
      "\n",
      "2022-11-27 19:34:45.151314: \n",
      "epoch:  279\n",
      "2022-11-27 19:34:59.497540: train loss : -0.9119\n",
      "2022-11-27 19:35:00.494849: validation loss: -0.8401\n",
      "2022-11-27 19:35:00.495190: Average global foreground Dice: [0.8925, 0.8754]\n",
      "2022-11-27 19:35:00.495244: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:35:00.843900: lr: 0.00744\n",
      "2022-11-27 19:35:00.844005: This epoch took 15.692664 s\n",
      "\n",
      "2022-11-27 19:35:00.844034: \n",
      "epoch:  280\n",
      "2022-11-27 19:35:15.101049: train loss : -0.9138\n",
      "2022-11-27 19:35:16.094441: validation loss: -0.8417\n",
      "2022-11-27 19:35:16.094830: Average global foreground Dice: [0.8947, 0.8776]\n",
      "2022-11-27 19:35:16.094895: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:35:16.553861: lr: 0.007431\n",
      "2022-11-27 19:35:16.553975: This epoch took 15.709915 s\n",
      "\n",
      "2022-11-27 19:35:16.554005: \n",
      "epoch:  281\n",
      "2022-11-27 19:35:30.802941: train loss : -0.9131\n",
      "2022-11-27 19:35:31.813681: validation loss: -0.8438\n",
      "2022-11-27 19:35:31.814012: Average global foreground Dice: [0.8969, 0.8774]\n",
      "2022-11-27 19:35:31.814071: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:35:32.155530: lr: 0.007422\n",
      "2022-11-27 19:35:32.155653: This epoch took 15.601605 s\n",
      "\n",
      "2022-11-27 19:35:32.155686: \n",
      "epoch:  282\n",
      "2022-11-27 19:35:46.463494: train loss : -0.9138\n",
      "2022-11-27 19:35:47.462605: validation loss: -0.8351\n",
      "2022-11-27 19:35:47.462937: Average global foreground Dice: [0.8904, 0.8717]\n",
      "2022-11-27 19:35:47.462997: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:35:47.807106: lr: 0.007413\n",
      "2022-11-27 19:35:47.807214: This epoch took 15.651501 s\n",
      "\n",
      "2022-11-27 19:35:47.807242: \n",
      "epoch:  283\n",
      "2022-11-27 19:36:02.061967: train loss : -0.9116\n",
      "2022-11-27 19:36:03.060905: validation loss: -0.8400\n",
      "2022-11-27 19:36:03.061228: Average global foreground Dice: [0.8923, 0.8741]\n",
      "2022-11-27 19:36:03.061281: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:36:03.402167: lr: 0.007403\n",
      "2022-11-27 19:36:03.402361: This epoch took 15.595092 s\n",
      "\n",
      "2022-11-27 19:36:03.402392: \n",
      "epoch:  284\n",
      "2022-11-27 19:36:17.702331: train loss : -0.9112\n",
      "2022-11-27 19:36:18.730691: validation loss: -0.8401\n",
      "2022-11-27 19:36:18.731073: Average global foreground Dice: [0.892, 0.8776]\n",
      "2022-11-27 19:36:18.731137: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:36:19.083752: lr: 0.007394\n",
      "2022-11-27 19:36:19.083862: This epoch took 15.681442 s\n",
      "\n",
      "2022-11-27 19:36:19.083891: \n",
      "epoch:  285\n",
      "2022-11-27 19:36:33.353549: train loss : -0.9103\n",
      "2022-11-27 19:36:34.339967: validation loss: -0.8395\n",
      "2022-11-27 19:36:34.340346: Average global foreground Dice: [0.8922, 0.8762]\n",
      "2022-11-27 19:36:34.340405: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:36:34.684284: lr: 0.007385\n",
      "2022-11-27 19:36:34.684401: This epoch took 15.600477 s\n",
      "\n",
      "2022-11-27 19:36:34.684446: \n",
      "epoch:  286\n",
      "2022-11-27 19:36:48.925323: train loss : -0.9114\n",
      "2022-11-27 19:36:49.955609: validation loss: -0.8395\n",
      "2022-11-27 19:36:49.955941: Average global foreground Dice: [0.8924, 0.8751]\n",
      "2022-11-27 19:36:49.955994: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:36:50.306935: lr: 0.007375\n",
      "2022-11-27 19:36:50.307043: This epoch took 15.622570 s\n",
      "\n",
      "2022-11-27 19:36:50.307073: \n",
      "epoch:  287\n",
      "2022-11-27 19:37:04.610078: train loss : -0.9118\n",
      "2022-11-27 19:37:05.632055: validation loss: -0.8419\n",
      "2022-11-27 19:37:05.632434: Average global foreground Dice: [0.8928, 0.8773]\n",
      "2022-11-27 19:37:05.632492: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:37:05.988068: lr: 0.007366\n",
      "2022-11-27 19:37:05.988183: This epoch took 15.681068 s\n",
      "\n",
      "2022-11-27 19:37:05.988214: \n",
      "epoch:  288\n",
      "2022-11-27 19:37:20.288203: train loss : -0.9088\n",
      "2022-11-27 19:37:21.277542: validation loss: -0.8458\n",
      "2022-11-27 19:37:21.277918: Average global foreground Dice: [0.8971, 0.8781]\n",
      "2022-11-27 19:37:21.277990: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:37:21.623096: lr: 0.007357\n",
      "2022-11-27 19:37:21.623203: This epoch took 15.634964 s\n",
      "\n",
      "2022-11-27 19:37:21.623237: \n",
      "epoch:  289\n",
      "2022-11-27 19:37:35.880785: train loss : -0.9116\n",
      "2022-11-27 19:37:36.883662: validation loss: -0.8408\n",
      "2022-11-27 19:37:36.884049: Average global foreground Dice: [0.8923, 0.8777]\n",
      "2022-11-27 19:37:36.884107: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 19:37:37.230284: lr: 0.007347\n",
      "2022-11-27 19:37:37.230391: This epoch took 15.607124 s\n",
      "\n",
      "2022-11-27 19:37:37.230421: \n",
      "epoch:  290\n",
      "2022-11-27 19:37:51.529596: train loss : -0.9107\n",
      "2022-11-27 19:37:52.539588: validation loss: -0.8396\n",
      "2022-11-27 19:37:52.539922: Average global foreground Dice: [0.8923, 0.8753]\n",
      "2022-11-27 19:37:52.539978: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:37:52.896435: lr: 0.007338\n",
      "2022-11-27 19:37:52.896539: This epoch took 15.666092 s\n",
      "\n",
      "2022-11-27 19:37:52.896569: \n",
      "epoch:  291\n",
      "2022-11-27 19:38:07.168885: train loss : -0.9120\n",
      "2022-11-27 19:38:08.184983: validation loss: -0.8367\n",
      "2022-11-27 19:38:08.185369: Average global foreground Dice: [0.8892, 0.8748]\n",
      "2022-11-27 19:38:08.185426: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:38:08.669717: lr: 0.007329\n",
      "2022-11-27 19:38:08.669833: This epoch took 15.773237 s\n",
      "\n",
      "2022-11-27 19:38:08.669863: \n",
      "epoch:  292\n",
      "2022-11-27 19:38:22.947485: train loss : -0.9126\n",
      "2022-11-27 19:38:23.942569: validation loss: -0.8416\n",
      "2022-11-27 19:38:23.942910: Average global foreground Dice: [0.8943, 0.8782]\n",
      "2022-11-27 19:38:23.942969: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:38:24.293850: lr: 0.007319\n",
      "2022-11-27 19:38:24.293979: This epoch took 15.624089 s\n",
      "\n",
      "2022-11-27 19:38:24.294008: \n",
      "epoch:  293\n",
      "2022-11-27 19:38:38.560025: train loss : -0.9129\n",
      "2022-11-27 19:38:39.576365: validation loss: -0.8354\n",
      "2022-11-27 19:38:39.576722: Average global foreground Dice: [0.8883, 0.8736]\n",
      "2022-11-27 19:38:39.576867: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:38:39.949107: lr: 0.00731\n",
      "2022-11-27 19:38:39.949208: This epoch took 15.655173 s\n",
      "\n",
      "2022-11-27 19:38:39.949240: \n",
      "epoch:  294\n",
      "2022-11-27 19:38:54.289657: train loss : -0.9124\n",
      "2022-11-27 19:38:55.343796: validation loss: -0.8459\n",
      "2022-11-27 19:38:55.344367: Average global foreground Dice: [0.8952, 0.8778]\n",
      "2022-11-27 19:38:55.344509: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:38:55.702562: lr: 0.007301\n",
      "2022-11-27 19:38:55.702673: This epoch took 15.753389 s\n",
      "\n",
      "2022-11-27 19:38:55.702703: \n",
      "epoch:  295\n",
      "2022-11-27 19:39:10.036477: train loss : -0.9119\n",
      "2022-11-27 19:39:11.061059: validation loss: -0.8406\n",
      "2022-11-27 19:39:11.061388: Average global foreground Dice: [0.8928, 0.8745]\n",
      "2022-11-27 19:39:11.061443: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:39:11.412923: lr: 0.007291\n",
      "2022-11-27 19:39:11.413028: This epoch took 15.710299 s\n",
      "\n",
      "2022-11-27 19:39:11.413056: \n",
      "epoch:  296\n",
      "2022-11-27 19:39:25.673562: train loss : -0.9131\n",
      "2022-11-27 19:39:26.662333: validation loss: -0.8459\n",
      "2022-11-27 19:39:26.662675: Average global foreground Dice: [0.8967, 0.8795]\n",
      "2022-11-27 19:39:26.662731: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:39:27.013978: lr: 0.007282\n",
      "2022-11-27 19:39:27.014091: This epoch took 15.601008 s\n",
      "\n",
      "2022-11-27 19:39:27.014121: \n",
      "epoch:  297\n",
      "2022-11-27 19:39:41.290792: train loss : -0.9122\n",
      "2022-11-27 19:39:42.292938: validation loss: -0.8390\n",
      "2022-11-27 19:39:42.293315: Average global foreground Dice: [0.8915, 0.8755]\n",
      "2022-11-27 19:39:42.293415: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:39:42.646371: lr: 0.007273\n",
      "2022-11-27 19:39:42.646479: This epoch took 15.632324 s\n",
      "\n",
      "2022-11-27 19:39:42.646514: \n",
      "epoch:  298\n",
      "2022-11-27 19:39:56.842809: train loss : -0.9121\n",
      "2022-11-27 19:39:57.855797: validation loss: -0.8470\n",
      "2022-11-27 19:39:57.856287: Average global foreground Dice: [0.8976, 0.88]\n",
      "2022-11-27 19:39:57.856368: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:39:58.247653: lr: 0.007264\n",
      "2022-11-27 19:39:58.247758: This epoch took 15.601213 s\n",
      "\n",
      "2022-11-27 19:39:58.247786: \n",
      "epoch:  299\n",
      "2022-11-27 19:40:12.470996: train loss : -0.9115\n",
      "2022-11-27 19:40:13.485155: validation loss: -0.8426\n",
      "2022-11-27 19:40:13.485554: Average global foreground Dice: [0.8952, 0.8768]\n",
      "2022-11-27 19:40:13.485649: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:40:13.859670: lr: 0.007254\n",
      "2022-11-27 19:40:13.859761: saving scheduled checkpoint file...\n",
      "2022-11-27 19:40:13.863997: saving checkpoint...\n",
      "2022-11-27 19:40:13.927417: done, saving took 0.07 seconds\n",
      "2022-11-27 19:40:13.929306: done\n",
      "2022-11-27 19:40:13.929375: This epoch took 15.681563 s\n",
      "\n",
      "2022-11-27 19:40:13.929401: \n",
      "epoch:  300\n",
      "2022-11-27 19:40:28.174482: train loss : -0.9124\n",
      "2022-11-27 19:40:29.179086: validation loss: -0.8421\n",
      "2022-11-27 19:40:29.179588: Average global foreground Dice: [0.8942, 0.8772]\n",
      "2022-11-27 19:40:29.179697: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:40:29.532771: lr: 0.007245\n",
      "2022-11-27 19:40:29.532876: This epoch took 15.603449 s\n",
      "\n",
      "2022-11-27 19:40:29.532906: \n",
      "epoch:  301\n",
      "2022-11-27 19:40:43.766346: train loss : -0.9129\n",
      "2022-11-27 19:40:44.815138: validation loss: -0.8405\n",
      "2022-11-27 19:40:44.815515: Average global foreground Dice: [0.8935, 0.8758]\n",
      "2022-11-27 19:40:44.815596: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:40:45.291288: lr: 0.007236\n",
      "2022-11-27 19:40:45.291399: This epoch took 15.758466 s\n",
      "\n",
      "2022-11-27 19:40:45.291425: \n",
      "epoch:  302\n",
      "2022-11-27 19:40:59.547105: train loss : -0.9128\n",
      "2022-11-27 19:41:00.549182: validation loss: -0.8417\n",
      "2022-11-27 19:41:00.549566: Average global foreground Dice: [0.8935, 0.8807]\n",
      "2022-11-27 19:41:00.549623: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:41:00.903439: lr: 0.007226\n",
      "2022-11-27 19:41:00.903548: This epoch took 15.612097 s\n",
      "\n",
      "2022-11-27 19:41:00.903577: \n",
      "epoch:  303\n",
      "2022-11-27 19:41:15.138939: train loss : -0.9122\n",
      "2022-11-27 19:41:16.132781: validation loss: -0.8408\n",
      "2022-11-27 19:41:16.133139: Average global foreground Dice: [0.8936, 0.8768]\n",
      "2022-11-27 19:41:16.133215: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:41:16.489108: lr: 0.007217\n",
      "2022-11-27 19:41:16.489215: This epoch took 15.585612 s\n",
      "\n",
      "2022-11-27 19:41:16.489248: \n",
      "epoch:  304\n",
      "2022-11-27 19:41:30.739918: train loss : -0.9136\n",
      "2022-11-27 19:41:31.739852: validation loss: -0.8508\n",
      "2022-11-27 19:41:31.740282: Average global foreground Dice: [0.8983, 0.8841]\n",
      "2022-11-27 19:41:31.740350: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:41:32.096523: lr: 0.007208\n",
      "2022-11-27 19:41:32.096625: This epoch took 15.607348 s\n",
      "\n",
      "2022-11-27 19:41:32.096651: \n",
      "epoch:  305\n",
      "2022-11-27 19:41:46.382446: train loss : -0.9133\n",
      "2022-11-27 19:41:47.411570: validation loss: -0.8475\n",
      "2022-11-27 19:41:47.411898: Average global foreground Dice: [0.8989, 0.881]\n",
      "2022-11-27 19:41:47.411952: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:41:47.766428: lr: 0.007198\n",
      "2022-11-27 19:41:47.766545: This epoch took 15.669854 s\n",
      "\n",
      "2022-11-27 19:41:47.766574: \n",
      "epoch:  306\n",
      "2022-11-27 19:42:02.028779: train loss : -0.9132\n",
      "2022-11-27 19:42:03.051695: validation loss: -0.8521\n",
      "2022-11-27 19:42:03.052027: Average global foreground Dice: [0.901, 0.884]\n",
      "2022-11-27 19:42:03.052082: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:42:03.413307: lr: 0.007189\n",
      "2022-11-27 19:42:03.413410: This epoch took 15.646810 s\n",
      "\n",
      "2022-11-27 19:42:03.413440: \n",
      "epoch:  307\n",
      "2022-11-27 19:42:17.644423: train loss : -0.9133\n",
      "2022-11-27 19:42:18.661786: validation loss: -0.8427\n",
      "2022-11-27 19:42:18.662129: Average global foreground Dice: [0.8924, 0.8787]\n",
      "2022-11-27 19:42:18.662186: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:42:19.025812: lr: 0.00718\n",
      "2022-11-27 19:42:19.025926: This epoch took 15.612459 s\n",
      "\n",
      "2022-11-27 19:42:19.025960: \n",
      "epoch:  308\n",
      "2022-11-27 19:42:33.246908: train loss : -0.9143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 19:42:34.240463: validation loss: -0.8422\n",
      "2022-11-27 19:42:34.240936: Average global foreground Dice: [0.8932, 0.8773]\n",
      "2022-11-27 19:42:34.241039: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:42:34.608322: lr: 0.00717\n",
      "2022-11-27 19:42:34.608422: This epoch took 15.582434 s\n",
      "\n",
      "2022-11-27 19:42:34.608448: \n",
      "epoch:  309\n",
      "2022-11-27 19:42:48.872966: train loss : -0.9118\n",
      "2022-11-27 19:42:49.880517: validation loss: -0.8413\n",
      "2022-11-27 19:42:49.880853: Average global foreground Dice: [0.8908, 0.8774]\n",
      "2022-11-27 19:42:49.880919: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:42:50.238099: lr: 0.007161\n",
      "2022-11-27 19:42:50.238221: This epoch took 15.629732 s\n",
      "\n",
      "2022-11-27 19:42:50.238252: \n",
      "epoch:  310\n",
      "2022-11-27 19:43:04.457480: train loss : -0.9137\n",
      "2022-11-27 19:43:05.486935: validation loss: -0.8415\n",
      "2022-11-27 19:43:05.487333: Average global foreground Dice: [0.8932, 0.8774]\n",
      "2022-11-27 19:43:05.487407: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:43:05.842596: lr: 0.007152\n",
      "2022-11-27 19:43:05.842701: This epoch took 15.604422 s\n",
      "\n",
      "2022-11-27 19:43:05.842730: \n",
      "epoch:  311\n",
      "2022-11-27 19:43:20.054224: train loss : -0.9136\n",
      "2022-11-27 19:43:21.053648: validation loss: -0.8424\n",
      "2022-11-27 19:43:21.053997: Average global foreground Dice: [0.8927, 0.8786]\n",
      "2022-11-27 19:43:21.054056: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:43:21.533310: lr: 0.007142\n",
      "2022-11-27 19:43:21.533421: This epoch took 15.690665 s\n",
      "\n",
      "2022-11-27 19:43:21.533449: \n",
      "epoch:  312\n",
      "2022-11-27 19:43:35.806284: train loss : -0.9151\n",
      "2022-11-27 19:43:36.791392: validation loss: -0.8458\n",
      "2022-11-27 19:43:36.791759: Average global foreground Dice: [0.8984, 0.8801]\n",
      "2022-11-27 19:43:36.791825: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:43:37.152774: lr: 0.007133\n",
      "2022-11-27 19:43:37.152880: This epoch took 15.619404 s\n",
      "\n",
      "2022-11-27 19:43:37.152906: \n",
      "epoch:  313\n",
      "2022-11-27 19:43:51.394817: train loss : -0.9155\n",
      "2022-11-27 19:43:52.395880: validation loss: -0.8390\n",
      "2022-11-27 19:43:52.396247: Average global foreground Dice: [0.8918, 0.8772]\n",
      "2022-11-27 19:43:52.396307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:43:52.750981: lr: 0.007123\n",
      "2022-11-27 19:43:52.751084: This epoch took 15.598152 s\n",
      "\n",
      "2022-11-27 19:43:52.751133: \n",
      "epoch:  314\n",
      "2022-11-27 19:44:07.063344: train loss : -0.9136\n",
      "2022-11-27 19:44:08.074157: validation loss: -0.8447\n",
      "2022-11-27 19:44:08.074607: Average global foreground Dice: [0.8966, 0.8787]\n",
      "2022-11-27 19:44:08.074708: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:44:08.433458: lr: 0.007114\n",
      "2022-11-27 19:44:08.433579: This epoch took 15.682403 s\n",
      "\n",
      "2022-11-27 19:44:08.433609: \n",
      "epoch:  315\n",
      "2022-11-27 19:44:22.733982: train loss : -0.9140\n",
      "2022-11-27 19:44:23.753489: validation loss: -0.8395\n",
      "2022-11-27 19:44:23.753934: Average global foreground Dice: [0.8919, 0.8747]\n",
      "2022-11-27 19:44:23.754167: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:44:24.110614: lr: 0.007105\n",
      "2022-11-27 19:44:24.110739: This epoch took 15.677102 s\n",
      "\n",
      "2022-11-27 19:44:24.110781: \n",
      "epoch:  316\n",
      "2022-11-27 19:44:38.379872: train loss : -0.9142\n",
      "2022-11-27 19:44:39.421147: validation loss: -0.8431\n",
      "2022-11-27 19:44:39.421488: Average global foreground Dice: [0.8936, 0.8767]\n",
      "2022-11-27 19:44:39.421546: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:44:39.790184: lr: 0.007095\n",
      "2022-11-27 19:44:39.790293: This epoch took 15.679481 s\n",
      "\n",
      "2022-11-27 19:44:39.790323: \n",
      "epoch:  317\n",
      "2022-11-27 19:44:54.072380: train loss : -0.9142\n",
      "2022-11-27 19:44:55.106665: validation loss: -0.8417\n",
      "2022-11-27 19:44:55.106992: Average global foreground Dice: [0.8943, 0.8754]\n",
      "2022-11-27 19:44:55.107047: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:44:55.458108: lr: 0.007086\n",
      "2022-11-27 19:44:55.458215: This epoch took 15.667866 s\n",
      "\n",
      "2022-11-27 19:44:55.458245: \n",
      "epoch:  318\n",
      "2022-11-27 19:45:09.689061: train loss : -0.9127\n",
      "2022-11-27 19:45:10.696691: validation loss: -0.8371\n",
      "2022-11-27 19:45:10.697164: Average global foreground Dice: [0.8889, 0.8746]\n",
      "2022-11-27 19:45:10.697241: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:45:11.054810: lr: 0.007077\n",
      "2022-11-27 19:45:11.054919: This epoch took 15.596647 s\n",
      "\n",
      "2022-11-27 19:45:11.054948: \n",
      "epoch:  319\n",
      "2022-11-27 19:45:25.294350: train loss : -0.9147\n",
      "2022-11-27 19:45:26.301582: validation loss: -0.8457\n",
      "2022-11-27 19:45:26.301932: Average global foreground Dice: [0.8957, 0.8797]\n",
      "2022-11-27 19:45:26.302014: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:45:26.660387: lr: 0.007067\n",
      "2022-11-27 19:45:26.660503: This epoch took 15.605509 s\n",
      "\n",
      "2022-11-27 19:45:26.660533: \n",
      "epoch:  320\n",
      "2022-11-27 19:45:40.942996: train loss : -0.9148\n",
      "2022-11-27 19:45:41.979748: validation loss: -0.8447\n",
      "2022-11-27 19:45:41.980154: Average global foreground Dice: [0.8954, 0.8796]\n",
      "2022-11-27 19:45:41.980237: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:45:42.357551: lr: 0.007058\n",
      "2022-11-27 19:45:42.357659: This epoch took 15.697100 s\n",
      "\n",
      "2022-11-27 19:45:42.357689: \n",
      "epoch:  321\n",
      "2022-11-27 19:45:56.601488: train loss : -0.9131\n",
      "2022-11-27 19:45:57.592642: validation loss: -0.8404\n",
      "2022-11-27 19:45:57.593030: Average global foreground Dice: [0.8926, 0.8762]\n",
      "2022-11-27 19:45:57.593089: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:45:58.054865: lr: 0.007049\n",
      "2022-11-27 19:45:58.055004: This epoch took 15.697272 s\n",
      "\n",
      "2022-11-27 19:45:58.055039: \n",
      "epoch:  322\n",
      "2022-11-27 19:46:12.371430: train loss : -0.9131\n",
      "2022-11-27 19:46:13.363008: validation loss: -0.8445\n",
      "2022-11-27 19:46:13.363384: Average global foreground Dice: [0.8946, 0.8819]\n",
      "2022-11-27 19:46:13.363440: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:46:13.718685: lr: 0.007039\n",
      "2022-11-27 19:46:13.718798: This epoch took 15.663733 s\n",
      "\n",
      "2022-11-27 19:46:13.718828: \n",
      "epoch:  323\n",
      "2022-11-27 19:46:28.027617: train loss : -0.9137\n",
      "2022-11-27 19:46:29.052806: validation loss: -0.8409\n",
      "2022-11-27 19:46:29.053316: Average global foreground Dice: [0.8934, 0.8767]\n",
      "2022-11-27 19:46:29.053457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:46:29.405789: lr: 0.00703\n",
      "2022-11-27 19:46:29.405914: This epoch took 15.687059 s\n",
      "\n",
      "2022-11-27 19:46:29.405966: \n",
      "epoch:  324\n",
      "2022-11-27 19:46:43.718536: train loss : -0.9140\n",
      "2022-11-27 19:46:44.719600: validation loss: -0.8447\n",
      "2022-11-27 19:46:44.719948: Average global foreground Dice: [0.8952, 0.8795]\n",
      "2022-11-27 19:46:44.720008: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:46:45.066961: lr: 0.007021\n",
      "2022-11-27 19:46:45.067086: This epoch took 15.661074 s\n",
      "\n",
      "2022-11-27 19:46:45.067118: \n",
      "epoch:  325\n",
      "2022-11-27 19:46:59.412880: train loss : -0.9152\n",
      "2022-11-27 19:47:00.407657: validation loss: -0.8414\n",
      "2022-11-27 19:47:00.407992: Average global foreground Dice: [0.8925, 0.8793]\n",
      "2022-11-27 19:47:00.408052: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:47:00.756894: lr: 0.007011\n",
      "2022-11-27 19:47:00.757007: This epoch took 15.689862 s\n",
      "\n",
      "2022-11-27 19:47:00.757042: \n",
      "epoch:  326\n",
      "2022-11-27 19:47:15.032915: train loss : -0.9140\n",
      "2022-11-27 19:47:16.023604: validation loss: -0.8345\n",
      "2022-11-27 19:47:16.023954: Average global foreground Dice: [0.891, 0.872]\n",
      "2022-11-27 19:47:16.024008: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:47:16.372451: lr: 0.007002\n",
      "2022-11-27 19:47:16.372562: This epoch took 15.615493 s\n",
      "\n",
      "2022-11-27 19:47:16.372591: \n",
      "epoch:  327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 19:47:30.694565: train loss : -0.9130\n",
      "2022-11-27 19:47:31.689347: validation loss: -0.8391\n",
      "2022-11-27 19:47:31.689731: Average global foreground Dice: [0.8917, 0.8757]\n",
      "2022-11-27 19:47:31.689791: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:47:32.038044: lr: 0.006992\n",
      "2022-11-27 19:47:32.038167: This epoch took 15.665533 s\n",
      "\n",
      "2022-11-27 19:47:32.038198: \n",
      "epoch:  328\n",
      "2022-11-27 19:47:46.364390: train loss : -0.9135\n",
      "2022-11-27 19:47:47.371656: validation loss: -0.8465\n",
      "2022-11-27 19:47:47.371987: Average global foreground Dice: [0.8974, 0.8797]\n",
      "2022-11-27 19:47:47.372052: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:47:47.719704: lr: 0.006983\n",
      "2022-11-27 19:47:47.719810: This epoch took 15.681585 s\n",
      "\n",
      "2022-11-27 19:47:47.719861: \n",
      "epoch:  329\n",
      "2022-11-27 19:48:01.936692: train loss : -0.9136\n",
      "2022-11-27 19:48:02.963521: validation loss: -0.8436\n",
      "2022-11-27 19:48:02.963877: Average global foreground Dice: [0.8939, 0.8772]\n",
      "2022-11-27 19:48:02.963938: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:48:03.312776: lr: 0.006974\n",
      "2022-11-27 19:48:03.312884: This epoch took 15.592996 s\n",
      "\n",
      "2022-11-27 19:48:03.312931: \n",
      "epoch:  330\n",
      "2022-11-27 19:48:17.609597: train loss : -0.9141\n",
      "2022-11-27 19:48:18.609172: validation loss: -0.8407\n",
      "2022-11-27 19:48:18.609540: Average global foreground Dice: [0.8925, 0.8775]\n",
      "2022-11-27 19:48:18.609613: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:48:18.963583: lr: 0.006964\n",
      "2022-11-27 19:48:18.963689: This epoch took 15.650726 s\n",
      "\n",
      "2022-11-27 19:48:18.963721: \n",
      "epoch:  331\n",
      "2022-11-27 19:48:33.260038: train loss : -0.9156\n",
      "2022-11-27 19:48:34.277333: validation loss: -0.8432\n",
      "2022-11-27 19:48:34.277699: Average global foreground Dice: [0.8967, 0.8778]\n",
      "2022-11-27 19:48:34.277824: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:48:34.775379: lr: 0.006955\n",
      "2022-11-27 19:48:34.775507: This epoch took 15.811732 s\n",
      "\n",
      "2022-11-27 19:48:34.775539: \n",
      "epoch:  332\n",
      "2022-11-27 19:48:49.075744: train loss : -0.9151\n",
      "2022-11-27 19:48:50.089089: validation loss: -0.8490\n",
      "2022-11-27 19:48:50.089483: Average global foreground Dice: [0.8983, 0.8817]\n",
      "2022-11-27 19:48:50.089575: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:48:50.438268: lr: 0.006946\n",
      "2022-11-27 19:48:50.438378: This epoch took 15.662813 s\n",
      "\n",
      "2022-11-27 19:48:50.438408: \n",
      "epoch:  333\n",
      "2022-11-27 19:49:04.714159: train loss : -0.9148\n",
      "2022-11-27 19:49:05.733733: validation loss: -0.8425\n",
      "2022-11-27 19:49:05.734109: Average global foreground Dice: [0.8961, 0.8761]\n",
      "2022-11-27 19:49:05.734356: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:49:06.084532: lr: 0.006936\n",
      "2022-11-27 19:49:06.084652: This epoch took 15.646218 s\n",
      "\n",
      "2022-11-27 19:49:06.084681: \n",
      "epoch:  334\n",
      "2022-11-27 19:49:20.321489: train loss : -0.9152\n",
      "2022-11-27 19:49:21.321756: validation loss: -0.8426\n",
      "2022-11-27 19:49:21.322134: Average global foreground Dice: [0.8944, 0.8765]\n",
      "2022-11-27 19:49:21.322194: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:49:21.672176: lr: 0.006927\n",
      "2022-11-27 19:49:21.672282: This epoch took 15.587575 s\n",
      "\n",
      "2022-11-27 19:49:21.672311: \n",
      "epoch:  335\n",
      "2022-11-27 19:49:35.902948: train loss : -0.9150\n",
      "2022-11-27 19:49:36.893432: validation loss: -0.8451\n",
      "2022-11-27 19:49:36.893814: Average global foreground Dice: [0.8963, 0.8805]\n",
      "2022-11-27 19:49:36.893905: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:49:37.242441: lr: 0.006918\n",
      "2022-11-27 19:49:37.242543: This epoch took 15.570207 s\n",
      "\n",
      "2022-11-27 19:49:37.242569: \n",
      "epoch:  336\n",
      "2022-11-27 19:49:51.505892: train loss : -0.9140\n",
      "2022-11-27 19:49:52.503605: validation loss: -0.8463\n",
      "2022-11-27 19:49:52.503990: Average global foreground Dice: [0.8977, 0.8804]\n",
      "2022-11-27 19:49:52.504048: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:49:52.876104: lr: 0.006908\n",
      "2022-11-27 19:49:52.876235: This epoch took 15.633642 s\n",
      "\n",
      "2022-11-27 19:49:52.876271: \n",
      "epoch:  337\n",
      "2022-11-27 19:50:07.130058: train loss : -0.9166\n",
      "2022-11-27 19:50:08.132766: validation loss: -0.8380\n",
      "2022-11-27 19:50:08.133171: Average global foreground Dice: [0.8917, 0.8752]\n",
      "2022-11-27 19:50:08.133231: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:50:08.481725: lr: 0.006899\n",
      "2022-11-27 19:50:08.481831: This epoch took 15.605530 s\n",
      "\n",
      "2022-11-27 19:50:08.481860: \n",
      "epoch:  338\n",
      "2022-11-27 19:50:22.743292: train loss : -0.9159\n",
      "2022-11-27 19:50:23.760395: validation loss: -0.8416\n",
      "2022-11-27 19:50:23.760802: Average global foreground Dice: [0.894, 0.8752]\n",
      "2022-11-27 19:50:23.760885: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:50:24.117293: lr: 0.006889\n",
      "2022-11-27 19:50:24.117401: This epoch took 15.635515 s\n",
      "\n",
      "2022-11-27 19:50:24.117430: \n",
      "epoch:  339\n",
      "2022-11-27 19:50:38.333663: train loss : -0.9133\n",
      "2022-11-27 19:50:39.327450: validation loss: -0.8438\n",
      "2022-11-27 19:50:39.327793: Average global foreground Dice: [0.8962, 0.879]\n",
      "2022-11-27 19:50:39.327853: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:50:39.687413: lr: 0.00688\n",
      "2022-11-27 19:50:39.687520: This epoch took 15.570064 s\n",
      "\n",
      "2022-11-27 19:50:39.687550: \n",
      "epoch:  340\n",
      "2022-11-27 19:50:54.078402: train loss : -0.9166\n",
      "2022-11-27 19:50:55.077791: validation loss: -0.8450\n",
      "2022-11-27 19:50:55.078135: Average global foreground Dice: [0.8973, 0.8803]\n",
      "2022-11-27 19:50:55.078194: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:50:55.423566: lr: 0.006871\n",
      "2022-11-27 19:50:55.423672: This epoch took 15.736095 s\n",
      "\n",
      "2022-11-27 19:50:55.423702: \n",
      "epoch:  341\n",
      "2022-11-27 19:51:09.717411: train loss : -0.9153\n",
      "2022-11-27 19:51:10.740492: validation loss: -0.8419\n",
      "2022-11-27 19:51:10.740820: Average global foreground Dice: [0.8934, 0.8767]\n",
      "2022-11-27 19:51:10.740877: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:51:11.099025: lr: 0.006861\n",
      "2022-11-27 19:51:11.099141: This epoch took 15.675397 s\n",
      "\n",
      "2022-11-27 19:51:11.099174: \n",
      "epoch:  342\n",
      "2022-11-27 19:51:25.366487: train loss : -0.9137\n",
      "2022-11-27 19:51:26.351447: validation loss: -0.8462\n",
      "2022-11-27 19:51:26.351824: Average global foreground Dice: [0.8978, 0.8794]\n",
      "2022-11-27 19:51:26.351879: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:51:26.842953: lr: 0.006852\n",
      "2022-11-27 19:51:26.843061: This epoch took 15.743860 s\n",
      "\n",
      "2022-11-27 19:51:26.843090: \n",
      "epoch:  343\n",
      "2022-11-27 19:51:41.123616: train loss : -0.9158\n",
      "2022-11-27 19:51:42.119918: validation loss: -0.8389\n",
      "2022-11-27 19:51:42.120250: Average global foreground Dice: [0.891, 0.8747]\n",
      "2022-11-27 19:51:42.120307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:51:42.478584: lr: 0.006842\n",
      "2022-11-27 19:51:42.478705: This epoch took 15.635588 s\n",
      "\n",
      "2022-11-27 19:51:42.478737: \n",
      "epoch:  344\n",
      "2022-11-27 19:51:56.738568: train loss : -0.9150\n",
      "2022-11-27 19:51:57.740258: validation loss: -0.8424\n",
      "2022-11-27 19:51:57.740611: Average global foreground Dice: [0.8936, 0.8759]\n",
      "2022-11-27 19:51:57.740667: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:51:58.095835: lr: 0.006833\n",
      "2022-11-27 19:51:58.095942: This epoch took 15.617178 s\n",
      "\n",
      "2022-11-27 19:51:58.095969: \n",
      "epoch:  345\n",
      "2022-11-27 19:52:12.407183: train loss : -0.9147\n",
      "2022-11-27 19:52:13.401015: validation loss: -0.8452\n",
      "2022-11-27 19:52:13.401349: Average global foreground Dice: [0.8933, 0.8796]\n",
      "2022-11-27 19:52:13.401407: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:52:13.780052: lr: 0.006824\n",
      "2022-11-27 19:52:13.780163: This epoch took 15.684169 s\n",
      "\n",
      "2022-11-27 19:52:13.780192: \n",
      "epoch:  346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 19:52:28.085396: train loss : -0.9150\n",
      "2022-11-27 19:52:29.097370: validation loss: -0.8459\n",
      "2022-11-27 19:52:29.097694: Average global foreground Dice: [0.8968, 0.8806]\n",
      "2022-11-27 19:52:29.097746: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:52:29.453712: lr: 0.006814\n",
      "2022-11-27 19:52:29.453840: This epoch took 15.673605 s\n",
      "\n",
      "2022-11-27 19:52:29.453871: \n",
      "epoch:  347\n",
      "2022-11-27 19:52:43.710476: train loss : -0.9148\n",
      "2022-11-27 19:52:44.723630: validation loss: -0.8337\n",
      "2022-11-27 19:52:44.724028: Average global foreground Dice: [0.8882, 0.8708]\n",
      "2022-11-27 19:52:44.724097: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:52:45.079355: lr: 0.006805\n",
      "2022-11-27 19:52:45.079464: This epoch took 15.625562 s\n",
      "\n",
      "2022-11-27 19:52:45.079493: \n",
      "epoch:  348\n",
      "2022-11-27 19:52:59.413213: train loss : -0.9157\n",
      "2022-11-27 19:53:00.407408: validation loss: -0.8475\n",
      "2022-11-27 19:53:00.407804: Average global foreground Dice: [0.8963, 0.8817]\n",
      "2022-11-27 19:53:00.407871: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:53:00.778330: lr: 0.006796\n",
      "2022-11-27 19:53:00.778440: This epoch took 15.698921 s\n",
      "\n",
      "2022-11-27 19:53:00.778470: \n",
      "epoch:  349\n",
      "2022-11-27 19:53:15.065421: train loss : -0.9149\n",
      "2022-11-27 19:53:16.070879: validation loss: -0.8397\n",
      "2022-11-27 19:53:16.071394: Average global foreground Dice: [0.8927, 0.876]\n",
      "2022-11-27 19:53:16.071485: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:53:16.435242: lr: 0.006786\n",
      "2022-11-27 19:53:16.435336: saving scheduled checkpoint file...\n",
      "2022-11-27 19:53:16.439218: saving checkpoint...\n",
      "2022-11-27 19:53:16.531067: done, saving took 0.10 seconds\n",
      "2022-11-27 19:53:16.536129: done\n",
      "2022-11-27 19:53:16.536298: This epoch took 15.757798 s\n",
      "\n",
      "2022-11-27 19:53:16.536381: \n",
      "epoch:  350\n",
      "2022-11-27 19:53:30.760646: train loss : -0.9151\n",
      "2022-11-27 19:53:31.778829: validation loss: -0.8402\n",
      "2022-11-27 19:53:31.779219: Average global foreground Dice: [0.8933, 0.8767]\n",
      "2022-11-27 19:53:31.779436: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:53:32.141396: lr: 0.006777\n",
      "2022-11-27 19:53:32.141501: This epoch took 15.605043 s\n",
      "\n",
      "2022-11-27 19:53:32.141530: \n",
      "epoch:  351\n",
      "2022-11-27 19:53:46.424941: train loss : -0.9166\n",
      "2022-11-27 19:53:47.434160: validation loss: -0.8453\n",
      "2022-11-27 19:53:47.434583: Average global foreground Dice: [0.8962, 0.8801]\n",
      "2022-11-27 19:53:47.434647: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:53:47.899844: lr: 0.006767\n",
      "2022-11-27 19:53:47.899952: This epoch took 15.758396 s\n",
      "\n",
      "2022-11-27 19:53:47.899982: \n",
      "epoch:  352\n",
      "2022-11-27 19:54:02.108207: train loss : -0.9160\n",
      "2022-11-27 19:54:03.104671: validation loss: -0.8453\n",
      "2022-11-27 19:54:03.105020: Average global foreground Dice: [0.8959, 0.8804]\n",
      "2022-11-27 19:54:03.105122: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:54:03.515404: lr: 0.006758\n",
      "2022-11-27 19:54:03.515515: This epoch took 15.615506 s\n",
      "\n",
      "2022-11-27 19:54:03.515544: \n",
      "epoch:  353\n",
      "2022-11-27 19:54:17.746597: train loss : -0.9145\n",
      "2022-11-27 19:54:18.738732: validation loss: -0.8402\n",
      "2022-11-27 19:54:18.739115: Average global foreground Dice: [0.8948, 0.8766]\n",
      "2022-11-27 19:54:18.739177: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:54:19.092248: lr: 0.006749\n",
      "2022-11-27 19:54:19.092356: This epoch took 15.576785 s\n",
      "\n",
      "2022-11-27 19:54:19.092385: \n",
      "epoch:  354\n",
      "2022-11-27 19:54:33.413887: train loss : -0.9148\n",
      "2022-11-27 19:54:34.399620: validation loss: -0.8429\n",
      "2022-11-27 19:54:34.399962: Average global foreground Dice: [0.8956, 0.8784]\n",
      "2022-11-27 19:54:34.400076: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:54:34.750595: lr: 0.006739\n",
      "2022-11-27 19:54:34.750701: This epoch took 15.658288 s\n",
      "\n",
      "2022-11-27 19:54:34.750729: \n",
      "epoch:  355\n",
      "2022-11-27 19:54:49.014810: train loss : -0.9163\n",
      "2022-11-27 19:54:50.068147: validation loss: -0.8417\n",
      "2022-11-27 19:54:50.068648: Average global foreground Dice: [0.8959, 0.8762]\n",
      "2022-11-27 19:54:50.068774: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:54:50.421379: lr: 0.00673\n",
      "2022-11-27 19:54:50.421512: This epoch took 15.670741 s\n",
      "\n",
      "2022-11-27 19:54:50.421542: \n",
      "epoch:  356\n",
      "2022-11-27 19:55:04.734591: train loss : -0.9169\n",
      "2022-11-27 19:55:05.720965: validation loss: -0.8418\n",
      "2022-11-27 19:55:05.721362: Average global foreground Dice: [0.8953, 0.8765]\n",
      "2022-11-27 19:55:05.721448: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:55:06.074024: lr: 0.00672\n",
      "2022-11-27 19:55:06.074132: This epoch took 15.652562 s\n",
      "\n",
      "2022-11-27 19:55:06.074172: \n",
      "epoch:  357\n",
      "2022-11-27 19:55:20.323196: train loss : -0.9178\n",
      "2022-11-27 19:55:21.344953: validation loss: -0.8430\n",
      "2022-11-27 19:55:21.345334: Average global foreground Dice: [0.8956, 0.88]\n",
      "2022-11-27 19:55:21.345390: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:55:21.697104: lr: 0.006711\n",
      "2022-11-27 19:55:21.697205: This epoch took 15.623003 s\n",
      "\n",
      "2022-11-27 19:55:21.697230: \n",
      "epoch:  358\n",
      "2022-11-27 19:55:35.966216: train loss : -0.9169\n",
      "2022-11-27 19:55:37.011894: validation loss: -0.8392\n",
      "2022-11-27 19:55:37.012274: Average global foreground Dice: [0.8929, 0.8765]\n",
      "2022-11-27 19:55:37.012331: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:55:37.363759: lr: 0.006702\n",
      "2022-11-27 19:55:37.363876: This epoch took 15.666608 s\n",
      "\n",
      "2022-11-27 19:55:37.363907: \n",
      "epoch:  359\n",
      "2022-11-27 19:55:51.632332: train loss : -0.9161\n",
      "2022-11-27 19:55:52.635321: validation loss: -0.8456\n",
      "2022-11-27 19:55:52.635695: Average global foreground Dice: [0.8981, 0.8793]\n",
      "2022-11-27 19:55:52.635753: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:55:53.004201: lr: 0.006692\n",
      "2022-11-27 19:55:53.004310: This epoch took 15.640376 s\n",
      "\n",
      "2022-11-27 19:55:53.004341: \n",
      "epoch:  360\n",
      "2022-11-27 19:56:07.292957: train loss : -0.9160\n",
      "2022-11-27 19:56:08.318875: validation loss: -0.8441\n",
      "2022-11-27 19:56:08.319250: Average global foreground Dice: [0.8969, 0.8789]\n",
      "2022-11-27 19:56:08.319325: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:56:08.674813: lr: 0.006683\n",
      "2022-11-27 19:56:08.674920: This epoch took 15.670552 s\n",
      "\n",
      "2022-11-27 19:56:08.674959: \n",
      "epoch:  361\n",
      "2022-11-27 19:56:22.941341: train loss : -0.9160\n",
      "2022-11-27 19:56:23.990004: validation loss: -0.8460\n",
      "2022-11-27 19:56:23.990349: Average global foreground Dice: [0.8976, 0.8796]\n",
      "2022-11-27 19:56:23.990402: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:56:24.349762: lr: 0.006673\n",
      "2022-11-27 19:56:24.349868: This epoch took 15.674881 s\n",
      "\n",
      "2022-11-27 19:56:24.349904: \n",
      "epoch:  362\n",
      "2022-11-27 19:56:38.550961: train loss : -0.9147\n",
      "2022-11-27 19:56:39.560195: validation loss: -0.8431\n",
      "2022-11-27 19:56:39.560523: Average global foreground Dice: [0.8937, 0.8785]\n",
      "2022-11-27 19:56:39.560576: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:56:40.052689: lr: 0.006664\n",
      "2022-11-27 19:56:40.052792: This epoch took 15.702860 s\n",
      "\n",
      "2022-11-27 19:56:40.052819: \n",
      "epoch:  363\n",
      "2022-11-27 19:56:54.307530: train loss : -0.9149\n",
      "2022-11-27 19:56:55.298641: validation loss: -0.8371\n",
      "2022-11-27 19:56:55.299144: Average global foreground Dice: [0.892, 0.875]\n",
      "2022-11-27 19:56:55.299280: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:56:55.670375: lr: 0.006654\n",
      "2022-11-27 19:56:55.670489: This epoch took 15.617644 s\n",
      "\n",
      "2022-11-27 19:56:55.670527: \n",
      "epoch:  364\n",
      "2022-11-27 19:57:09.943490: train loss : -0.9163\n",
      "2022-11-27 19:57:10.958344: validation loss: -0.8427\n",
      "2022-11-27 19:57:10.958719: Average global foreground Dice: [0.8955, 0.8779]\n",
      "2022-11-27 19:57:10.958778: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 19:57:11.331534: lr: 0.006645\n",
      "2022-11-27 19:57:11.331656: This epoch took 15.661086 s\n",
      "\n",
      "2022-11-27 19:57:11.331694: \n",
      "epoch:  365\n",
      "2022-11-27 19:57:25.655434: train loss : -0.9145\n",
      "2022-11-27 19:57:26.642016: validation loss: -0.8448\n",
      "2022-11-27 19:57:26.642344: Average global foreground Dice: [0.8964, 0.8802]\n",
      "2022-11-27 19:57:26.642397: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:57:26.999871: lr: 0.006636\n",
      "2022-11-27 19:57:26.999989: This epoch took 15.668244 s\n",
      "\n",
      "2022-11-27 19:57:27.000024: \n",
      "epoch:  366\n",
      "2022-11-27 19:57:41.277704: train loss : -0.9162\n",
      "2022-11-27 19:57:42.272959: validation loss: -0.8409\n",
      "2022-11-27 19:57:42.273520: Average global foreground Dice: [0.8954, 0.8772]\n",
      "2022-11-27 19:57:42.273613: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:57:42.640843: lr: 0.006626\n",
      "2022-11-27 19:57:42.640953: This epoch took 15.640903 s\n",
      "\n",
      "2022-11-27 19:57:42.640981: \n",
      "epoch:  367\n",
      "2022-11-27 19:57:56.898822: train loss : -0.9171\n",
      "2022-11-27 19:57:57.922834: validation loss: -0.8479\n",
      "2022-11-27 19:57:57.923196: Average global foreground Dice: [0.8989, 0.8809]\n",
      "2022-11-27 19:57:57.923432: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:57:58.281104: lr: 0.006617\n",
      "2022-11-27 19:57:58.281205: This epoch took 15.640198 s\n",
      "\n",
      "2022-11-27 19:57:58.281231: \n",
      "epoch:  368\n",
      "2022-11-27 19:58:12.525732: train loss : -0.9161\n",
      "2022-11-27 19:58:13.543778: validation loss: -0.8417\n",
      "2022-11-27 19:58:13.544132: Average global foreground Dice: [0.8956, 0.8766]\n",
      "2022-11-27 19:58:13.544191: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:58:13.901094: lr: 0.006607\n",
      "2022-11-27 19:58:13.901196: This epoch took 15.619919 s\n",
      "\n",
      "2022-11-27 19:58:13.901226: \n",
      "epoch:  369\n",
      "2022-11-27 19:58:28.148083: train loss : -0.9158\n",
      "2022-11-27 19:58:29.155394: validation loss: -0.8413\n",
      "2022-11-27 19:58:29.155841: Average global foreground Dice: [0.8955, 0.8752]\n",
      "2022-11-27 19:58:29.155918: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:58:29.515018: lr: 0.006598\n",
      "2022-11-27 19:58:29.515128: This epoch took 15.613877 s\n",
      "\n",
      "2022-11-27 19:58:29.515157: \n",
      "epoch:  370\n",
      "2022-11-27 19:58:43.758068: train loss : -0.9158\n",
      "2022-11-27 19:58:44.784816: validation loss: -0.8412\n",
      "2022-11-27 19:58:44.785200: Average global foreground Dice: [0.8935, 0.8771]\n",
      "2022-11-27 19:58:44.785261: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:58:45.143229: lr: 0.006588\n",
      "2022-11-27 19:58:45.143328: This epoch took 15.628145 s\n",
      "\n",
      "2022-11-27 19:58:45.143355: \n",
      "epoch:  371\n",
      "2022-11-27 19:58:59.436883: train loss : -0.9166\n",
      "2022-11-27 19:59:00.435156: validation loss: -0.8469\n",
      "2022-11-27 19:59:00.435498: Average global foreground Dice: [0.8976, 0.882]\n",
      "2022-11-27 19:59:00.435551: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:59:00.791919: lr: 0.006579\n",
      "2022-11-27 19:59:00.792038: This epoch took 15.648643 s\n",
      "\n",
      "2022-11-27 19:59:00.792068: \n",
      "epoch:  372\n",
      "2022-11-27 19:59:15.070960: train loss : -0.9175\n",
      "2022-11-27 19:59:16.079042: validation loss: -0.8412\n",
      "2022-11-27 19:59:16.079418: Average global foreground Dice: [0.8938, 0.8761]\n",
      "2022-11-27 19:59:16.079506: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:59:16.591178: lr: 0.00657\n",
      "2022-11-27 19:59:16.591310: This epoch took 15.799216 s\n",
      "\n",
      "2022-11-27 19:59:16.591340: \n",
      "epoch:  373\n",
      "2022-11-27 19:59:30.847322: train loss : -0.9153\n",
      "2022-11-27 19:59:31.860768: validation loss: -0.8427\n",
      "2022-11-27 19:59:31.861138: Average global foreground Dice: [0.8947, 0.8766]\n",
      "2022-11-27 19:59:31.861196: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:59:32.217692: lr: 0.00656\n",
      "2022-11-27 19:59:32.217812: This epoch took 15.626430 s\n",
      "\n",
      "2022-11-27 19:59:32.217844: \n",
      "epoch:  374\n",
      "2022-11-27 19:59:46.465813: train loss : -0.9174\n",
      "2022-11-27 19:59:47.479386: validation loss: -0.8342\n",
      "2022-11-27 19:59:47.479721: Average global foreground Dice: [0.8915, 0.8737]\n",
      "2022-11-27 19:59:47.479775: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 19:59:47.838761: lr: 0.006551\n",
      "2022-11-27 19:59:47.838865: This epoch took 15.620994 s\n",
      "\n",
      "2022-11-27 19:59:47.838894: \n",
      "epoch:  375\n",
      "2022-11-27 20:00:02.088153: train loss : -0.9153\n",
      "2022-11-27 20:00:03.080842: validation loss: -0.8406\n",
      "2022-11-27 20:00:03.081325: Average global foreground Dice: [0.8958, 0.8747]\n",
      "2022-11-27 20:00:03.081424: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:00:03.444778: lr: 0.006541\n",
      "2022-11-27 20:00:03.444882: This epoch took 15.605960 s\n",
      "\n",
      "2022-11-27 20:00:03.444909: \n",
      "epoch:  376\n",
      "2022-11-27 20:00:17.704402: train loss : -0.9164\n",
      "2022-11-27 20:00:18.705635: validation loss: -0.8397\n",
      "2022-11-27 20:00:18.706045: Average global foreground Dice: [0.8941, 0.8759]\n",
      "2022-11-27 20:00:18.706106: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:00:19.065785: lr: 0.006532\n",
      "2022-11-27 20:00:19.065908: This epoch took 15.620953 s\n",
      "\n",
      "2022-11-27 20:00:19.065941: \n",
      "epoch:  377\n",
      "2022-11-27 20:00:33.355042: train loss : -0.9180\n",
      "2022-11-27 20:00:34.347754: validation loss: -0.8408\n",
      "2022-11-27 20:00:34.348119: Average global foreground Dice: [0.8944, 0.8758]\n",
      "2022-11-27 20:00:34.348173: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:00:34.727051: lr: 0.006522\n",
      "2022-11-27 20:00:34.727181: This epoch took 15.661198 s\n",
      "\n",
      "2022-11-27 20:00:34.727211: \n",
      "epoch:  378\n",
      "2022-11-27 20:00:48.960057: train loss : -0.9160\n",
      "2022-11-27 20:00:49.972880: validation loss: -0.8397\n",
      "2022-11-27 20:00:49.973221: Average global foreground Dice: [0.8943, 0.8772]\n",
      "2022-11-27 20:00:49.973275: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:00:50.353575: lr: 0.006513\n",
      "2022-11-27 20:00:50.353682: This epoch took 15.626444 s\n",
      "\n",
      "2022-11-27 20:00:50.353711: \n",
      "epoch:  379\n",
      "2022-11-27 20:01:04.613259: train loss : -0.9154\n",
      "2022-11-27 20:01:05.606291: validation loss: -0.8413\n",
      "2022-11-27 20:01:05.606707: Average global foreground Dice: [0.8965, 0.8765]\n",
      "2022-11-27 20:01:05.606793: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:01:05.966918: lr: 0.006504\n",
      "2022-11-27 20:01:05.967027: This epoch took 15.613288 s\n",
      "\n",
      "2022-11-27 20:01:05.967060: \n",
      "epoch:  380\n",
      "2022-11-27 20:01:20.258652: train loss : -0.9154\n",
      "2022-11-27 20:01:21.247260: validation loss: -0.8412\n",
      "2022-11-27 20:01:21.247607: Average global foreground Dice: [0.894, 0.8763]\n",
      "2022-11-27 20:01:21.247665: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:01:21.603577: lr: 0.006494\n",
      "2022-11-27 20:01:21.603682: This epoch took 15.636593 s\n",
      "\n",
      "2022-11-27 20:01:21.603712: \n",
      "epoch:  381\n",
      "2022-11-27 20:01:35.904382: train loss : -0.9182\n",
      "2022-11-27 20:01:36.893228: validation loss: -0.8390\n",
      "2022-11-27 20:01:36.893576: Average global foreground Dice: [0.8946, 0.8761]\n",
      "2022-11-27 20:01:36.893630: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:01:37.251913: lr: 0.006485\n",
      "2022-11-27 20:01:37.252029: This epoch took 15.648274 s\n",
      "\n",
      "2022-11-27 20:01:37.252059: \n",
      "epoch:  382\n",
      "2022-11-27 20:01:51.502621: train loss : -0.9175\n",
      "2022-11-27 20:01:52.513942: validation loss: -0.8421\n",
      "2022-11-27 20:01:52.514441: Average global foreground Dice: [0.8955, 0.8782]\n",
      "2022-11-27 20:01:52.514520: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:01:53.051066: lr: 0.006475\n",
      "2022-11-27 20:01:53.051189: This epoch took 15.799089 s\n",
      "\n",
      "2022-11-27 20:01:53.051220: \n",
      "epoch:  383\n",
      "2022-11-27 20:02:07.314383: train loss : -0.9173\n",
      "2022-11-27 20:02:08.307126: validation loss: -0.8424\n",
      "2022-11-27 20:02:08.307514: Average global foreground Dice: [0.8947, 0.8767]\n",
      "2022-11-27 20:02:08.309441: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 20:02:08.670776: lr: 0.006466\n",
      "2022-11-27 20:02:08.670885: This epoch took 15.619638 s\n",
      "\n",
      "2022-11-27 20:02:08.670913: \n",
      "epoch:  384\n",
      "2022-11-27 20:02:22.914522: train loss : -0.9162\n",
      "2022-11-27 20:02:23.910167: validation loss: -0.8445\n",
      "2022-11-27 20:02:23.910590: Average global foreground Dice: [0.8955, 0.8785]\n",
      "2022-11-27 20:02:23.910666: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:02:24.269028: lr: 0.006456\n",
      "2022-11-27 20:02:24.269145: This epoch took 15.598189 s\n",
      "\n",
      "2022-11-27 20:02:24.269176: \n",
      "epoch:  385\n",
      "2022-11-27 20:02:38.497744: train loss : -0.9153\n",
      "2022-11-27 20:02:39.536513: validation loss: -0.8409\n",
      "2022-11-27 20:02:39.536880: Average global foreground Dice: [0.8952, 0.8779]\n",
      "2022-11-27 20:02:39.536946: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:02:39.919969: lr: 0.006447\n",
      "2022-11-27 20:02:39.920078: This epoch took 15.650875 s\n",
      "\n",
      "2022-11-27 20:02:39.920129: \n",
      "epoch:  386\n",
      "2022-11-27 20:02:54.223020: train loss : -0.9159\n",
      "2022-11-27 20:02:55.212892: validation loss: -0.8476\n",
      "2022-11-27 20:02:55.213227: Average global foreground Dice: [0.8983, 0.8823]\n",
      "2022-11-27 20:02:55.213281: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:02:55.579809: lr: 0.006437\n",
      "2022-11-27 20:02:55.579932: This epoch took 15.659758 s\n",
      "\n",
      "2022-11-27 20:02:55.579965: \n",
      "epoch:  387\n",
      "2022-11-27 20:03:09.824654: train loss : -0.9171\n",
      "2022-11-27 20:03:10.882269: validation loss: -0.8381\n",
      "2022-11-27 20:03:10.882708: Average global foreground Dice: [0.8917, 0.8748]\n",
      "2022-11-27 20:03:10.882864: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:03:11.278498: lr: 0.006428\n",
      "2022-11-27 20:03:11.278604: This epoch took 15.698612 s\n",
      "\n",
      "2022-11-27 20:03:11.278634: \n",
      "epoch:  388\n",
      "2022-11-27 20:03:25.479943: train loss : -0.9182\n",
      "2022-11-27 20:03:26.481300: validation loss: -0.8404\n",
      "2022-11-27 20:03:26.481679: Average global foreground Dice: [0.8948, 0.877]\n",
      "2022-11-27 20:03:26.481741: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:03:26.844157: lr: 0.006419\n",
      "2022-11-27 20:03:26.844259: This epoch took 15.565598 s\n",
      "\n",
      "2022-11-27 20:03:26.844286: \n",
      "epoch:  389\n",
      "2022-11-27 20:03:41.167863: train loss : -0.9192\n",
      "2022-11-27 20:03:42.197424: validation loss: -0.8473\n",
      "2022-11-27 20:03:42.197779: Average global foreground Dice: [0.8964, 0.8838]\n",
      "2022-11-27 20:03:42.197835: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:03:42.563932: lr: 0.006409\n",
      "2022-11-27 20:03:42.564035: This epoch took 15.719724 s\n",
      "\n",
      "2022-11-27 20:03:42.564061: \n",
      "epoch:  390\n",
      "2022-11-27 20:03:56.810481: train loss : -0.9178\n",
      "2022-11-27 20:03:57.794442: validation loss: -0.8394\n",
      "2022-11-27 20:03:57.794829: Average global foreground Dice: [0.8919, 0.8753]\n",
      "2022-11-27 20:03:57.794893: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:03:58.192886: lr: 0.0064\n",
      "2022-11-27 20:03:58.192989: This epoch took 15.628903 s\n",
      "\n",
      "2022-11-27 20:03:58.193019: \n",
      "epoch:  391\n",
      "2022-11-27 20:04:12.477410: train loss : -0.9167\n",
      "2022-11-27 20:04:13.459221: validation loss: -0.8431\n",
      "2022-11-27 20:04:13.459601: Average global foreground Dice: [0.8959, 0.8784]\n",
      "2022-11-27 20:04:13.459661: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:04:13.828414: lr: 0.00639\n",
      "2022-11-27 20:04:13.828532: This epoch took 15.635487 s\n",
      "\n",
      "2022-11-27 20:04:13.828561: \n",
      "epoch:  392\n",
      "2022-11-27 20:04:28.118447: train loss : -0.9173\n",
      "2022-11-27 20:04:29.126443: validation loss: -0.8449\n",
      "2022-11-27 20:04:29.126782: Average global foreground Dice: [0.8965, 0.8791]\n",
      "2022-11-27 20:04:29.126839: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:04:29.620286: lr: 0.006381\n",
      "2022-11-27 20:04:29.620420: This epoch took 15.791817 s\n",
      "\n",
      "2022-11-27 20:04:29.620450: \n",
      "epoch:  393\n",
      "2022-11-27 20:04:43.879679: train loss : -0.9167\n",
      "2022-11-27 20:04:44.866345: validation loss: -0.8418\n",
      "2022-11-27 20:04:44.866658: Average global foreground Dice: [0.8933, 0.8787]\n",
      "2022-11-27 20:04:44.866713: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:04:45.245781: lr: 0.006371\n",
      "2022-11-27 20:04:45.245887: This epoch took 15.625411 s\n",
      "\n",
      "2022-11-27 20:04:45.245924: \n",
      "epoch:  394\n",
      "2022-11-27 20:04:59.579841: train loss : -0.9175\n",
      "2022-11-27 20:05:00.585529: validation loss: -0.8419\n",
      "2022-11-27 20:05:00.585926: Average global foreground Dice: [0.8952, 0.8767]\n",
      "2022-11-27 20:05:00.586008: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:05:00.945999: lr: 0.006362\n",
      "2022-11-27 20:05:00.946110: This epoch took 15.700159 s\n",
      "\n",
      "2022-11-27 20:05:00.946140: \n",
      "epoch:  395\n",
      "2022-11-27 20:05:15.147405: train loss : -0.9183\n",
      "2022-11-27 20:05:16.159836: validation loss: -0.8431\n",
      "2022-11-27 20:05:16.160247: Average global foreground Dice: [0.895, 0.8786]\n",
      "2022-11-27 20:05:16.160318: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:05:16.527421: lr: 0.006352\n",
      "2022-11-27 20:05:16.527528: This epoch took 15.581360 s\n",
      "\n",
      "2022-11-27 20:05:16.527557: \n",
      "epoch:  396\n",
      "2022-11-27 20:05:30.785468: train loss : -0.9180\n",
      "2022-11-27 20:05:31.820667: validation loss: -0.8393\n",
      "2022-11-27 20:05:31.821061: Average global foreground Dice: [0.8943, 0.8762]\n",
      "2022-11-27 20:05:31.821120: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:05:32.180357: lr: 0.006343\n",
      "2022-11-27 20:05:32.180460: This epoch took 15.652877 s\n",
      "\n",
      "2022-11-27 20:05:32.180489: \n",
      "epoch:  397\n",
      "2022-11-27 20:05:46.411613: train loss : -0.9177\n",
      "2022-11-27 20:05:47.447171: validation loss: -0.8437\n",
      "2022-11-27 20:05:47.447564: Average global foreground Dice: [0.896, 0.8794]\n",
      "2022-11-27 20:05:47.447623: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:05:47.832403: lr: 0.006333\n",
      "2022-11-27 20:05:47.832525: This epoch took 15.651994 s\n",
      "\n",
      "2022-11-27 20:05:47.832555: \n",
      "epoch:  398\n",
      "2022-11-27 20:06:02.089512: train loss : -0.9164\n",
      "2022-11-27 20:06:03.127840: validation loss: -0.8396\n",
      "2022-11-27 20:06:03.128281: Average global foreground Dice: [0.8954, 0.8774]\n",
      "2022-11-27 20:06:03.128360: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:06:03.487715: lr: 0.006324\n",
      "2022-11-27 20:06:03.487845: This epoch took 15.655248 s\n",
      "\n",
      "2022-11-27 20:06:03.487874: \n",
      "epoch:  399\n",
      "2022-11-27 20:06:17.741643: train loss : -0.9170\n",
      "2022-11-27 20:06:18.747928: validation loss: -0.8428\n",
      "2022-11-27 20:06:18.748255: Average global foreground Dice: [0.8944, 0.879]\n",
      "2022-11-27 20:06:18.748308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:06:19.109472: lr: 0.006314\n",
      "2022-11-27 20:06:19.109579: saving scheduled checkpoint file...\n",
      "2022-11-27 20:06:19.113531: saving checkpoint...\n",
      "2022-11-27 20:06:19.180373: done, saving took 0.07 seconds\n",
      "2022-11-27 20:06:19.185503: done\n",
      "2022-11-27 20:06:19.185684: This epoch took 15.697780 s\n",
      "\n",
      "2022-11-27 20:06:19.185777: \n",
      "epoch:  400\n",
      "2022-11-27 20:06:33.415001: train loss : -0.9187\n",
      "2022-11-27 20:06:34.415373: validation loss: -0.8443\n",
      "2022-11-27 20:06:34.415815: Average global foreground Dice: [0.8949, 0.8818]\n",
      "2022-11-27 20:06:34.415893: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:06:34.783163: lr: 0.006305\n",
      "2022-11-27 20:06:34.783271: This epoch took 15.597409 s\n",
      "\n",
      "2022-11-27 20:06:34.783301: \n",
      "epoch:  401\n",
      "2022-11-27 20:06:49.006412: train loss : -0.9190\n",
      "2022-11-27 20:06:50.005948: validation loss: -0.8380\n",
      "2022-11-27 20:06:50.006283: Average global foreground Dice: [0.8919, 0.8766]\n",
      "2022-11-27 20:06:50.006345: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:06:50.469109: lr: 0.006296\n",
      "2022-11-27 20:06:50.469235: This epoch took 15.685890 s\n",
      "\n",
      "2022-11-27 20:06:50.469264: \n",
      "epoch:  402\n",
      "2022-11-27 20:07:04.693580: train loss : -0.9197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 20:07:05.703354: validation loss: -0.8448\n",
      "2022-11-27 20:07:05.703728: Average global foreground Dice: [0.8958, 0.8794]\n",
      "2022-11-27 20:07:05.703788: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:07:06.076487: lr: 0.006286\n",
      "2022-11-27 20:07:06.076597: This epoch took 15.607306 s\n",
      "\n",
      "2022-11-27 20:07:06.076624: \n",
      "epoch:  403\n",
      "2022-11-27 20:07:20.336668: train loss : -0.9197\n",
      "2022-11-27 20:07:21.354919: validation loss: -0.8447\n",
      "2022-11-27 20:07:21.355279: Average global foreground Dice: [0.8956, 0.882]\n",
      "2022-11-27 20:07:21.355390: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:07:21.715786: lr: 0.006277\n",
      "2022-11-27 20:07:21.715895: This epoch took 15.639241 s\n",
      "\n",
      "2022-11-27 20:07:21.715924: \n",
      "epoch:  404\n",
      "2022-11-27 20:07:36.008450: train loss : -0.9176\n",
      "2022-11-27 20:07:37.004854: validation loss: -0.8362\n",
      "2022-11-27 20:07:37.005225: Average global foreground Dice: [0.8901, 0.8741]\n",
      "2022-11-27 20:07:37.005283: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:07:37.358661: lr: 0.006267\n",
      "2022-11-27 20:07:37.358783: This epoch took 15.642819 s\n",
      "\n",
      "2022-11-27 20:07:37.358813: \n",
      "epoch:  405\n",
      "2022-11-27 20:07:51.603224: train loss : -0.9194\n",
      "2022-11-27 20:07:52.617728: validation loss: -0.8411\n",
      "2022-11-27 20:07:52.618178: Average global foreground Dice: [0.8943, 0.8785]\n",
      "2022-11-27 20:07:52.618254: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:07:52.974148: lr: 0.006258\n",
      "2022-11-27 20:07:52.974279: This epoch took 15.615439 s\n",
      "\n",
      "2022-11-27 20:07:52.974323: \n",
      "epoch:  406\n",
      "2022-11-27 20:08:07.228866: train loss : -0.9179\n",
      "2022-11-27 20:08:08.216551: validation loss: -0.8418\n",
      "2022-11-27 20:08:08.216893: Average global foreground Dice: [0.8943, 0.879]\n",
      "2022-11-27 20:08:08.216948: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:08:08.591615: lr: 0.006248\n",
      "2022-11-27 20:08:08.591841: This epoch took 15.617481 s\n",
      "\n",
      "2022-11-27 20:08:08.591872: \n",
      "epoch:  407\n",
      "2022-11-27 20:08:22.821241: train loss : -0.9188\n",
      "2022-11-27 20:08:23.858041: validation loss: -0.8382\n",
      "2022-11-27 20:08:23.858469: Average global foreground Dice: [0.8924, 0.8769]\n",
      "2022-11-27 20:08:23.858619: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:08:24.217678: lr: 0.006239\n",
      "2022-11-27 20:08:24.217786: This epoch took 15.625886 s\n",
      "\n",
      "2022-11-27 20:08:24.217816: \n",
      "epoch:  408\n",
      "2022-11-27 20:08:38.446589: train loss : -0.9176\n",
      "2022-11-27 20:08:39.438353: validation loss: -0.8440\n",
      "2022-11-27 20:08:39.438696: Average global foreground Dice: [0.8968, 0.8808]\n",
      "2022-11-27 20:08:39.438752: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:08:39.802828: lr: 0.006229\n",
      "2022-11-27 20:08:39.802933: This epoch took 15.585091 s\n",
      "\n",
      "2022-11-27 20:08:39.802963: \n",
      "epoch:  409\n",
      "2022-11-27 20:08:54.100829: train loss : -0.9170\n",
      "2022-11-27 20:08:55.113170: validation loss: -0.8462\n",
      "2022-11-27 20:08:55.113618: Average global foreground Dice: [0.8952, 0.8815]\n",
      "2022-11-27 20:08:55.113826: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:08:55.472752: lr: 0.00622\n",
      "2022-11-27 20:08:55.472881: This epoch took 15.669876 s\n",
      "\n",
      "2022-11-27 20:08:55.472911: \n",
      "epoch:  410\n",
      "2022-11-27 20:09:09.690478: train loss : -0.9177\n",
      "2022-11-27 20:09:10.699192: validation loss: -0.8415\n",
      "2022-11-27 20:09:10.699569: Average global foreground Dice: [0.8945, 0.8774]\n",
      "2022-11-27 20:09:10.699680: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:09:11.060136: lr: 0.00621\n",
      "2022-11-27 20:09:11.060243: This epoch took 15.587306 s\n",
      "\n",
      "2022-11-27 20:09:11.060271: \n",
      "epoch:  411\n",
      "2022-11-27 20:09:25.316378: train loss : -0.9179\n",
      "2022-11-27 20:09:26.328117: validation loss: -0.8447\n",
      "2022-11-27 20:09:26.328563: Average global foreground Dice: [0.897, 0.8798]\n",
      "2022-11-27 20:09:26.328634: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:09:26.797806: lr: 0.006201\n",
      "2022-11-27 20:09:26.797925: This epoch took 15.737628 s\n",
      "\n",
      "2022-11-27 20:09:26.797973: \n",
      "epoch:  412\n",
      "2022-11-27 20:09:41.052253: train loss : -0.9162\n",
      "2022-11-27 20:09:42.043573: validation loss: -0.8383\n",
      "2022-11-27 20:09:42.043905: Average global foreground Dice: [0.8919, 0.8758]\n",
      "2022-11-27 20:09:42.044134: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:09:42.418558: lr: 0.006191\n",
      "2022-11-27 20:09:42.418681: This epoch took 15.620681 s\n",
      "\n",
      "2022-11-27 20:09:42.418710: \n",
      "epoch:  413\n",
      "2022-11-27 20:09:56.697011: train loss : -0.9183\n",
      "2022-11-27 20:09:57.723363: validation loss: -0.8349\n",
      "2022-11-27 20:09:57.723742: Average global foreground Dice: [0.8893, 0.8737]\n",
      "2022-11-27 20:09:57.723802: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:09:58.071025: lr: 0.006182\n",
      "2022-11-27 20:09:58.071139: This epoch took 15.652400 s\n",
      "\n",
      "2022-11-27 20:09:58.071173: \n",
      "epoch:  414\n",
      "2022-11-27 20:10:12.347450: train loss : -0.9185\n",
      "2022-11-27 20:10:13.368582: validation loss: -0.8426\n",
      "2022-11-27 20:10:13.368980: Average global foreground Dice: [0.8956, 0.8777]\n",
      "2022-11-27 20:10:13.369048: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:10:13.717200: lr: 0.006172\n",
      "2022-11-27 20:10:13.717307: This epoch took 15.646104 s\n",
      "\n",
      "2022-11-27 20:10:13.717333: \n",
      "epoch:  415\n",
      "2022-11-27 20:10:27.927043: train loss : -0.9196\n",
      "2022-11-27 20:10:28.962728: validation loss: -0.8423\n",
      "2022-11-27 20:10:28.963199: Average global foreground Dice: [0.8948, 0.8768]\n",
      "2022-11-27 20:10:28.963289: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:10:29.333416: lr: 0.006163\n",
      "2022-11-27 20:10:29.333524: This epoch took 15.616163 s\n",
      "\n",
      "2022-11-27 20:10:29.333569: \n",
      "epoch:  416\n",
      "2022-11-27 20:10:43.574731: train loss : -0.9185\n",
      "2022-11-27 20:10:44.593427: validation loss: -0.8442\n",
      "2022-11-27 20:10:44.593807: Average global foreground Dice: [0.8951, 0.8795]\n",
      "2022-11-27 20:10:44.593867: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:10:44.942695: lr: 0.006153\n",
      "2022-11-27 20:10:44.942803: This epoch took 15.609208 s\n",
      "\n",
      "2022-11-27 20:10:44.942834: \n",
      "epoch:  417\n",
      "2022-11-27 20:10:59.241735: train loss : -0.9192\n",
      "2022-11-27 20:11:00.241769: validation loss: -0.8403\n",
      "2022-11-27 20:11:00.242137: Average global foreground Dice: [0.8949, 0.8776]\n",
      "2022-11-27 20:11:00.242205: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:11:00.589702: lr: 0.006144\n",
      "2022-11-27 20:11:00.589812: This epoch took 15.646950 s\n",
      "\n",
      "2022-11-27 20:11:00.589912: \n",
      "epoch:  418\n",
      "2022-11-27 20:11:14.803177: train loss : -0.9185\n",
      "2022-11-27 20:11:15.811800: validation loss: -0.8446\n",
      "2022-11-27 20:11:15.812267: Average global foreground Dice: [0.8963, 0.8825]\n",
      "2022-11-27 20:11:15.812338: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:11:16.164296: lr: 0.006134\n",
      "2022-11-27 20:11:16.164403: This epoch took 15.574446 s\n",
      "\n",
      "2022-11-27 20:11:16.164434: \n",
      "epoch:  419\n",
      "2022-11-27 20:11:30.392565: train loss : -0.9176\n",
      "2022-11-27 20:11:31.403406: validation loss: -0.8414\n",
      "2022-11-27 20:11:31.403765: Average global foreground Dice: [0.8951, 0.8775]\n",
      "2022-11-27 20:11:31.403828: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:11:31.751653: lr: 0.006125\n",
      "2022-11-27 20:11:31.751760: This epoch took 15.587299 s\n",
      "\n",
      "2022-11-27 20:11:31.751796: \n",
      "epoch:  420\n",
      "2022-11-27 20:11:46.034473: train loss : -0.9177\n",
      "2022-11-27 20:11:47.033622: validation loss: -0.8403\n",
      "2022-11-27 20:11:47.033977: Average global foreground Dice: [0.8921, 0.8785]\n",
      "2022-11-27 20:11:47.034038: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:11:47.419533: lr: 0.006115\n",
      "2022-11-27 20:11:47.419633: This epoch took 15.667805 s\n",
      "\n",
      "2022-11-27 20:11:47.419661: \n",
      "epoch:  421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 20:12:01.660494: train loss : -0.9197\n",
      "2022-11-27 20:12:02.647184: validation loss: -0.8425\n",
      "2022-11-27 20:12:02.647568: Average global foreground Dice: [0.8951, 0.8801]\n",
      "2022-11-27 20:12:02.647628: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:12:03.004224: lr: 0.006106\n",
      "2022-11-27 20:12:03.004324: This epoch took 15.584639 s\n",
      "\n",
      "2022-11-27 20:12:03.004351: \n",
      "epoch:  422\n",
      "2022-11-27 20:12:17.236181: train loss : -0.9184\n",
      "2022-11-27 20:12:18.260613: validation loss: -0.8344\n",
      "2022-11-27 20:12:18.261024: Average global foreground Dice: [0.8888, 0.875]\n",
      "2022-11-27 20:12:18.261197: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:12:18.771327: lr: 0.006096\n",
      "2022-11-27 20:12:18.771465: This epoch took 15.767068 s\n",
      "\n",
      "2022-11-27 20:12:18.771496: \n",
      "epoch:  423\n",
      "2022-11-27 20:12:33.038159: train loss : -0.9187\n",
      "2022-11-27 20:12:34.057429: validation loss: -0.8440\n",
      "2022-11-27 20:12:34.057764: Average global foreground Dice: [0.8958, 0.8813]\n",
      "2022-11-27 20:12:34.057827: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:12:34.411861: lr: 0.006087\n",
      "2022-11-27 20:12:34.411984: This epoch took 15.640446 s\n",
      "\n",
      "2022-11-27 20:12:34.412015: \n",
      "epoch:  424\n",
      "2022-11-27 20:12:48.708686: train loss : -0.9193\n",
      "2022-11-27 20:12:49.741117: validation loss: -0.8383\n",
      "2022-11-27 20:12:49.741459: Average global foreground Dice: [0.8934, 0.8771]\n",
      "2022-11-27 20:12:49.741520: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:12:50.120149: lr: 0.006077\n",
      "2022-11-27 20:12:50.120256: This epoch took 15.708215 s\n",
      "\n",
      "2022-11-27 20:12:50.120283: \n",
      "epoch:  425\n",
      "2022-11-27 20:13:04.398446: train loss : -0.9185\n",
      "2022-11-27 20:13:05.386840: validation loss: -0.8393\n",
      "2022-11-27 20:13:05.387225: Average global foreground Dice: [0.8929, 0.8775]\n",
      "2022-11-27 20:13:05.387288: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:13:05.757121: lr: 0.006068\n",
      "2022-11-27 20:13:05.757229: This epoch took 15.636917 s\n",
      "\n",
      "2022-11-27 20:13:05.757257: \n",
      "epoch:  426\n",
      "2022-11-27 20:13:20.048406: train loss : -0.9195\n",
      "2022-11-27 20:13:21.053076: validation loss: -0.8380\n",
      "2022-11-27 20:13:21.053501: Average global foreground Dice: [0.8924, 0.8744]\n",
      "2022-11-27 20:13:21.053581: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:13:21.412244: lr: 0.006058\n",
      "2022-11-27 20:13:21.412352: This epoch took 15.655069 s\n",
      "\n",
      "2022-11-27 20:13:21.412380: \n",
      "epoch:  427\n",
      "2022-11-27 20:13:35.649363: train loss : -0.9185\n",
      "2022-11-27 20:13:36.643795: validation loss: -0.8396\n",
      "2022-11-27 20:13:36.644286: Average global foreground Dice: [0.8935, 0.8787]\n",
      "2022-11-27 20:13:36.644373: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:13:37.002102: lr: 0.006049\n",
      "2022-11-27 20:13:37.002210: This epoch took 15.589805 s\n",
      "\n",
      "2022-11-27 20:13:37.002239: \n",
      "epoch:  428\n",
      "2022-11-27 20:13:51.239575: train loss : -0.9185\n",
      "2022-11-27 20:13:52.250586: validation loss: -0.8415\n",
      "2022-11-27 20:13:52.250918: Average global foreground Dice: [0.894, 0.8785]\n",
      "2022-11-27 20:13:52.250973: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:13:52.625052: lr: 0.006039\n",
      "2022-11-27 20:13:52.625154: This epoch took 15.622888 s\n",
      "\n",
      "2022-11-27 20:13:52.625180: \n",
      "epoch:  429\n",
      "2022-11-27 20:14:06.895337: train loss : -0.9203\n",
      "2022-11-27 20:14:07.887264: validation loss: -0.8413\n",
      "2022-11-27 20:14:07.887603: Average global foreground Dice: [0.8966, 0.8779]\n",
      "2022-11-27 20:14:07.887663: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:14:08.244160: lr: 0.00603\n",
      "2022-11-27 20:14:08.244282: This epoch took 15.619061 s\n",
      "\n",
      "2022-11-27 20:14:08.244312: \n",
      "epoch:  430\n",
      "2022-11-27 20:14:22.497549: train loss : -0.9188\n",
      "2022-11-27 20:14:23.502109: validation loss: -0.8425\n",
      "2022-11-27 20:14:23.502473: Average global foreground Dice: [0.8966, 0.8796]\n",
      "2022-11-27 20:14:23.502529: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:14:23.857777: lr: 0.00602\n",
      "2022-11-27 20:14:23.857905: This epoch took 15.613546 s\n",
      "\n",
      "2022-11-27 20:14:23.857936: \n",
      "epoch:  431\n",
      "2022-11-27 20:14:38.140642: train loss : -0.9198\n",
      "2022-11-27 20:14:39.173476: validation loss: -0.8435\n",
      "2022-11-27 20:14:39.173967: Average global foreground Dice: [0.8969, 0.8806]\n",
      "2022-11-27 20:14:39.174056: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:14:39.551154: lr: 0.006011\n",
      "2022-11-27 20:14:39.551251: This epoch took 15.693288 s\n",
      "\n",
      "2022-11-27 20:14:39.551277: \n",
      "epoch:  432\n",
      "2022-11-27 20:14:53.836472: train loss : -0.9177\n",
      "2022-11-27 20:14:54.846575: validation loss: -0.8417\n",
      "2022-11-27 20:14:54.846961: Average global foreground Dice: [0.8941, 0.878]\n",
      "2022-11-27 20:14:54.847024: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:14:55.225178: lr: 0.006001\n",
      "2022-11-27 20:14:55.225283: This epoch took 15.673981 s\n",
      "\n",
      "2022-11-27 20:14:55.225313: \n",
      "epoch:  433\n",
      "2022-11-27 20:15:09.475689: train loss : -0.9195\n",
      "2022-11-27 20:15:10.481222: validation loss: -0.8402\n",
      "2022-11-27 20:15:10.481611: Average global foreground Dice: [0.8945, 0.8774]\n",
      "2022-11-27 20:15:10.481691: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:15:10.971061: lr: 0.005991\n",
      "2022-11-27 20:15:10.971194: This epoch took 15.745854 s\n",
      "\n",
      "2022-11-27 20:15:10.971221: \n",
      "epoch:  434\n",
      "2022-11-27 20:15:25.264072: train loss : -0.9184\n",
      "2022-11-27 20:15:26.287071: validation loss: -0.8412\n",
      "2022-11-27 20:15:26.287395: Average global foreground Dice: [0.893, 0.8776]\n",
      "2022-11-27 20:15:26.287453: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:15:26.641044: lr: 0.005982\n",
      "2022-11-27 20:15:26.641157: This epoch took 15.669911 s\n",
      "\n",
      "2022-11-27 20:15:26.641186: \n",
      "epoch:  435\n",
      "2022-11-27 20:15:40.904527: train loss : -0.9202\n",
      "2022-11-27 20:15:41.888770: validation loss: -0.8483\n",
      "2022-11-27 20:15:41.889144: Average global foreground Dice: [0.8999, 0.8811]\n",
      "2022-11-27 20:15:41.889262: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:15:42.249310: lr: 0.005972\n",
      "2022-11-27 20:15:42.249423: This epoch took 15.608209 s\n",
      "\n",
      "2022-11-27 20:15:42.249452: \n",
      "epoch:  436\n",
      "2022-11-27 20:15:56.570182: train loss : -0.9190\n",
      "2022-11-27 20:15:57.566380: validation loss: -0.8412\n",
      "2022-11-27 20:15:57.566765: Average global foreground Dice: [0.8947, 0.8777]\n",
      "2022-11-27 20:15:57.566830: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:15:57.920938: lr: 0.005963\n",
      "2022-11-27 20:15:57.921044: This epoch took 15.671566 s\n",
      "\n",
      "2022-11-27 20:15:57.921073: \n",
      "epoch:  437\n",
      "2022-11-27 20:16:12.171165: train loss : -0.9197\n",
      "2022-11-27 20:16:13.165377: validation loss: -0.8396\n",
      "2022-11-27 20:16:13.165757: Average global foreground Dice: [0.8926, 0.8768]\n",
      "2022-11-27 20:16:13.165816: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:16:13.533843: lr: 0.005953\n",
      "2022-11-27 20:16:13.533959: This epoch took 15.612858 s\n",
      "\n",
      "2022-11-27 20:16:13.533992: \n",
      "epoch:  438\n",
      "2022-11-27 20:16:27.788166: train loss : -0.9181\n",
      "2022-11-27 20:16:28.819052: validation loss: -0.8475\n",
      "2022-11-27 20:16:28.819394: Average global foreground Dice: [0.8975, 0.8809]\n",
      "2022-11-27 20:16:28.819457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:16:29.177922: lr: 0.005944\n",
      "2022-11-27 20:16:29.178033: This epoch took 15.644015 s\n",
      "\n",
      "2022-11-27 20:16:29.178062: \n",
      "epoch:  439\n",
      "2022-11-27 20:16:43.440249: train loss : -0.9179\n",
      "2022-11-27 20:16:44.455310: validation loss: -0.8407\n",
      "2022-11-27 20:16:44.455706: Average global foreground Dice: [0.8941, 0.8757]\n",
      "2022-11-27 20:16:44.455782: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:16:44.828915: lr: 0.005934\n",
      "2022-11-27 20:16:44.829036: This epoch took 15.650931 s\n",
      "\n",
      "2022-11-27 20:16:44.829066: \n",
      "epoch:  440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 20:16:59.179266: train loss : -0.9191\n",
      "2022-11-27 20:17:00.194684: validation loss: -0.8397\n",
      "2022-11-27 20:17:00.195018: Average global foreground Dice: [0.8935, 0.8776]\n",
      "2022-11-27 20:17:00.195072: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:17:00.549273: lr: 0.005925\n",
      "2022-11-27 20:17:00.549376: This epoch took 15.720284 s\n",
      "\n",
      "2022-11-27 20:17:00.549403: \n",
      "epoch:  441\n",
      "2022-11-27 20:17:14.827979: train loss : -0.9184\n",
      "2022-11-27 20:17:15.835136: validation loss: -0.8383\n",
      "2022-11-27 20:17:15.835641: Average global foreground Dice: [0.8927, 0.8739]\n",
      "2022-11-27 20:17:15.835729: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:17:16.193702: lr: 0.005915\n",
      "2022-11-27 20:17:16.193801: This epoch took 15.644374 s\n",
      "\n",
      "2022-11-27 20:17:16.193827: \n",
      "epoch:  442\n",
      "2022-11-27 20:17:30.476636: train loss : -0.9190\n",
      "2022-11-27 20:17:31.455565: validation loss: -0.8432\n",
      "2022-11-27 20:17:31.455901: Average global foreground Dice: [0.8971, 0.8808]\n",
      "2022-11-27 20:17:31.455956: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:17:31.809133: lr: 0.005906\n",
      "2022-11-27 20:17:31.809237: This epoch took 15.615384 s\n",
      "\n",
      "2022-11-27 20:17:31.809265: \n",
      "epoch:  443\n",
      "2022-11-27 20:17:46.069540: train loss : -0.9178\n",
      "2022-11-27 20:17:47.060819: validation loss: -0.8412\n",
      "2022-11-27 20:17:47.061208: Average global foreground Dice: [0.894, 0.8772]\n",
      "2022-11-27 20:17:47.061271: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:17:47.533350: lr: 0.005896\n",
      "2022-11-27 20:17:47.533458: This epoch took 15.724167 s\n",
      "\n",
      "2022-11-27 20:17:47.533490: \n",
      "epoch:  444\n",
      "2022-11-27 20:18:01.859919: train loss : -0.9171\n",
      "2022-11-27 20:18:02.842023: validation loss: -0.8386\n",
      "2022-11-27 20:18:02.842399: Average global foreground Dice: [0.8934, 0.8753]\n",
      "2022-11-27 20:18:02.842459: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:18:03.192202: lr: 0.005887\n",
      "2022-11-27 20:18:03.192312: This epoch took 15.658797 s\n",
      "\n",
      "2022-11-27 20:18:03.192338: \n",
      "epoch:  445\n",
      "2022-11-27 20:18:17.477953: train loss : -0.9199\n",
      "2022-11-27 20:18:18.485504: validation loss: -0.8439\n",
      "2022-11-27 20:18:18.485841: Average global foreground Dice: [0.8967, 0.8791]\n",
      "2022-11-27 20:18:18.485905: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:18:18.832765: lr: 0.005877\n",
      "2022-11-27 20:18:18.832870: This epoch took 15.640508 s\n",
      "\n",
      "2022-11-27 20:18:18.832897: \n",
      "epoch:  446\n",
      "2022-11-27 20:18:33.106956: train loss : -0.9192\n",
      "2022-11-27 20:18:34.102863: validation loss: -0.8398\n",
      "2022-11-27 20:18:34.103196: Average global foreground Dice: [0.8939, 0.8766]\n",
      "2022-11-27 20:18:34.103254: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:18:34.459422: lr: 0.005867\n",
      "2022-11-27 20:18:34.459540: This epoch took 15.626601 s\n",
      "\n",
      "2022-11-27 20:18:34.459573: \n",
      "epoch:  447\n",
      "2022-11-27 20:18:48.684067: train loss : -0.9192\n",
      "2022-11-27 20:18:49.684825: validation loss: -0.8403\n",
      "2022-11-27 20:18:49.685150: Average global foreground Dice: [0.8956, 0.877]\n",
      "2022-11-27 20:18:49.685209: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:18:50.037337: lr: 0.005858\n",
      "2022-11-27 20:18:50.037444: This epoch took 15.577844 s\n",
      "\n",
      "2022-11-27 20:18:50.037470: \n",
      "epoch:  448\n",
      "2022-11-27 20:19:04.301218: train loss : -0.9188\n",
      "2022-11-27 20:19:05.317950: validation loss: -0.8391\n",
      "2022-11-27 20:19:05.318349: Average global foreground Dice: [0.8956, 0.8761]\n",
      "2022-11-27 20:19:05.318417: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:19:05.667916: lr: 0.005848\n",
      "2022-11-27 20:19:05.668024: This epoch took 15.630530 s\n",
      "\n",
      "2022-11-27 20:19:05.668057: \n",
      "epoch:  449\n",
      "2022-11-27 20:19:19.877167: train loss : -0.9188\n",
      "2022-11-27 20:19:20.908899: validation loss: -0.8388\n",
      "2022-11-27 20:19:20.909286: Average global foreground Dice: [0.8927, 0.8757]\n",
      "2022-11-27 20:19:20.909348: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:19:21.258381: lr: 0.005839\n",
      "2022-11-27 20:19:21.258469: saving scheduled checkpoint file...\n",
      "2022-11-27 20:19:21.262508: saving checkpoint...\n",
      "2022-11-27 20:19:21.326189: done, saving took 0.07 seconds\n",
      "2022-11-27 20:19:21.328118: done\n",
      "2022-11-27 20:19:21.328193: This epoch took 15.660106 s\n",
      "\n",
      "2022-11-27 20:19:21.328222: \n",
      "epoch:  450\n",
      "2022-11-27 20:19:35.593739: train loss : -0.9188\n",
      "2022-11-27 20:19:36.606790: validation loss: -0.8482\n",
      "2022-11-27 20:19:36.607180: Average global foreground Dice: [0.8996, 0.8813]\n",
      "2022-11-27 20:19:36.607238: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:19:36.963791: lr: 0.005829\n",
      "2022-11-27 20:19:36.963899: This epoch took 15.635650 s\n",
      "\n",
      "2022-11-27 20:19:36.963932: \n",
      "epoch:  451\n",
      "2022-11-27 20:19:51.195481: train loss : -0.9196\n",
      "2022-11-27 20:19:52.221586: validation loss: -0.8449\n",
      "2022-11-27 20:19:52.221970: Average global foreground Dice: [0.8975, 0.8798]\n",
      "2022-11-27 20:19:52.222031: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:19:52.572912: lr: 0.00582\n",
      "2022-11-27 20:19:52.573016: This epoch took 15.609055 s\n",
      "\n",
      "2022-11-27 20:19:52.573044: \n",
      "epoch:  452\n",
      "2022-11-27 20:20:06.878828: train loss : -0.9198\n",
      "2022-11-27 20:20:07.919438: validation loss: -0.8414\n",
      "2022-11-27 20:20:07.919883: Average global foreground Dice: [0.8918, 0.8772]\n",
      "2022-11-27 20:20:07.919959: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:20:08.272777: lr: 0.00581\n",
      "2022-11-27 20:20:08.272882: This epoch took 15.699811 s\n",
      "\n",
      "2022-11-27 20:20:08.272911: \n",
      "epoch:  453\n",
      "2022-11-27 20:20:22.534767: train loss : -0.9193\n",
      "2022-11-27 20:20:23.530734: validation loss: -0.8400\n",
      "2022-11-27 20:20:23.531075: Average global foreground Dice: [0.8954, 0.8778]\n",
      "2022-11-27 20:20:23.531132: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:20:23.881365: lr: 0.005801\n",
      "2022-11-27 20:20:23.881467: This epoch took 15.608529 s\n",
      "\n",
      "2022-11-27 20:20:23.881495: \n",
      "epoch:  454\n",
      "2022-11-27 20:20:38.158356: train loss : -0.9196\n",
      "2022-11-27 20:20:39.144400: validation loss: -0.8345\n",
      "2022-11-27 20:20:39.144754: Average global foreground Dice: [0.8908, 0.8725]\n",
      "2022-11-27 20:20:39.144835: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:20:39.642117: lr: 0.005791\n",
      "2022-11-27 20:20:39.642234: This epoch took 15.760711 s\n",
      "\n",
      "2022-11-27 20:20:39.642262: \n",
      "epoch:  455\n",
      "2022-11-27 20:20:53.941516: train loss : -0.9186\n",
      "2022-11-27 20:20:54.938950: validation loss: -0.8400\n",
      "2022-11-27 20:20:54.939325: Average global foreground Dice: [0.8933, 0.8771]\n",
      "2022-11-27 20:20:54.939387: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:20:55.293407: lr: 0.005781\n",
      "2022-11-27 20:20:55.293516: This epoch took 15.651220 s\n",
      "\n",
      "2022-11-27 20:20:55.293561: \n",
      "epoch:  456\n",
      "2022-11-27 20:21:09.584442: train loss : -0.9198\n",
      "2022-11-27 20:21:10.575924: validation loss: -0.8404\n",
      "2022-11-27 20:21:10.576257: Average global foreground Dice: [0.8964, 0.878]\n",
      "2022-11-27 20:21:10.576322: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:21:10.959562: lr: 0.005772\n",
      "2022-11-27 20:21:10.959680: This epoch took 15.666091 s\n",
      "\n",
      "2022-11-27 20:21:10.959709: \n",
      "epoch:  457\n",
      "2022-11-27 20:21:25.240039: train loss : -0.9203\n",
      "2022-11-27 20:21:26.226570: validation loss: -0.8429\n",
      "2022-11-27 20:21:26.226902: Average global foreground Dice: [0.897, 0.8796]\n",
      "2022-11-27 20:21:26.226962: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:21:26.586111: lr: 0.005762\n",
      "2022-11-27 20:21:26.586219: This epoch took 15.626483 s\n",
      "\n",
      "2022-11-27 20:21:26.586248: \n",
      "epoch:  458\n",
      "2022-11-27 20:21:40.857615: train loss : -0.9206\n",
      "2022-11-27 20:21:41.853960: validation loss: -0.8449\n",
      "2022-11-27 20:21:41.854344: Average global foreground Dice: [0.8944, 0.8798]\n",
      "2022-11-27 20:21:41.854399: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 20:21:42.215542: lr: 0.005753\n",
      "2022-11-27 20:21:42.215662: This epoch took 15.629372 s\n",
      "\n",
      "2022-11-27 20:21:42.215693: \n",
      "epoch:  459\n",
      "2022-11-27 20:21:56.443270: train loss : -0.9193\n",
      "2022-11-27 20:21:57.438228: validation loss: -0.8433\n",
      "2022-11-27 20:21:57.438618: Average global foreground Dice: [0.8968, 0.8807]\n",
      "2022-11-27 20:21:57.438773: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:21:57.797779: lr: 0.005743\n",
      "2022-11-27 20:21:57.797888: This epoch took 15.582169 s\n",
      "\n",
      "2022-11-27 20:21:57.797930: \n",
      "epoch:  460\n",
      "2022-11-27 20:22:12.076145: train loss : -0.9200\n",
      "2022-11-27 20:22:13.114953: validation loss: -0.8481\n",
      "2022-11-27 20:22:13.115333: Average global foreground Dice: [0.8986, 0.8821]\n",
      "2022-11-27 20:22:13.115394: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:22:13.485707: lr: 0.005734\n",
      "2022-11-27 20:22:13.485816: This epoch took 15.687855 s\n",
      "\n",
      "2022-11-27 20:22:13.485846: \n",
      "epoch:  461\n",
      "2022-11-27 20:22:27.816825: train loss : -0.9213\n",
      "2022-11-27 20:22:28.882768: validation loss: -0.8399\n",
      "2022-11-27 20:22:28.883155: Average global foreground Dice: [0.8938, 0.8764]\n",
      "2022-11-27 20:22:28.883214: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:22:29.239690: lr: 0.005724\n",
      "2022-11-27 20:22:29.239826: This epoch took 15.753954 s\n",
      "\n",
      "2022-11-27 20:22:29.239856: \n",
      "epoch:  462\n",
      "2022-11-27 20:22:43.583717: train loss : -0.9191\n",
      "2022-11-27 20:22:44.571397: validation loss: -0.8453\n",
      "2022-11-27 20:22:44.571733: Average global foreground Dice: [0.897, 0.8805]\n",
      "2022-11-27 20:22:44.571983: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:22:44.935872: lr: 0.005714\n",
      "2022-11-27 20:22:44.935993: This epoch took 15.696095 s\n",
      "\n",
      "2022-11-27 20:22:44.936023: \n",
      "epoch:  463\n",
      "2022-11-27 20:22:59.200266: train loss : -0.9196\n",
      "2022-11-27 20:23:00.204749: validation loss: -0.8447\n",
      "2022-11-27 20:23:00.205295: Average global foreground Dice: [0.8986, 0.8798]\n",
      "2022-11-27 20:23:00.206183: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:23:00.601887: lr: 0.005705\n",
      "2022-11-27 20:23:00.605834: saving checkpoint...\n",
      "2022-11-27 20:23:00.671547: done, saving took 0.07 seconds\n",
      "2022-11-27 20:23:00.673791: This epoch took 15.737730 s\n",
      "\n",
      "2022-11-27 20:23:00.673860: \n",
      "epoch:  464\n",
      "2022-11-27 20:23:14.915901: train loss : -0.9218\n",
      "2022-11-27 20:23:15.903146: validation loss: -0.8443\n",
      "2022-11-27 20:23:15.903629: Average global foreground Dice: [0.897, 0.8806]\n",
      "2022-11-27 20:23:15.903927: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:23:16.362791: lr: 0.005695\n",
      "2022-11-27 20:23:16.366920: saving checkpoint...\n",
      "2022-11-27 20:23:16.432159: done, saving took 0.07 seconds\n",
      "2022-11-27 20:23:16.433979: This epoch took 15.760087 s\n",
      "\n",
      "2022-11-27 20:23:16.434035: \n",
      "epoch:  465\n",
      "2022-11-27 20:23:30.738280: train loss : -0.9206\n",
      "2022-11-27 20:23:31.750466: validation loss: -0.8407\n",
      "2022-11-27 20:23:31.750870: Average global foreground Dice: [0.8957, 0.8784]\n",
      "2022-11-27 20:23:31.750930: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:23:32.101154: lr: 0.005686\n",
      "2022-11-27 20:23:32.101282: This epoch took 15.667218 s\n",
      "\n",
      "2022-11-27 20:23:32.101310: \n",
      "epoch:  466\n",
      "2022-11-27 20:23:46.369425: train loss : -0.9193\n",
      "2022-11-27 20:23:47.415421: validation loss: -0.8357\n",
      "2022-11-27 20:23:47.415865: Average global foreground Dice: [0.8931, 0.8732]\n",
      "2022-11-27 20:23:47.415965: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:23:47.771919: lr: 0.005676\n",
      "2022-11-27 20:23:47.772032: This epoch took 15.670694 s\n",
      "\n",
      "2022-11-27 20:23:47.772073: \n",
      "epoch:  467\n",
      "2022-11-27 20:24:02.063572: train loss : -0.9198\n",
      "2022-11-27 20:24:03.071283: validation loss: -0.8429\n",
      "2022-11-27 20:24:03.071710: Average global foreground Dice: [0.8954, 0.8805]\n",
      "2022-11-27 20:24:03.071776: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:24:03.424258: lr: 0.005667\n",
      "2022-11-27 20:24:03.424370: This epoch took 15.652267 s\n",
      "\n",
      "2022-11-27 20:24:03.424400: \n",
      "epoch:  468\n",
      "2022-11-27 20:24:17.693789: train loss : -0.9211\n",
      "2022-11-27 20:24:18.703057: validation loss: -0.8401\n",
      "2022-11-27 20:24:18.703428: Average global foreground Dice: [0.8949, 0.8796]\n",
      "2022-11-27 20:24:18.703519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:24:19.054615: lr: 0.005657\n",
      "2022-11-27 20:24:19.054724: This epoch took 15.630299 s\n",
      "\n",
      "2022-11-27 20:24:19.054754: \n",
      "epoch:  469\n",
      "2022-11-27 20:24:33.299470: train loss : -0.9222\n",
      "2022-11-27 20:24:34.306210: validation loss: -0.8368\n",
      "2022-11-27 20:24:34.306610: Average global foreground Dice: [0.8937, 0.877]\n",
      "2022-11-27 20:24:34.306679: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:24:34.660949: lr: 0.005647\n",
      "2022-11-27 20:24:34.661053: This epoch took 15.606272 s\n",
      "\n",
      "2022-11-27 20:24:34.661080: \n",
      "epoch:  470\n",
      "2022-11-27 20:24:48.893159: train loss : -0.9207\n",
      "2022-11-27 20:24:49.889401: validation loss: -0.8432\n",
      "2022-11-27 20:24:49.889765: Average global foreground Dice: [0.8977, 0.8794]\n",
      "2022-11-27 20:24:49.889883: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:24:50.264070: lr: 0.005638\n",
      "2022-11-27 20:24:50.264177: This epoch took 15.603072 s\n",
      "\n",
      "2022-11-27 20:24:50.264205: \n",
      "epoch:  471\n",
      "2022-11-27 20:25:04.559655: train loss : -0.9191\n",
      "2022-11-27 20:25:05.559979: validation loss: -0.8390\n",
      "2022-11-27 20:25:05.560359: Average global foreground Dice: [0.8932, 0.8754]\n",
      "2022-11-27 20:25:05.560417: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:25:05.916363: lr: 0.005628\n",
      "2022-11-27 20:25:05.916471: This epoch took 15.652239 s\n",
      "\n",
      "2022-11-27 20:25:05.916502: \n",
      "epoch:  472\n",
      "2022-11-27 20:25:20.201592: train loss : -0.9223\n",
      "2022-11-27 20:25:21.220807: validation loss: -0.8449\n",
      "2022-11-27 20:25:21.221188: Average global foreground Dice: [0.8978, 0.8793]\n",
      "2022-11-27 20:25:21.221242: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:25:21.576969: lr: 0.005619\n",
      "2022-11-27 20:25:21.577085: This epoch took 15.660556 s\n",
      "\n",
      "2022-11-27 20:25:21.577113: \n",
      "epoch:  473\n",
      "2022-11-27 20:25:35.854067: train loss : -0.9211\n",
      "2022-11-27 20:25:36.881083: validation loss: -0.8417\n",
      "2022-11-27 20:25:36.881452: Average global foreground Dice: [0.8968, 0.8784]\n",
      "2022-11-27 20:25:36.881528: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:25:37.237072: lr: 0.005609\n",
      "2022-11-27 20:25:37.237178: This epoch took 15.660034 s\n",
      "\n",
      "2022-11-27 20:25:37.237206: \n",
      "epoch:  474\n",
      "2022-11-27 20:25:51.469205: train loss : -0.9224\n",
      "2022-11-27 20:25:52.454070: validation loss: -0.8417\n",
      "2022-11-27 20:25:52.454491: Average global foreground Dice: [0.8957, 0.8768]\n",
      "2022-11-27 20:25:52.454561: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:25:52.814641: lr: 0.005599\n",
      "2022-11-27 20:25:52.814761: This epoch took 15.577512 s\n",
      "\n",
      "2022-11-27 20:25:52.814794: \n",
      "epoch:  475\n",
      "2022-11-27 20:26:07.022959: train loss : -0.9203\n",
      "2022-11-27 20:26:08.017618: validation loss: -0.8400\n",
      "2022-11-27 20:26:08.017954: Average global foreground Dice: [0.8942, 0.8765]\n",
      "2022-11-27 20:26:08.018011: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:26:08.529415: lr: 0.00559\n",
      "2022-11-27 20:26:08.529540: This epoch took 15.714705 s\n",
      "\n",
      "2022-11-27 20:26:08.529573: \n",
      "epoch:  476\n",
      "2022-11-27 20:26:22.817422: train loss : -0.9220\n",
      "2022-11-27 20:26:23.840060: validation loss: -0.8436\n",
      "2022-11-27 20:26:23.840410: Average global foreground Dice: [0.8979, 0.8803]\n",
      "2022-11-27 20:26:23.840514: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:26:24.204171: lr: 0.00558\n",
      "2022-11-27 20:26:24.204295: This epoch took 15.674680 s\n",
      "\n",
      "2022-11-27 20:26:24.204326: \n",
      "epoch:  477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 20:26:38.514938: train loss : -0.9220\n",
      "2022-11-27 20:26:39.538060: validation loss: -0.8409\n",
      "2022-11-27 20:26:39.538481: Average global foreground Dice: [0.895, 0.8782]\n",
      "2022-11-27 20:26:39.538566: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:26:39.941087: lr: 0.005571\n",
      "2022-11-27 20:26:39.941202: This epoch took 15.736850 s\n",
      "\n",
      "2022-11-27 20:26:39.941232: \n",
      "epoch:  478\n",
      "2022-11-27 20:26:54.254648: train loss : -0.9210\n",
      "2022-11-27 20:26:55.260997: validation loss: -0.8429\n",
      "2022-11-27 20:26:55.261334: Average global foreground Dice: [0.8957, 0.88]\n",
      "2022-11-27 20:26:55.261388: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:26:55.618965: lr: 0.005561\n",
      "2022-11-27 20:26:55.619069: This epoch took 15.677792 s\n",
      "\n",
      "2022-11-27 20:26:55.619096: \n",
      "epoch:  479\n",
      "2022-11-27 20:27:09.854088: train loss : -0.9199\n",
      "2022-11-27 20:27:10.840100: validation loss: -0.8401\n",
      "2022-11-27 20:27:10.840469: Average global foreground Dice: [0.8959, 0.8749]\n",
      "2022-11-27 20:27:10.840526: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:27:11.211150: lr: 0.005551\n",
      "2022-11-27 20:27:11.211259: This epoch took 15.592139 s\n",
      "\n",
      "2022-11-27 20:27:11.211289: \n",
      "epoch:  480\n",
      "2022-11-27 20:27:25.521495: train loss : -0.9209\n",
      "2022-11-27 20:27:26.525183: validation loss: -0.8401\n",
      "2022-11-27 20:27:26.525532: Average global foreground Dice: [0.8957, 0.8756]\n",
      "2022-11-27 20:27:26.525588: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:27:26.880697: lr: 0.005542\n",
      "2022-11-27 20:27:26.880818: This epoch took 15.669487 s\n",
      "\n",
      "2022-11-27 20:27:26.880850: \n",
      "epoch:  481\n",
      "2022-11-27 20:27:41.135287: train loss : -0.9215\n",
      "2022-11-27 20:27:42.165982: validation loss: -0.8380\n",
      "2022-11-27 20:27:42.166329: Average global foreground Dice: [0.8922, 0.8738]\n",
      "2022-11-27 20:27:42.166384: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:27:42.527852: lr: 0.005532\n",
      "2022-11-27 20:27:42.527977: This epoch took 15.647085 s\n",
      "\n",
      "2022-11-27 20:27:42.528008: \n",
      "epoch:  482\n",
      "2022-11-27 20:27:56.839183: train loss : -0.9196\n",
      "2022-11-27 20:27:57.838030: validation loss: -0.8451\n",
      "2022-11-27 20:27:57.838621: Average global foreground Dice: [0.898, 0.8802]\n",
      "2022-11-27 20:27:57.838703: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:27:58.202875: lr: 0.005523\n",
      "2022-11-27 20:27:58.202993: This epoch took 15.674943 s\n",
      "\n",
      "2022-11-27 20:27:58.203027: \n",
      "epoch:  483\n",
      "2022-11-27 20:28:12.455397: train loss : -0.9197\n",
      "2022-11-27 20:28:13.466858: validation loss: -0.8420\n",
      "2022-11-27 20:28:13.467238: Average global foreground Dice: [0.8967, 0.8783]\n",
      "2022-11-27 20:28:13.467297: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:28:13.841040: lr: 0.005513\n",
      "2022-11-27 20:28:13.841145: This epoch took 15.638092 s\n",
      "\n",
      "2022-11-27 20:28:13.841173: \n",
      "epoch:  484\n",
      "2022-11-27 20:28:28.115396: train loss : -0.9215\n",
      "2022-11-27 20:28:29.118980: validation loss: -0.8396\n",
      "2022-11-27 20:28:29.119416: Average global foreground Dice: [0.8919, 0.8772]\n",
      "2022-11-27 20:28:29.119489: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:28:29.495834: lr: 0.005503\n",
      "2022-11-27 20:28:29.495937: This epoch took 15.654738 s\n",
      "\n",
      "2022-11-27 20:28:29.495966: \n",
      "epoch:  485\n",
      "2022-11-27 20:28:43.782043: train loss : -0.9194\n",
      "2022-11-27 20:28:44.774740: validation loss: -0.8440\n",
      "2022-11-27 20:28:44.775128: Average global foreground Dice: [0.8981, 0.88]\n",
      "2022-11-27 20:28:44.775185: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:28:45.240699: lr: 0.005494\n",
      "2022-11-27 20:28:45.240808: This epoch took 15.744814 s\n",
      "\n",
      "2022-11-27 20:28:45.240836: \n",
      "epoch:  486\n",
      "2022-11-27 20:28:59.537052: train loss : -0.9204\n",
      "2022-11-27 20:29:00.524779: validation loss: -0.8392\n",
      "2022-11-27 20:29:00.525111: Average global foreground Dice: [0.8935, 0.8764]\n",
      "2022-11-27 20:29:00.525167: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:29:00.899730: lr: 0.005484\n",
      "2022-11-27 20:29:00.899863: This epoch took 15.658985 s\n",
      "\n",
      "2022-11-27 20:29:00.899903: \n",
      "epoch:  487\n",
      "2022-11-27 20:29:15.126811: train loss : -0.9225\n",
      "2022-11-27 20:29:16.147707: validation loss: -0.8438\n",
      "2022-11-27 20:29:16.148070: Average global foreground Dice: [0.8984, 0.8792]\n",
      "2022-11-27 20:29:16.148143: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:29:16.498562: lr: 0.005474\n",
      "2022-11-27 20:29:16.498666: This epoch took 15.598721 s\n",
      "\n",
      "2022-11-27 20:29:16.498695: \n",
      "epoch:  488\n",
      "2022-11-27 20:29:30.793279: train loss : -0.9205\n",
      "2022-11-27 20:29:31.816278: validation loss: -0.8437\n",
      "2022-11-27 20:29:31.816673: Average global foreground Dice: [0.8973, 0.8787]\n",
      "2022-11-27 20:29:31.816735: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:29:32.167001: lr: 0.005465\n",
      "2022-11-27 20:29:32.167112: This epoch took 15.668391 s\n",
      "\n",
      "2022-11-27 20:29:32.167141: \n",
      "epoch:  489\n",
      "2022-11-27 20:29:46.482760: train loss : -0.9217\n",
      "2022-11-27 20:29:47.493537: validation loss: -0.8381\n",
      "2022-11-27 20:29:47.494009: Average global foreground Dice: [0.896, 0.873]\n",
      "2022-11-27 20:29:47.494182: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:29:47.871509: lr: 0.005455\n",
      "2022-11-27 20:29:47.871627: This epoch took 15.704459 s\n",
      "\n",
      "2022-11-27 20:29:47.871663: \n",
      "epoch:  490\n",
      "2022-11-27 20:30:02.179625: train loss : -0.9218\n",
      "2022-11-27 20:30:03.209769: validation loss: -0.8376\n",
      "2022-11-27 20:30:03.210167: Average global foreground Dice: [0.8925, 0.8749]\n",
      "2022-11-27 20:30:03.210226: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:30:03.564255: lr: 0.005446\n",
      "2022-11-27 20:30:03.564364: This epoch took 15.692671 s\n",
      "\n",
      "2022-11-27 20:30:03.564394: \n",
      "epoch:  491\n",
      "2022-11-27 20:30:17.840990: train loss : -0.9203\n",
      "2022-11-27 20:30:18.839435: validation loss: -0.8386\n",
      "2022-11-27 20:30:18.839790: Average global foreground Dice: [0.8941, 0.8761]\n",
      "2022-11-27 20:30:18.839855: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:30:19.194014: lr: 0.005436\n",
      "2022-11-27 20:30:19.194121: This epoch took 15.629700 s\n",
      "\n",
      "2022-11-27 20:30:19.194152: \n",
      "epoch:  492\n",
      "2022-11-27 20:30:33.456422: train loss : -0.9210\n",
      "2022-11-27 20:30:34.461666: validation loss: -0.8447\n",
      "2022-11-27 20:30:34.462136: Average global foreground Dice: [0.8979, 0.8815]\n",
      "2022-11-27 20:30:34.462351: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:30:34.833445: lr: 0.005426\n",
      "2022-11-27 20:30:34.833548: This epoch took 15.639369 s\n",
      "\n",
      "2022-11-27 20:30:34.833580: \n",
      "epoch:  493\n",
      "2022-11-27 20:30:49.136819: train loss : -0.9207\n",
      "2022-11-27 20:30:50.164561: validation loss: -0.8401\n",
      "2022-11-27 20:30:50.164963: Average global foreground Dice: [0.8931, 0.8777]\n",
      "2022-11-27 20:30:50.165147: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:30:50.523627: lr: 0.005417\n",
      "2022-11-27 20:30:50.523746: This epoch took 15.690110 s\n",
      "\n",
      "2022-11-27 20:30:50.523778: \n",
      "epoch:  494\n",
      "2022-11-27 20:31:04.781901: train loss : -0.9216\n",
      "2022-11-27 20:31:05.759686: validation loss: -0.8427\n",
      "2022-11-27 20:31:05.760071: Average global foreground Dice: [0.8955, 0.878]\n",
      "2022-11-27 20:31:05.760132: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:31:06.121210: lr: 0.005407\n",
      "2022-11-27 20:31:06.121437: This epoch took 15.597632 s\n",
      "\n",
      "2022-11-27 20:31:06.121477: \n",
      "epoch:  495\n",
      "2022-11-27 20:31:20.378861: train loss : -0.9214\n",
      "2022-11-27 20:31:21.359485: validation loss: -0.8423\n",
      "2022-11-27 20:31:21.359823: Average global foreground Dice: [0.8947, 0.8812]\n",
      "2022-11-27 20:31:21.359879: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:31:21.715931: lr: 0.005397\n",
      "2022-11-27 20:31:21.716033: This epoch took 15.594528 s\n",
      "\n",
      "2022-11-27 20:31:21.716061: \n",
      "epoch:  496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 20:31:35.979159: train loss : -0.9220\n",
      "2022-11-27 20:31:36.967440: validation loss: -0.8355\n",
      "2022-11-27 20:31:36.967796: Average global foreground Dice: [0.8951, 0.8755]\n",
      "2022-11-27 20:31:36.967857: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:31:37.467509: lr: 0.005388\n",
      "2022-11-27 20:31:37.467619: This epoch took 15.751532 s\n",
      "\n",
      "2022-11-27 20:31:37.467644: \n",
      "epoch:  497\n",
      "2022-11-27 20:31:51.800962: train loss : -0.9210\n",
      "2022-11-27 20:31:52.797654: validation loss: -0.8363\n",
      "2022-11-27 20:31:52.797994: Average global foreground Dice: [0.8918, 0.8759]\n",
      "2022-11-27 20:31:52.798050: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:31:53.199932: lr: 0.005378\n",
      "2022-11-27 20:31:53.200047: This epoch took 15.732379 s\n",
      "\n",
      "2022-11-27 20:31:53.200077: \n",
      "epoch:  498\n",
      "2022-11-27 20:32:07.494982: train loss : -0.9230\n",
      "2022-11-27 20:32:08.476634: validation loss: -0.8388\n",
      "2022-11-27 20:32:08.477069: Average global foreground Dice: [0.8921, 0.8753]\n",
      "2022-11-27 20:32:08.477152: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:32:08.838463: lr: 0.005369\n",
      "2022-11-27 20:32:08.838574: This epoch took 15.638471 s\n",
      "\n",
      "2022-11-27 20:32:08.838603: \n",
      "epoch:  499\n",
      "2022-11-27 20:32:23.170946: train loss : -0.9221\n",
      "2022-11-27 20:32:24.195348: validation loss: -0.8429\n",
      "2022-11-27 20:32:24.195824: Average global foreground Dice: [0.8974, 0.8785]\n",
      "2022-11-27 20:32:24.195931: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:32:24.556597: lr: 0.005359\n",
      "2022-11-27 20:32:24.556691: saving scheduled checkpoint file...\n",
      "2022-11-27 20:32:24.560591: saving checkpoint...\n",
      "2022-11-27 20:32:24.625616: done, saving took 0.07 seconds\n",
      "2022-11-27 20:32:24.627337: done\n",
      "2022-11-27 20:32:24.627404: This epoch took 15.788775 s\n",
      "\n",
      "2022-11-27 20:32:24.627432: \n",
      "epoch:  500\n",
      "2022-11-27 20:32:38.895236: train loss : -0.9214\n",
      "2022-11-27 20:32:39.956253: validation loss: -0.8416\n",
      "2022-11-27 20:32:39.956584: Average global foreground Dice: [0.8948, 0.8772]\n",
      "2022-11-27 20:32:39.956639: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:32:40.319581: lr: 0.005349\n",
      "2022-11-27 20:32:40.319732: This epoch took 15.692273 s\n",
      "\n",
      "2022-11-27 20:32:40.319764: \n",
      "epoch:  501\n",
      "2022-11-27 20:32:54.637462: train loss : -0.9211\n",
      "2022-11-27 20:32:55.646927: validation loss: -0.8401\n",
      "2022-11-27 20:32:55.647277: Average global foreground Dice: [0.8957, 0.878]\n",
      "2022-11-27 20:32:55.647334: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:32:56.009765: lr: 0.00534\n",
      "2022-11-27 20:32:56.009879: This epoch took 15.690072 s\n",
      "\n",
      "2022-11-27 20:32:56.009918: \n",
      "epoch:  502\n",
      "2022-11-27 20:33:10.258662: train loss : -0.9215\n",
      "2022-11-27 20:33:11.266472: validation loss: -0.8463\n",
      "2022-11-27 20:33:11.266852: Average global foreground Dice: [0.8984, 0.882]\n",
      "2022-11-27 20:33:11.266909: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:33:11.625616: lr: 0.00533\n",
      "2022-11-27 20:33:11.625720: This epoch took 15.615771 s\n",
      "\n",
      "2022-11-27 20:33:11.625768: \n",
      "epoch:  503\n",
      "2022-11-27 20:33:25.919232: train loss : -0.9216\n",
      "2022-11-27 20:33:26.913018: validation loss: -0.8389\n",
      "2022-11-27 20:33:26.913350: Average global foreground Dice: [0.8944, 0.8762]\n",
      "2022-11-27 20:33:26.913403: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:33:27.277144: lr: 0.00532\n",
      "2022-11-27 20:33:27.277284: This epoch took 15.651485 s\n",
      "\n",
      "2022-11-27 20:33:27.277328: \n",
      "epoch:  504\n",
      "2022-11-27 20:33:41.560197: train loss : -0.9231\n",
      "2022-11-27 20:33:42.572887: validation loss: -0.8415\n",
      "2022-11-27 20:33:42.573219: Average global foreground Dice: [0.8952, 0.879]\n",
      "2022-11-27 20:33:42.573276: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:33:42.931695: lr: 0.005311\n",
      "2022-11-27 20:33:42.931804: This epoch took 15.654446 s\n",
      "\n",
      "2022-11-27 20:33:42.931837: \n",
      "epoch:  505\n",
      "2022-11-27 20:33:57.255995: train loss : -0.9218\n",
      "2022-11-27 20:33:58.266064: validation loss: -0.8406\n",
      "2022-11-27 20:33:58.266396: Average global foreground Dice: [0.8957, 0.8757]\n",
      "2022-11-27 20:33:58.266455: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:33:58.624534: lr: 0.005301\n",
      "2022-11-27 20:33:58.624637: This epoch took 15.692757 s\n",
      "\n",
      "2022-11-27 20:33:58.624681: \n",
      "epoch:  506\n",
      "2022-11-27 20:34:12.900318: train loss : -0.9222\n",
      "2022-11-27 20:34:13.906878: validation loss: -0.8401\n",
      "2022-11-27 20:34:13.907208: Average global foreground Dice: [0.8946, 0.8766]\n",
      "2022-11-27 20:34:13.907538: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:34:14.404484: lr: 0.005291\n",
      "2022-11-27 20:34:14.404608: This epoch took 15.779886 s\n",
      "\n",
      "2022-11-27 20:34:14.404642: \n",
      "epoch:  507\n",
      "2022-11-27 20:34:28.660537: train loss : -0.9216\n",
      "2022-11-27 20:34:29.642266: validation loss: -0.8439\n",
      "2022-11-27 20:34:29.642638: Average global foreground Dice: [0.8979, 0.8794]\n",
      "2022-11-27 20:34:29.642698: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:34:30.021428: lr: 0.005282\n",
      "2022-11-27 20:34:30.021553: This epoch took 15.616860 s\n",
      "\n",
      "2022-11-27 20:34:30.021584: \n",
      "epoch:  508\n",
      "2022-11-27 20:34:44.277951: train loss : -0.9223\n",
      "2022-11-27 20:34:45.272137: validation loss: -0.8422\n",
      "2022-11-27 20:34:45.272547: Average global foreground Dice: [0.8963, 0.8785]\n",
      "2022-11-27 20:34:45.272612: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:34:45.636419: lr: 0.005272\n",
      "2022-11-27 20:34:45.636541: This epoch took 15.614914 s\n",
      "\n",
      "2022-11-27 20:34:45.636575: \n",
      "epoch:  509\n",
      "2022-11-27 20:34:59.953987: train loss : -0.9234\n",
      "2022-11-27 20:35:00.950374: validation loss: -0.8439\n",
      "2022-11-27 20:35:00.951055: Average global foreground Dice: [0.8964, 0.8833]\n",
      "2022-11-27 20:35:00.951299: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:35:01.332063: lr: 0.005262\n",
      "2022-11-27 20:35:01.332168: This epoch took 15.695566 s\n",
      "\n",
      "2022-11-27 20:35:01.332221: \n",
      "epoch:  510\n",
      "2022-11-27 20:35:15.636251: train loss : -0.9237\n",
      "2022-11-27 20:35:16.647862: validation loss: -0.8372\n",
      "2022-11-27 20:35:16.648249: Average global foreground Dice: [0.8931, 0.8745]\n",
      "2022-11-27 20:35:16.648308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:35:17.013330: lr: 0.005253\n",
      "2022-11-27 20:35:17.013443: This epoch took 15.681198 s\n",
      "\n",
      "2022-11-27 20:35:17.013474: \n",
      "epoch:  511\n",
      "2022-11-27 20:35:31.304302: train loss : -0.9216\n",
      "2022-11-27 20:35:32.293077: validation loss: -0.8434\n",
      "2022-11-27 20:35:32.293413: Average global foreground Dice: [0.8969, 0.8793]\n",
      "2022-11-27 20:35:32.293474: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:35:32.651356: lr: 0.005243\n",
      "2022-11-27 20:35:32.651460: This epoch took 15.637954 s\n",
      "\n",
      "2022-11-27 20:35:32.651489: \n",
      "epoch:  512\n",
      "2022-11-27 20:35:46.957150: train loss : -0.9204\n",
      "2022-11-27 20:35:47.960752: validation loss: -0.8370\n",
      "2022-11-27 20:35:47.961109: Average global foreground Dice: [0.8937, 0.8754]\n",
      "2022-11-27 20:35:47.961197: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:35:48.321342: lr: 0.005233\n",
      "2022-11-27 20:35:48.321447: This epoch took 15.669932 s\n",
      "\n",
      "2022-11-27 20:35:48.321476: \n",
      "epoch:  513\n",
      "2022-11-27 20:36:02.559736: train loss : -0.9217\n",
      "2022-11-27 20:36:03.566050: validation loss: -0.8401\n",
      "2022-11-27 20:36:03.566557: Average global foreground Dice: [0.8947, 0.877]\n",
      "2022-11-27 20:36:03.566685: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:36:03.932287: lr: 0.005224\n",
      "2022-11-27 20:36:03.932393: This epoch took 15.610890 s\n",
      "\n",
      "2022-11-27 20:36:03.932423: \n",
      "epoch:  514\n",
      "2022-11-27 20:36:18.210154: train loss : -0.9216\n",
      "2022-11-27 20:36:19.201114: validation loss: -0.8418\n",
      "2022-11-27 20:36:19.201463: Average global foreground Dice: [0.8979, 0.8773]\n",
      "2022-11-27 20:36:19.201517: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 20:36:19.560823: lr: 0.005214\n",
      "2022-11-27 20:36:19.560923: This epoch took 15.628456 s\n",
      "\n",
      "2022-11-27 20:36:19.560950: \n",
      "epoch:  515\n",
      "2022-11-27 20:36:33.814490: train loss : -0.9238\n",
      "2022-11-27 20:36:34.814254: validation loss: -0.8396\n",
      "2022-11-27 20:36:34.814583: Average global foreground Dice: [0.8945, 0.8773]\n",
      "2022-11-27 20:36:34.814640: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:36:35.179099: lr: 0.005204\n",
      "2022-11-27 20:36:35.179219: This epoch took 15.618229 s\n",
      "\n",
      "2022-11-27 20:36:35.179249: \n",
      "epoch:  516\n",
      "2022-11-27 20:36:49.487128: train loss : -0.9225\n",
      "2022-11-27 20:36:50.492583: validation loss: -0.8408\n",
      "2022-11-27 20:36:50.492969: Average global foreground Dice: [0.8953, 0.8758]\n",
      "2022-11-27 20:36:50.493025: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:36:50.967218: lr: 0.005195\n",
      "2022-11-27 20:36:50.967326: This epoch took 15.788050 s\n",
      "\n",
      "2022-11-27 20:36:50.967356: \n",
      "epoch:  517\n",
      "2022-11-27 20:37:05.183097: train loss : -0.9238\n",
      "2022-11-27 20:37:06.172729: validation loss: -0.8431\n",
      "2022-11-27 20:37:06.173115: Average global foreground Dice: [0.8971, 0.8798]\n",
      "2022-11-27 20:37:06.173175: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:37:06.550695: lr: 0.005185\n",
      "2022-11-27 20:37:06.550807: This epoch took 15.583426 s\n",
      "\n",
      "2022-11-27 20:37:06.550841: \n",
      "epoch:  518\n",
      "2022-11-27 20:37:20.788893: train loss : -0.9228\n",
      "2022-11-27 20:37:21.793038: validation loss: -0.8410\n",
      "2022-11-27 20:37:21.793390: Average global foreground Dice: [0.8948, 0.8783]\n",
      "2022-11-27 20:37:21.793478: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:37:22.146033: lr: 0.005175\n",
      "2022-11-27 20:37:22.146142: This epoch took 15.595268 s\n",
      "\n",
      "2022-11-27 20:37:22.146183: \n",
      "epoch:  519\n",
      "2022-11-27 20:37:36.360180: train loss : -0.9220\n",
      "2022-11-27 20:37:37.351795: validation loss: -0.8387\n",
      "2022-11-27 20:37:37.352140: Average global foreground Dice: [0.8944, 0.8756]\n",
      "2022-11-27 20:37:37.352197: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:37:37.705231: lr: 0.005166\n",
      "2022-11-27 20:37:37.705337: This epoch took 15.559124 s\n",
      "\n",
      "2022-11-27 20:37:37.705363: \n",
      "epoch:  520\n",
      "2022-11-27 20:37:52.024516: train loss : -0.9232\n",
      "2022-11-27 20:37:53.029706: validation loss: -0.8466\n",
      "2022-11-27 20:37:53.030180: Average global foreground Dice: [0.8974, 0.8824]\n",
      "2022-11-27 20:37:53.030257: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:37:53.394192: lr: 0.005156\n",
      "2022-11-27 20:37:53.394302: This epoch took 15.688897 s\n",
      "\n",
      "2022-11-27 20:37:53.394334: \n",
      "epoch:  521\n",
      "2022-11-27 20:38:07.614788: train loss : -0.9232\n",
      "2022-11-27 20:38:08.606285: validation loss: -0.8373\n",
      "2022-11-27 20:38:08.606668: Average global foreground Dice: [0.8944, 0.8776]\n",
      "2022-11-27 20:38:08.606727: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:38:08.960958: lr: 0.005146\n",
      "2022-11-27 20:38:08.961069: This epoch took 15.566708 s\n",
      "\n",
      "2022-11-27 20:38:08.961100: \n",
      "epoch:  522\n",
      "2022-11-27 20:38:23.245720: train loss : -0.9215\n",
      "2022-11-27 20:38:24.277078: validation loss: -0.8403\n",
      "2022-11-27 20:38:24.277422: Average global foreground Dice: [0.8932, 0.876]\n",
      "2022-11-27 20:38:24.277482: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:38:24.647866: lr: 0.005136\n",
      "2022-11-27 20:38:24.648090: This epoch took 15.686964 s\n",
      "\n",
      "2022-11-27 20:38:24.648125: \n",
      "epoch:  523\n",
      "2022-11-27 20:38:38.895900: train loss : -0.9220\n",
      "2022-11-27 20:38:39.894725: validation loss: -0.8356\n",
      "2022-11-27 20:38:39.895053: Average global foreground Dice: [0.8922, 0.8722]\n",
      "2022-11-27 20:38:39.895113: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:38:40.253268: lr: 0.005127\n",
      "2022-11-27 20:38:40.253378: This epoch took 15.605225 s\n",
      "\n",
      "2022-11-27 20:38:40.253405: \n",
      "epoch:  524\n",
      "2022-11-27 20:38:54.515142: train loss : -0.9238\n",
      "2022-11-27 20:38:55.535767: validation loss: -0.8400\n",
      "2022-11-27 20:38:55.536151: Average global foreground Dice: [0.8958, 0.8755]\n",
      "2022-11-27 20:38:55.536207: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:38:55.891593: lr: 0.005117\n",
      "2022-11-27 20:38:55.891699: This epoch took 15.638269 s\n",
      "\n",
      "2022-11-27 20:38:55.891728: \n",
      "epoch:  525\n",
      "2022-11-27 20:39:10.179235: train loss : -0.9218\n",
      "2022-11-27 20:39:11.187904: validation loss: -0.8424\n",
      "2022-11-27 20:39:11.188247: Average global foreground Dice: [0.8956, 0.8798]\n",
      "2022-11-27 20:39:11.188303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:39:11.550133: lr: 0.005107\n",
      "2022-11-27 20:39:11.550238: This epoch took 15.658485 s\n",
      "\n",
      "2022-11-27 20:39:11.550269: \n",
      "epoch:  526\n",
      "2022-11-27 20:39:25.777763: train loss : -0.9209\n",
      "2022-11-27 20:39:26.790193: validation loss: -0.8355\n",
      "2022-11-27 20:39:26.790532: Average global foreground Dice: [0.8917, 0.8741]\n",
      "2022-11-27 20:39:26.790586: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:39:27.147814: lr: 0.005098\n",
      "2022-11-27 20:39:27.147919: This epoch took 15.597624 s\n",
      "\n",
      "2022-11-27 20:39:27.147949: \n",
      "epoch:  527\n",
      "2022-11-27 20:39:41.465675: train loss : -0.9210\n",
      "2022-11-27 20:39:42.455086: validation loss: -0.8395\n",
      "2022-11-27 20:39:42.455858: Average global foreground Dice: [0.8947, 0.8763]\n",
      "2022-11-27 20:39:42.456005: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:39:42.950718: lr: 0.005088\n",
      "2022-11-27 20:39:42.950829: This epoch took 15.802853 s\n",
      "\n",
      "2022-11-27 20:39:42.950858: \n",
      "epoch:  528\n",
      "2022-11-27 20:39:57.160999: train loss : -0.9222\n",
      "2022-11-27 20:39:58.163085: validation loss: -0.8407\n",
      "2022-11-27 20:39:58.163459: Average global foreground Dice: [0.8947, 0.878]\n",
      "2022-11-27 20:39:58.163525: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:39:58.527579: lr: 0.005078\n",
      "2022-11-27 20:39:58.527695: This epoch took 15.576810 s\n",
      "\n",
      "2022-11-27 20:39:58.527741: \n",
      "epoch:  529\n",
      "2022-11-27 20:40:12.800190: train loss : -0.9236\n",
      "2022-11-27 20:40:13.796232: validation loss: -0.8448\n",
      "2022-11-27 20:40:13.796551: Average global foreground Dice: [0.8984, 0.882]\n",
      "2022-11-27 20:40:13.796611: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:40:14.159355: lr: 0.005069\n",
      "2022-11-27 20:40:14.159464: This epoch took 15.631696 s\n",
      "\n",
      "2022-11-27 20:40:14.159491: \n",
      "epoch:  530\n",
      "2022-11-27 20:40:28.499331: train loss : -0.9230\n",
      "2022-11-27 20:40:29.504612: validation loss: -0.8386\n",
      "2022-11-27 20:40:29.504950: Average global foreground Dice: [0.894, 0.8791]\n",
      "2022-11-27 20:40:29.505003: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:40:29.889471: lr: 0.005059\n",
      "2022-11-27 20:40:29.889577: This epoch took 15.730045 s\n",
      "\n",
      "2022-11-27 20:40:29.889604: \n",
      "epoch:  531\n",
      "2022-11-27 20:40:44.113830: train loss : -0.9230\n",
      "2022-11-27 20:40:45.115592: validation loss: -0.8405\n",
      "2022-11-27 20:40:45.115952: Average global foreground Dice: [0.8934, 0.876]\n",
      "2022-11-27 20:40:45.116044: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:40:45.475377: lr: 0.005049\n",
      "2022-11-27 20:40:45.475490: This epoch took 15.585862 s\n",
      "\n",
      "2022-11-27 20:40:45.475519: \n",
      "epoch:  532\n",
      "2022-11-27 20:40:59.777358: train loss : -0.9228\n",
      "2022-11-27 20:41:00.763641: validation loss: -0.8408\n",
      "2022-11-27 20:41:00.764012: Average global foreground Dice: [0.8952, 0.8763]\n",
      "2022-11-27 20:41:00.764071: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:41:01.122264: lr: 0.005039\n",
      "2022-11-27 20:41:01.122372: This epoch took 15.646820 s\n",
      "\n",
      "2022-11-27 20:41:01.122401: \n",
      "epoch:  533\n",
      "2022-11-27 20:41:15.405584: train loss : -0.9217\n",
      "2022-11-27 20:41:16.414294: validation loss: -0.8364\n",
      "2022-11-27 20:41:16.414672: Average global foreground Dice: [0.8919, 0.8755]\n",
      "2022-11-27 20:41:16.414731: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 20:41:16.776267: lr: 0.00503\n",
      "2022-11-27 20:41:16.776386: This epoch took 15.653959 s\n",
      "\n",
      "2022-11-27 20:41:16.776417: \n",
      "epoch:  534\n",
      "2022-11-27 20:41:30.986629: train loss : -0.9221\n",
      "2022-11-27 20:41:31.986353: validation loss: -0.8415\n",
      "2022-11-27 20:41:31.986791: Average global foreground Dice: [0.8955, 0.8781]\n",
      "2022-11-27 20:41:31.986867: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:41:32.342623: lr: 0.00502\n",
      "2022-11-27 20:41:32.342731: This epoch took 15.566287 s\n",
      "\n",
      "2022-11-27 20:41:32.342761: \n",
      "epoch:  535\n",
      "2022-11-27 20:41:46.636765: train loss : -0.9232\n",
      "2022-11-27 20:41:47.633524: validation loss: -0.8413\n",
      "2022-11-27 20:41:47.633916: Average global foreground Dice: [0.8955, 0.8772]\n",
      "2022-11-27 20:41:47.633981: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:41:47.994442: lr: 0.00501\n",
      "2022-11-27 20:41:47.994551: This epoch took 15.651764 s\n",
      "\n",
      "2022-11-27 20:41:47.994579: \n",
      "epoch:  536\n",
      "2022-11-27 20:42:02.240689: train loss : -0.9236\n",
      "2022-11-27 20:42:03.259591: validation loss: -0.8386\n",
      "2022-11-27 20:42:03.260162: Average global foreground Dice: [0.8927, 0.875]\n",
      "2022-11-27 20:42:03.260256: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:42:03.655324: lr: 0.005001\n",
      "2022-11-27 20:42:03.655424: This epoch took 15.660818 s\n",
      "\n",
      "2022-11-27 20:42:03.655467: \n",
      "epoch:  537\n",
      "2022-11-27 20:42:17.898460: train loss : -0.9219\n",
      "2022-11-27 20:42:18.885312: validation loss: -0.8390\n",
      "2022-11-27 20:42:18.885643: Average global foreground Dice: [0.8935, 0.877]\n",
      "2022-11-27 20:42:18.885701: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:42:19.246473: lr: 0.004991\n",
      "2022-11-27 20:42:19.246576: This epoch took 15.591074 s\n",
      "\n",
      "2022-11-27 20:42:19.246605: \n",
      "epoch:  538\n",
      "2022-11-27 20:42:33.514192: train loss : -0.9239\n",
      "2022-11-27 20:42:34.646698: validation loss: -0.8416\n",
      "2022-11-27 20:42:34.647063: Average global foreground Dice: [0.8955, 0.8789]\n",
      "2022-11-27 20:42:34.647128: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:42:35.013738: lr: 0.004981\n",
      "2022-11-27 20:42:35.013856: This epoch took 15.767225 s\n",
      "\n",
      "2022-11-27 20:42:35.013886: \n",
      "epoch:  539\n",
      "2022-11-27 20:42:49.260221: train loss : -0.9243\n",
      "2022-11-27 20:42:50.317528: validation loss: -0.8453\n",
      "2022-11-27 20:42:50.317940: Average global foreground Dice: [0.8997, 0.8819]\n",
      "2022-11-27 20:42:50.318004: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:42:50.714588: lr: 0.004971\n",
      "2022-11-27 20:42:50.714697: This epoch took 15.700776 s\n",
      "\n",
      "2022-11-27 20:42:50.714726: \n",
      "epoch:  540\n",
      "2022-11-27 20:43:05.023228: train loss : -0.9227\n",
      "2022-11-27 20:43:06.031561: validation loss: -0.8408\n",
      "2022-11-27 20:43:06.031928: Average global foreground Dice: [0.8958, 0.8777]\n",
      "2022-11-27 20:43:06.032015: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:43:06.392360: lr: 0.004962\n",
      "2022-11-27 20:43:06.392472: This epoch took 15.677720 s\n",
      "\n",
      "2022-11-27 20:43:06.392501: \n",
      "epoch:  541\n",
      "2022-11-27 20:43:20.693177: train loss : -0.9234\n",
      "2022-11-27 20:43:21.684730: validation loss: -0.8396\n",
      "2022-11-27 20:43:21.685110: Average global foreground Dice: [0.8952, 0.8769]\n",
      "2022-11-27 20:43:21.685168: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:43:22.050607: lr: 0.004952\n",
      "2022-11-27 20:43:22.050715: This epoch took 15.658187 s\n",
      "\n",
      "2022-11-27 20:43:22.050743: \n",
      "epoch:  542\n",
      "2022-11-27 20:43:36.390975: train loss : -0.9225\n",
      "2022-11-27 20:43:37.436406: validation loss: -0.8388\n",
      "2022-11-27 20:43:37.436735: Average global foreground Dice: [0.8941, 0.8766]\n",
      "2022-11-27 20:43:37.436791: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:43:37.814287: lr: 0.004942\n",
      "2022-11-27 20:43:37.814390: This epoch took 15.763620 s\n",
      "\n",
      "2022-11-27 20:43:37.814420: \n",
      "epoch:  543\n",
      "2022-11-27 20:43:52.016907: train loss : -0.9236\n",
      "2022-11-27 20:43:53.070958: validation loss: -0.8397\n",
      "2022-11-27 20:43:53.071303: Average global foreground Dice: [0.8937, 0.8752]\n",
      "2022-11-27 20:43:53.071361: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:43:53.438798: lr: 0.004933\n",
      "2022-11-27 20:43:53.438906: This epoch took 15.624460 s\n",
      "\n",
      "2022-11-27 20:43:53.438946: \n",
      "epoch:  544\n",
      "2022-11-27 20:44:07.695083: train loss : -0.9222\n",
      "2022-11-27 20:44:08.689673: validation loss: -0.8405\n",
      "2022-11-27 20:44:08.690072: Average global foreground Dice: [0.8969, 0.8756]\n",
      "2022-11-27 20:44:08.690135: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:44:09.060730: lr: 0.004923\n",
      "2022-11-27 20:44:09.060837: This epoch took 15.621861 s\n",
      "\n",
      "2022-11-27 20:44:09.060865: \n",
      "epoch:  545\n",
      "2022-11-27 20:44:23.318713: train loss : -0.9239\n",
      "2022-11-27 20:44:24.348463: validation loss: -0.8382\n",
      "2022-11-27 20:44:24.348805: Average global foreground Dice: [0.8926, 0.8756]\n",
      "2022-11-27 20:44:24.348859: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:44:24.719765: lr: 0.004913\n",
      "2022-11-27 20:44:24.719882: This epoch took 15.658974 s\n",
      "\n",
      "2022-11-27 20:44:24.719911: \n",
      "epoch:  546\n",
      "2022-11-27 20:44:38.952193: train loss : -0.9219\n",
      "2022-11-27 20:44:39.985036: validation loss: -0.8388\n",
      "2022-11-27 20:44:39.985409: Average global foreground Dice: [0.8938, 0.8761]\n",
      "2022-11-27 20:44:39.985460: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:44:40.347472: lr: 0.004903\n",
      "2022-11-27 20:44:40.347574: This epoch took 15.627636 s\n",
      "\n",
      "2022-11-27 20:44:40.347600: \n",
      "epoch:  547\n",
      "2022-11-27 20:44:54.569107: train loss : -0.9225\n",
      "2022-11-27 20:44:55.574843: validation loss: -0.8362\n",
      "2022-11-27 20:44:55.575166: Average global foreground Dice: [0.8924, 0.875]\n",
      "2022-11-27 20:44:55.575222: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:44:55.943403: lr: 0.004894\n",
      "2022-11-27 20:44:55.943517: This epoch took 15.595876 s\n",
      "\n",
      "2022-11-27 20:44:55.943548: \n",
      "epoch:  548\n",
      "2022-11-27 20:45:10.214020: train loss : -0.9230\n",
      "2022-11-27 20:45:11.202073: validation loss: -0.8461\n",
      "2022-11-27 20:45:11.202410: Average global foreground Dice: [0.8983, 0.8797]\n",
      "2022-11-27 20:45:11.202470: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:45:11.670029: lr: 0.004884\n",
      "2022-11-27 20:45:11.670141: This epoch took 15.726552 s\n",
      "\n",
      "2022-11-27 20:45:11.670171: \n",
      "epoch:  549\n",
      "2022-11-27 20:45:25.931933: train loss : -0.9254\n",
      "2022-11-27 20:45:26.948768: validation loss: -0.8375\n",
      "2022-11-27 20:45:26.949145: Average global foreground Dice: [0.8911, 0.8759]\n",
      "2022-11-27 20:45:26.949206: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:45:27.303687: lr: 0.004874\n",
      "2022-11-27 20:45:27.303790: saving scheduled checkpoint file...\n",
      "2022-11-27 20:45:27.307679: saving checkpoint...\n",
      "2022-11-27 20:45:27.372772: done, saving took 0.07 seconds\n",
      "2022-11-27 20:45:27.375738: done\n",
      "2022-11-27 20:45:27.375840: This epoch took 15.705642 s\n",
      "\n",
      "2022-11-27 20:45:27.375878: \n",
      "epoch:  550\n",
      "2022-11-27 20:45:41.620755: train loss : -0.9237\n",
      "2022-11-27 20:45:42.622973: validation loss: -0.8400\n",
      "2022-11-27 20:45:42.623312: Average global foreground Dice: [0.8952, 0.8756]\n",
      "2022-11-27 20:45:42.623370: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:45:42.978331: lr: 0.004864\n",
      "2022-11-27 20:45:42.978455: This epoch took 15.602527 s\n",
      "\n",
      "2022-11-27 20:45:42.978485: \n",
      "epoch:  551\n",
      "2022-11-27 20:45:57.168418: train loss : -0.9226\n",
      "2022-11-27 20:45:58.161630: validation loss: -0.8446\n",
      "2022-11-27 20:45:58.162295: Average global foreground Dice: [0.8979, 0.8813]\n",
      "2022-11-27 20:45:58.162429: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:45:58.524284: lr: 0.004855\n",
      "2022-11-27 20:45:58.524409: This epoch took 15.545882 s\n",
      "\n",
      "2022-11-27 20:45:58.524439: \n",
      "epoch:  552\n",
      "2022-11-27 20:46:12.804540: train loss : -0.9230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 20:46:13.822845: validation loss: -0.8375\n",
      "2022-11-27 20:46:13.823175: Average global foreground Dice: [0.8929, 0.8749]\n",
      "2022-11-27 20:46:13.823235: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:46:14.179863: lr: 0.004845\n",
      "2022-11-27 20:46:14.179984: This epoch took 15.655503 s\n",
      "\n",
      "2022-11-27 20:46:14.180017: \n",
      "epoch:  553\n",
      "2022-11-27 20:46:28.449236: train loss : -0.9229\n",
      "2022-11-27 20:46:29.443127: validation loss: -0.8405\n",
      "2022-11-27 20:46:29.443464: Average global foreground Dice: [0.8961, 0.8769]\n",
      "2022-11-27 20:46:29.443519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:46:29.805171: lr: 0.004835\n",
      "2022-11-27 20:46:29.805278: This epoch took 15.625225 s\n",
      "\n",
      "2022-11-27 20:46:29.805321: \n",
      "epoch:  554\n",
      "2022-11-27 20:46:44.070704: train loss : -0.9241\n",
      "2022-11-27 20:46:45.112503: validation loss: -0.8373\n",
      "2022-11-27 20:46:45.112880: Average global foreground Dice: [0.8928, 0.8748]\n",
      "2022-11-27 20:46:45.112939: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:46:45.468398: lr: 0.004825\n",
      "2022-11-27 20:46:45.468518: This epoch took 15.663153 s\n",
      "\n",
      "2022-11-27 20:46:45.468548: \n",
      "epoch:  555\n",
      "2022-11-27 20:46:59.821170: train loss : -0.9232\n",
      "2022-11-27 20:47:00.834669: validation loss: -0.8339\n",
      "2022-11-27 20:47:00.835060: Average global foreground Dice: [0.8906, 0.8733]\n",
      "2022-11-27 20:47:00.835118: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:47:01.190935: lr: 0.004816\n",
      "2022-11-27 20:47:01.191045: This epoch took 15.722470 s\n",
      "\n",
      "2022-11-27 20:47:01.191076: \n",
      "epoch:  556\n",
      "2022-11-27 20:47:15.440307: train loss : -0.9245\n",
      "2022-11-27 20:47:16.449371: validation loss: -0.8387\n",
      "2022-11-27 20:47:16.449757: Average global foreground Dice: [0.8949, 0.8758]\n",
      "2022-11-27 20:47:16.449821: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:47:16.805513: lr: 0.004806\n",
      "2022-11-27 20:47:16.805644: This epoch took 15.614541 s\n",
      "\n",
      "2022-11-27 20:47:16.805675: \n",
      "epoch:  557\n",
      "2022-11-27 20:47:31.067346: train loss : -0.9240\n",
      "2022-11-27 20:47:32.078218: validation loss: -0.8423\n",
      "2022-11-27 20:47:32.078561: Average global foreground Dice: [0.8972, 0.8793]\n",
      "2022-11-27 20:47:32.078641: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:47:32.436064: lr: 0.004796\n",
      "2022-11-27 20:47:32.436167: This epoch took 15.630466 s\n",
      "\n",
      "2022-11-27 20:47:32.436195: \n",
      "epoch:  558\n",
      "2022-11-27 20:47:46.718613: train loss : -0.9246\n",
      "2022-11-27 20:47:47.730903: validation loss: -0.8345\n",
      "2022-11-27 20:47:47.731498: Average global foreground Dice: [0.8919, 0.8738]\n",
      "2022-11-27 20:47:47.731676: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:47:48.205314: lr: 0.004786\n",
      "2022-11-27 20:47:48.205428: This epoch took 15.769206 s\n",
      "\n",
      "2022-11-27 20:47:48.205455: \n",
      "epoch:  559\n",
      "2022-11-27 20:48:02.476395: train loss : -0.9247\n",
      "2022-11-27 20:48:03.501221: validation loss: -0.8475\n",
      "2022-11-27 20:48:03.501713: Average global foreground Dice: [0.9006, 0.8831]\n",
      "2022-11-27 20:48:03.501878: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:48:03.861600: lr: 0.004776\n",
      "2022-11-27 20:48:03.861714: This epoch took 15.656234 s\n",
      "\n",
      "2022-11-27 20:48:03.861742: \n",
      "epoch:  560\n",
      "2022-11-27 20:48:18.136729: train loss : -0.9230\n",
      "2022-11-27 20:48:19.132837: validation loss: -0.8405\n",
      "2022-11-27 20:48:19.133171: Average global foreground Dice: [0.8936, 0.8755]\n",
      "2022-11-27 20:48:19.133231: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:48:19.494236: lr: 0.004767\n",
      "2022-11-27 20:48:19.494348: This epoch took 15.632578 s\n",
      "\n",
      "2022-11-27 20:48:19.494377: \n",
      "epoch:  561\n",
      "2022-11-27 20:48:33.711269: train loss : -0.9234\n",
      "2022-11-27 20:48:34.707819: validation loss: -0.8365\n",
      "2022-11-27 20:48:34.708198: Average global foreground Dice: [0.8923, 0.8746]\n",
      "2022-11-27 20:48:34.708256: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:48:35.064486: lr: 0.004757\n",
      "2022-11-27 20:48:35.064597: This epoch took 15.570193 s\n",
      "\n",
      "2022-11-27 20:48:35.064623: \n",
      "epoch:  562\n",
      "2022-11-27 20:48:49.354255: train loss : -0.9256\n",
      "2022-11-27 20:48:50.380165: validation loss: -0.8396\n",
      "2022-11-27 20:48:50.380554: Average global foreground Dice: [0.8941, 0.8772]\n",
      "2022-11-27 20:48:50.380615: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:48:50.736237: lr: 0.004747\n",
      "2022-11-27 20:48:50.736352: This epoch took 15.671703 s\n",
      "\n",
      "2022-11-27 20:48:50.736382: \n",
      "epoch:  563\n",
      "2022-11-27 20:49:04.994293: train loss : -0.9250\n",
      "2022-11-27 20:49:05.994626: validation loss: -0.8432\n",
      "2022-11-27 20:49:05.995225: Average global foreground Dice: [0.8974, 0.8801]\n",
      "2022-11-27 20:49:05.995331: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:49:06.385258: lr: 0.004737\n",
      "2022-11-27 20:49:06.385369: This epoch took 15.648959 s\n",
      "\n",
      "2022-11-27 20:49:06.385397: \n",
      "epoch:  564\n",
      "2022-11-27 20:49:20.633105: train loss : -0.9248\n",
      "2022-11-27 20:49:21.642401: validation loss: -0.8296\n",
      "2022-11-27 20:49:21.642814: Average global foreground Dice: [0.8892, 0.8709]\n",
      "2022-11-27 20:49:21.642970: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:49:22.020818: lr: 0.004728\n",
      "2022-11-27 20:49:22.020927: This epoch took 15.635506 s\n",
      "\n",
      "2022-11-27 20:49:22.020957: \n",
      "epoch:  565\n",
      "2022-11-27 20:49:36.301805: train loss : -0.9246\n",
      "2022-11-27 20:49:37.323845: validation loss: -0.8434\n",
      "2022-11-27 20:49:37.324171: Average global foreground Dice: [0.8978, 0.8795]\n",
      "2022-11-27 20:49:37.324227: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:49:37.678728: lr: 0.004718\n",
      "2022-11-27 20:49:37.678838: This epoch took 15.657855 s\n",
      "\n",
      "2022-11-27 20:49:37.678867: \n",
      "epoch:  566\n",
      "2022-11-27 20:49:51.961870: train loss : -0.9229\n",
      "2022-11-27 20:49:52.971342: validation loss: -0.8378\n",
      "2022-11-27 20:49:52.971725: Average global foreground Dice: [0.8949, 0.876]\n",
      "2022-11-27 20:49:52.971802: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:49:53.382462: lr: 0.004708\n",
      "2022-11-27 20:49:53.382570: This epoch took 15.703671 s\n",
      "\n",
      "2022-11-27 20:49:53.382596: \n",
      "epoch:  567\n",
      "2022-11-27 20:50:07.602917: train loss : -0.9240\n",
      "2022-11-27 20:50:08.629334: validation loss: -0.8381\n",
      "2022-11-27 20:50:08.629672: Average global foreground Dice: [0.894, 0.8777]\n",
      "2022-11-27 20:50:08.629727: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:50:09.002281: lr: 0.004698\n",
      "2022-11-27 20:50:09.002411: This epoch took 15.619789 s\n",
      "\n",
      "2022-11-27 20:50:09.002457: \n",
      "epoch:  568\n",
      "2022-11-27 20:50:23.255095: train loss : -0.9240\n",
      "2022-11-27 20:50:24.248996: validation loss: -0.8377\n",
      "2022-11-27 20:50:24.249378: Average global foreground Dice: [0.8912, 0.8766]\n",
      "2022-11-27 20:50:24.249438: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:50:24.609198: lr: 0.004688\n",
      "2022-11-27 20:50:24.609314: This epoch took 15.606814 s\n",
      "\n",
      "2022-11-27 20:50:24.609345: \n",
      "epoch:  569\n",
      "2022-11-27 20:50:38.839213: train loss : -0.9237\n",
      "2022-11-27 20:50:39.908668: validation loss: -0.8432\n",
      "2022-11-27 20:50:39.909549: Average global foreground Dice: [0.8967, 0.8806]\n",
      "2022-11-27 20:50:39.909706: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:50:40.416546: lr: 0.004679\n",
      "2022-11-27 20:50:40.416653: This epoch took 15.807281 s\n",
      "\n",
      "2022-11-27 20:50:40.416678: \n",
      "epoch:  570\n",
      "2022-11-27 20:50:54.729777: train loss : -0.9233\n",
      "2022-11-27 20:50:55.759392: validation loss: -0.8406\n",
      "2022-11-27 20:50:55.759728: Average global foreground Dice: [0.8957, 0.8794]\n",
      "2022-11-27 20:50:55.759793: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:50:56.128181: lr: 0.004669\n",
      "2022-11-27 20:50:56.128306: This epoch took 15.711587 s\n",
      "\n",
      "2022-11-27 20:50:56.128336: \n",
      "epoch:  571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 20:51:10.455080: train loss : -0.9251\n",
      "2022-11-27 20:51:11.449176: validation loss: -0.8408\n",
      "2022-11-27 20:51:11.449503: Average global foreground Dice: [0.8954, 0.8793]\n",
      "2022-11-27 20:51:11.449559: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:51:11.809556: lr: 0.004659\n",
      "2022-11-27 20:51:11.809666: This epoch took 15.681304 s\n",
      "\n",
      "2022-11-27 20:51:11.809692: \n",
      "epoch:  572\n",
      "2022-11-27 20:51:26.129867: train loss : -0.9240\n",
      "2022-11-27 20:51:27.127838: validation loss: -0.8431\n",
      "2022-11-27 20:51:27.128298: Average global foreground Dice: [0.8953, 0.8796]\n",
      "2022-11-27 20:51:27.128381: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:51:27.492960: lr: 0.004649\n",
      "2022-11-27 20:51:27.493064: This epoch took 15.683348 s\n",
      "\n",
      "2022-11-27 20:51:27.493094: \n",
      "epoch:  573\n",
      "2022-11-27 20:51:41.782128: train loss : -0.9241\n",
      "2022-11-27 20:51:42.784024: validation loss: -0.8439\n",
      "2022-11-27 20:51:42.784361: Average global foreground Dice: [0.896, 0.8806]\n",
      "2022-11-27 20:51:42.784420: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:51:43.149416: lr: 0.004639\n",
      "2022-11-27 20:51:43.149531: This epoch took 15.656395 s\n",
      "\n",
      "2022-11-27 20:51:43.149563: \n",
      "epoch:  574\n",
      "2022-11-27 20:51:57.416250: train loss : -0.9231\n",
      "2022-11-27 20:51:58.417975: validation loss: -0.8377\n",
      "2022-11-27 20:51:58.418309: Average global foreground Dice: [0.894, 0.877]\n",
      "2022-11-27 20:51:58.418366: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:51:58.799186: lr: 0.00463\n",
      "2022-11-27 20:51:58.799298: This epoch took 15.649709 s\n",
      "\n",
      "2022-11-27 20:51:58.799328: \n",
      "epoch:  575\n",
      "2022-11-27 20:52:13.072784: train loss : -0.9242\n",
      "2022-11-27 20:52:14.062788: validation loss: -0.8348\n",
      "2022-11-27 20:52:14.063221: Average global foreground Dice: [0.8911, 0.8717]\n",
      "2022-11-27 20:52:14.063423: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:52:14.436704: lr: 0.00462\n",
      "2022-11-27 20:52:14.436814: This epoch took 15.637459 s\n",
      "\n",
      "2022-11-27 20:52:14.436843: \n",
      "epoch:  576\n",
      "2022-11-27 20:52:28.639577: train loss : -0.9254\n",
      "2022-11-27 20:52:29.628165: validation loss: -0.8407\n",
      "2022-11-27 20:52:29.628551: Average global foreground Dice: [0.8953, 0.8805]\n",
      "2022-11-27 20:52:29.628608: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:52:29.992544: lr: 0.00461\n",
      "2022-11-27 20:52:29.992665: This epoch took 15.555780 s\n",
      "\n",
      "2022-11-27 20:52:29.992695: \n",
      "epoch:  577\n",
      "2022-11-27 20:52:44.229223: train loss : -0.9242\n",
      "2022-11-27 20:52:45.241268: validation loss: -0.8406\n",
      "2022-11-27 20:52:45.241607: Average global foreground Dice: [0.8954, 0.8781]\n",
      "2022-11-27 20:52:45.241663: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:52:45.603269: lr: 0.0046\n",
      "2022-11-27 20:52:45.603372: This epoch took 15.610651 s\n",
      "\n",
      "2022-11-27 20:52:45.603398: \n",
      "epoch:  578\n",
      "2022-11-27 20:52:59.863518: train loss : -0.9239\n",
      "2022-11-27 20:53:00.857043: validation loss: -0.8392\n",
      "2022-11-27 20:53:00.857394: Average global foreground Dice: [0.8944, 0.8775]\n",
      "2022-11-27 20:53:00.857451: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:53:01.220185: lr: 0.00459\n",
      "2022-11-27 20:53:01.220300: This epoch took 15.616861 s\n",
      "\n",
      "2022-11-27 20:53:01.220331: \n",
      "epoch:  579\n",
      "2022-11-27 20:53:15.470408: train loss : -0.9250\n",
      "2022-11-27 20:53:16.485264: validation loss: -0.8437\n",
      "2022-11-27 20:53:16.485593: Average global foreground Dice: [0.8957, 0.8812]\n",
      "2022-11-27 20:53:16.485652: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:53:16.956634: lr: 0.004581\n",
      "2022-11-27 20:53:16.956756: This epoch took 15.736399 s\n",
      "\n",
      "2022-11-27 20:53:16.956786: \n",
      "epoch:  580\n",
      "2022-11-27 20:53:31.234853: train loss : -0.9240\n",
      "2022-11-27 20:53:32.230599: validation loss: -0.8449\n",
      "2022-11-27 20:53:32.230985: Average global foreground Dice: [0.8983, 0.8817]\n",
      "2022-11-27 20:53:32.231155: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:53:32.601245: lr: 0.004571\n",
      "2022-11-27 20:53:32.601370: This epoch took 15.644540 s\n",
      "\n",
      "2022-11-27 20:53:32.601405: \n",
      "epoch:  581\n",
      "2022-11-27 20:53:46.841338: train loss : -0.9263\n",
      "2022-11-27 20:53:47.836134: validation loss: -0.8390\n",
      "2022-11-27 20:53:47.836510: Average global foreground Dice: [0.8937, 0.8768]\n",
      "2022-11-27 20:53:47.836568: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:53:48.194153: lr: 0.004561\n",
      "2022-11-27 20:53:48.194266: This epoch took 15.592834 s\n",
      "\n",
      "2022-11-27 20:53:48.194296: \n",
      "epoch:  582\n",
      "2022-11-27 20:54:02.398744: train loss : -0.9242\n",
      "2022-11-27 20:54:03.416022: validation loss: -0.8411\n",
      "2022-11-27 20:54:03.416402: Average global foreground Dice: [0.894, 0.8792]\n",
      "2022-11-27 20:54:03.416461: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:54:03.774855: lr: 0.004551\n",
      "2022-11-27 20:54:03.774972: This epoch took 15.580649 s\n",
      "\n",
      "2022-11-27 20:54:03.775002: \n",
      "epoch:  583\n",
      "2022-11-27 20:54:18.028198: train loss : -0.9250\n",
      "2022-11-27 20:54:19.039375: validation loss: -0.8416\n",
      "2022-11-27 20:54:19.039722: Average global foreground Dice: [0.8954, 0.878]\n",
      "2022-11-27 20:54:19.039777: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:54:19.395259: lr: 0.004541\n",
      "2022-11-27 20:54:19.395384: This epoch took 15.620339 s\n",
      "\n",
      "2022-11-27 20:54:19.395416: \n",
      "epoch:  584\n",
      "2022-11-27 20:54:33.630226: train loss : -0.9266\n",
      "2022-11-27 20:54:34.653950: validation loss: -0.8383\n",
      "2022-11-27 20:54:34.654320: Average global foreground Dice: [0.8933, 0.8771]\n",
      "2022-11-27 20:54:34.654378: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:54:35.014111: lr: 0.004532\n",
      "2022-11-27 20:54:35.014225: This epoch took 15.618781 s\n",
      "\n",
      "2022-11-27 20:54:35.014254: \n",
      "epoch:  585\n",
      "2022-11-27 20:54:49.310116: train loss : -0.9239\n",
      "2022-11-27 20:54:50.366719: validation loss: -0.8414\n",
      "2022-11-27 20:54:50.367057: Average global foreground Dice: [0.895, 0.8788]\n",
      "2022-11-27 20:54:50.367291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:54:50.730443: lr: 0.004522\n",
      "2022-11-27 20:54:50.730553: This epoch took 15.716272 s\n",
      "\n",
      "2022-11-27 20:54:50.730580: \n",
      "epoch:  586\n",
      "2022-11-27 20:55:05.035034: train loss : -0.9257\n",
      "2022-11-27 20:55:06.048965: validation loss: -0.8436\n",
      "2022-11-27 20:55:06.049346: Average global foreground Dice: [0.8983, 0.8813]\n",
      "2022-11-27 20:55:06.049501: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:55:06.409470: lr: 0.004512\n",
      "2022-11-27 20:55:06.409575: This epoch took 15.678968 s\n",
      "\n",
      "2022-11-27 20:55:06.409601: \n",
      "epoch:  587\n",
      "2022-11-27 20:55:20.703430: train loss : -0.9250\n",
      "2022-11-27 20:55:21.715466: validation loss: -0.8411\n",
      "2022-11-27 20:55:21.715844: Average global foreground Dice: [0.8956, 0.8788]\n",
      "2022-11-27 20:55:21.715900: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:55:22.075923: lr: 0.004502\n",
      "2022-11-27 20:55:22.076030: This epoch took 15.666404 s\n",
      "\n",
      "2022-11-27 20:55:22.076059: \n",
      "epoch:  588\n",
      "2022-11-27 20:55:36.296445: train loss : -0.9245\n",
      "2022-11-27 20:55:37.285878: validation loss: -0.8441\n",
      "2022-11-27 20:55:37.286300: Average global foreground Dice: [0.8969, 0.8778]\n",
      "2022-11-27 20:55:37.286434: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:55:37.650231: lr: 0.004492\n",
      "2022-11-27 20:55:37.650332: This epoch took 15.574246 s\n",
      "\n",
      "2022-11-27 20:55:37.650361: \n",
      "epoch:  589\n",
      "2022-11-27 20:55:51.963917: train loss : -0.9257\n",
      "2022-11-27 20:55:52.975695: validation loss: -0.8352\n",
      "2022-11-27 20:55:52.976043: Average global foreground Dice: [0.8928, 0.8754]\n",
      "2022-11-27 20:55:52.976099: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:55:53.336838: lr: 0.004482\n",
      "2022-11-27 20:55:53.336942: This epoch took 15.686555 s\n",
      "\n",
      "2022-11-27 20:55:53.336970: \n",
      "epoch:  590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 20:56:07.632389: train loss : -0.9256\n",
      "2022-11-27 20:56:08.633064: validation loss: -0.8393\n",
      "2022-11-27 20:56:08.633437: Average global foreground Dice: [0.8941, 0.8774]\n",
      "2022-11-27 20:56:08.633526: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:56:09.146153: lr: 0.004473\n",
      "2022-11-27 20:56:09.146285: This epoch took 15.809273 s\n",
      "\n",
      "2022-11-27 20:56:09.146318: \n",
      "epoch:  591\n",
      "2022-11-27 20:56:23.393617: train loss : -0.9253\n",
      "2022-11-27 20:56:24.395447: validation loss: -0.8403\n",
      "2022-11-27 20:56:24.395825: Average global foreground Dice: [0.8967, 0.8789]\n",
      "2022-11-27 20:56:24.395887: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:56:24.783465: lr: 0.004463\n",
      "2022-11-27 20:56:24.783579: This epoch took 15.637225 s\n",
      "\n",
      "2022-11-27 20:56:24.783609: \n",
      "epoch:  592\n",
      "2022-11-27 20:56:39.008840: train loss : -0.9243\n",
      "2022-11-27 20:56:40.006878: validation loss: -0.8455\n",
      "2022-11-27 20:56:40.007208: Average global foreground Dice: [0.8994, 0.8832]\n",
      "2022-11-27 20:56:40.007267: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:56:40.370320: lr: 0.004453\n",
      "2022-11-27 20:56:40.370435: This epoch took 15.586799 s\n",
      "\n",
      "2022-11-27 20:56:40.370462: \n",
      "epoch:  593\n",
      "2022-11-27 20:56:54.660655: train loss : -0.9266\n",
      "2022-11-27 20:56:55.657328: validation loss: -0.8369\n",
      "2022-11-27 20:56:55.657714: Average global foreground Dice: [0.8939, 0.8792]\n",
      "2022-11-27 20:56:55.657828: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:56:56.023336: lr: 0.004443\n",
      "2022-11-27 20:56:56.023450: This epoch took 15.652961 s\n",
      "\n",
      "2022-11-27 20:56:56.023480: \n",
      "epoch:  594\n",
      "2022-11-27 20:57:10.261751: train loss : -0.9265\n",
      "2022-11-27 20:57:11.299623: validation loss: -0.8386\n",
      "2022-11-27 20:57:11.299972: Average global foreground Dice: [0.8947, 0.8803]\n",
      "2022-11-27 20:57:11.300028: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:57:11.665369: lr: 0.004433\n",
      "2022-11-27 20:57:11.665473: This epoch took 15.641966 s\n",
      "\n",
      "2022-11-27 20:57:11.665518: \n",
      "epoch:  595\n",
      "2022-11-27 20:57:25.969331: train loss : -0.9254\n",
      "2022-11-27 20:57:26.973294: validation loss: -0.8377\n",
      "2022-11-27 20:57:26.973636: Average global foreground Dice: [0.893, 0.877]\n",
      "2022-11-27 20:57:26.973694: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:57:27.340612: lr: 0.004423\n",
      "2022-11-27 20:57:27.340719: This epoch took 15.675175 s\n",
      "\n",
      "2022-11-27 20:57:27.340747: \n",
      "epoch:  596\n",
      "2022-11-27 20:57:41.605252: train loss : -0.9250\n",
      "2022-11-27 20:57:42.618663: validation loss: -0.8435\n",
      "2022-11-27 20:57:42.619141: Average global foreground Dice: [0.8972, 0.8806]\n",
      "2022-11-27 20:57:42.619217: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:57:42.981551: lr: 0.004413\n",
      "2022-11-27 20:57:42.981657: This epoch took 15.640883 s\n",
      "\n",
      "2022-11-27 20:57:42.981685: \n",
      "epoch:  597\n",
      "2022-11-27 20:57:57.230046: train loss : -0.9242\n",
      "2022-11-27 20:57:58.243373: validation loss: -0.8416\n",
      "2022-11-27 20:57:58.243753: Average global foreground Dice: [0.8956, 0.8804]\n",
      "2022-11-27 20:57:58.243817: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:57:58.608372: lr: 0.004404\n",
      "2022-11-27 20:57:58.608473: This epoch took 15.626761 s\n",
      "\n",
      "2022-11-27 20:57:58.608500: \n",
      "epoch:  598\n",
      "2022-11-27 20:58:12.846400: train loss : -0.9261\n",
      "2022-11-27 20:58:13.880313: validation loss: -0.8393\n",
      "2022-11-27 20:58:13.880648: Average global foreground Dice: [0.894, 0.8771]\n",
      "2022-11-27 20:58:13.880701: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:58:14.244020: lr: 0.004394\n",
      "2022-11-27 20:58:14.244124: This epoch took 15.635595 s\n",
      "\n",
      "2022-11-27 20:58:14.244157: \n",
      "epoch:  599\n",
      "2022-11-27 20:58:28.524696: train loss : -0.9244\n",
      "2022-11-27 20:58:29.529186: validation loss: -0.8424\n",
      "2022-11-27 20:58:29.529518: Average global foreground Dice: [0.8945, 0.8813]\n",
      "2022-11-27 20:58:29.529572: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:58:29.891674: lr: 0.004384\n",
      "2022-11-27 20:58:29.891764: saving scheduled checkpoint file...\n",
      "2022-11-27 20:58:29.895638: saving checkpoint...\n",
      "2022-11-27 20:58:30.077557: done, saving took 0.19 seconds\n",
      "2022-11-27 20:58:30.103478: done\n",
      "2022-11-27 20:58:30.103577: This epoch took 15.859390 s\n",
      "\n",
      "2022-11-27 20:58:30.103607: \n",
      "epoch:  600\n",
      "2022-11-27 20:58:44.333109: train loss : -0.9255\n",
      "2022-11-27 20:58:45.345688: validation loss: -0.8408\n",
      "2022-11-27 20:58:45.346037: Average global foreground Dice: [0.8967, 0.8794]\n",
      "2022-11-27 20:58:45.346101: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:58:45.717031: lr: 0.004374\n",
      "2022-11-27 20:58:45.717161: This epoch took 15.613509 s\n",
      "\n",
      "2022-11-27 20:58:45.717192: \n",
      "epoch:  601\n",
      "2022-11-27 20:59:00.046041: train loss : -0.9280\n",
      "2022-11-27 20:59:01.052091: validation loss: -0.8428\n",
      "2022-11-27 20:59:01.052838: Average global foreground Dice: [0.8987, 0.8774]\n",
      "2022-11-27 20:59:01.053611: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:59:01.431962: lr: 0.004364\n",
      "2022-11-27 20:59:01.432085: This epoch took 15.714851 s\n",
      "\n",
      "2022-11-27 20:59:01.432117: \n",
      "epoch:  602\n",
      "2022-11-27 20:59:15.740359: train loss : -0.9259\n",
      "2022-11-27 20:59:16.758344: validation loss: -0.8425\n",
      "2022-11-27 20:59:16.758684: Average global foreground Dice: [0.8971, 0.8827]\n",
      "2022-11-27 20:59:16.758736: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:59:17.130045: lr: 0.004354\n",
      "2022-11-27 20:59:17.134124: saving checkpoint...\n",
      "2022-11-27 20:59:17.201289: done, saving took 0.07 seconds\n",
      "2022-11-27 20:59:17.205940: This epoch took 15.773793 s\n",
      "\n",
      "2022-11-27 20:59:17.206060: \n",
      "epoch:  603\n",
      "2022-11-27 20:59:31.439372: train loss : -0.9289\n",
      "2022-11-27 20:59:32.501153: validation loss: -0.8385\n",
      "2022-11-27 20:59:32.501534: Average global foreground Dice: [0.8948, 0.8779]\n",
      "2022-11-27 20:59:32.501592: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:59:32.885494: lr: 0.004344\n",
      "2022-11-27 20:59:32.885619: This epoch took 15.679480 s\n",
      "\n",
      "2022-11-27 20:59:32.885648: \n",
      "epoch:  604\n",
      "2022-11-27 20:59:47.192740: train loss : -0.9262\n",
      "2022-11-27 20:59:48.197599: validation loss: -0.8422\n",
      "2022-11-27 20:59:48.197937: Average global foreground Dice: [0.8963, 0.8792]\n",
      "2022-11-27 20:59:48.198002: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 20:59:48.587857: lr: 0.004334\n",
      "2022-11-27 20:59:48.587962: This epoch took 15.702288 s\n",
      "\n",
      "2022-11-27 20:59:48.587988: \n",
      "epoch:  605\n",
      "2022-11-27 21:00:02.874597: train loss : -0.9244\n",
      "2022-11-27 21:00:03.864408: validation loss: -0.8384\n",
      "2022-11-27 21:00:03.864782: Average global foreground Dice: [0.8934, 0.8787]\n",
      "2022-11-27 21:00:03.864838: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:00:04.231682: lr: 0.004325\n",
      "2022-11-27 21:00:04.231787: This epoch took 15.643770 s\n",
      "\n",
      "2022-11-27 21:00:04.231814: \n",
      "epoch:  606\n",
      "2022-11-27 21:00:18.477369: train loss : -0.9271\n",
      "2022-11-27 21:00:19.470425: validation loss: -0.8440\n",
      "2022-11-27 21:00:19.470753: Average global foreground Dice: [0.8966, 0.881]\n",
      "2022-11-27 21:00:19.470811: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:00:19.832930: lr: 0.004315\n",
      "2022-11-27 21:00:19.833032: This epoch took 15.601193 s\n",
      "\n",
      "2022-11-27 21:00:19.833058: \n",
      "epoch:  607\n",
      "2022-11-27 21:00:34.050522: train loss : -0.9241\n",
      "2022-11-27 21:00:35.041243: validation loss: -0.8383\n",
      "2022-11-27 21:00:35.041589: Average global foreground Dice: [0.8926, 0.8771]\n",
      "2022-11-27 21:00:35.041645: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:00:35.413463: lr: 0.004305\n",
      "2022-11-27 21:00:35.413569: This epoch took 15.580486 s\n",
      "\n",
      "2022-11-27 21:00:35.413599: \n",
      "epoch:  608\n",
      "2022-11-27 21:00:49.628105: train loss : -0.9226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:00:50.669549: validation loss: -0.8397\n",
      "2022-11-27 21:00:50.670071: Average global foreground Dice: [0.8963, 0.8778]\n",
      "2022-11-27 21:00:50.670350: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:00:51.040052: lr: 0.004295\n",
      "2022-11-27 21:00:51.040170: This epoch took 15.626530 s\n",
      "\n",
      "2022-11-27 21:00:51.040203: \n",
      "epoch:  609\n",
      "2022-11-27 21:01:05.304806: train loss : -0.9264\n",
      "2022-11-27 21:01:06.313607: validation loss: -0.8436\n",
      "2022-11-27 21:01:06.314000: Average global foreground Dice: [0.8983, 0.8815]\n",
      "2022-11-27 21:01:06.314066: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:01:06.680712: lr: 0.004285\n",
      "2022-11-27 21:01:06.680813: This epoch took 15.640583 s\n",
      "\n",
      "2022-11-27 21:01:06.680839: \n",
      "epoch:  610\n",
      "2022-11-27 21:01:21.000646: train loss : -0.9250\n",
      "2022-11-27 21:01:22.005558: validation loss: -0.8340\n",
      "2022-11-27 21:01:22.005963: Average global foreground Dice: [0.8936, 0.8755]\n",
      "2022-11-27 21:01:22.006074: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:01:22.505557: lr: 0.004275\n",
      "2022-11-27 21:01:22.505736: This epoch took 15.824872 s\n",
      "\n",
      "2022-11-27 21:01:22.505853: \n",
      "epoch:  611\n",
      "2022-11-27 21:01:36.813204: train loss : -0.9276\n",
      "2022-11-27 21:01:37.812508: validation loss: -0.8386\n",
      "2022-11-27 21:01:37.812889: Average global foreground Dice: [0.8943, 0.8786]\n",
      "2022-11-27 21:01:37.812949: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:01:38.205309: lr: 0.004265\n",
      "2022-11-27 21:01:38.205434: This epoch took 15.699552 s\n",
      "\n",
      "2022-11-27 21:01:38.205463: \n",
      "epoch:  612\n",
      "2022-11-27 21:01:52.493581: train loss : -0.9251\n",
      "2022-11-27 21:01:53.495933: validation loss: -0.8455\n",
      "2022-11-27 21:01:53.496269: Average global foreground Dice: [0.8994, 0.8837]\n",
      "2022-11-27 21:01:53.496328: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:01:53.868223: lr: 0.004255\n",
      "2022-11-27 21:01:53.868334: This epoch took 15.662844 s\n",
      "\n",
      "2022-11-27 21:01:53.868361: \n",
      "epoch:  613\n",
      "2022-11-27 21:02:08.136359: train loss : -0.9236\n",
      "2022-11-27 21:02:09.160480: validation loss: -0.8396\n",
      "2022-11-27 21:02:09.161022: Average global foreground Dice: [0.8954, 0.8783]\n",
      "2022-11-27 21:02:09.161127: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:02:09.535396: lr: 0.004245\n",
      "2022-11-27 21:02:09.535504: This epoch took 15.667118 s\n",
      "\n",
      "2022-11-27 21:02:09.535533: \n",
      "epoch:  614\n",
      "2022-11-27 21:02:23.791452: train loss : -0.9236\n",
      "2022-11-27 21:02:24.775047: validation loss: -0.8404\n",
      "2022-11-27 21:02:24.775431: Average global foreground Dice: [0.8966, 0.8752]\n",
      "2022-11-27 21:02:24.775494: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:02:25.144447: lr: 0.004236\n",
      "2022-11-27 21:02:25.144552: This epoch took 15.608992 s\n",
      "\n",
      "2022-11-27 21:02:25.144579: \n",
      "epoch:  615\n",
      "2022-11-27 21:02:39.378645: train loss : -0.9264\n",
      "2022-11-27 21:02:40.399397: validation loss: -0.8406\n",
      "2022-11-27 21:02:40.399868: Average global foreground Dice: [0.8952, 0.8786]\n",
      "2022-11-27 21:02:40.399959: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:02:40.788756: lr: 0.004226\n",
      "2022-11-27 21:02:40.788977: This epoch took 15.644373 s\n",
      "\n",
      "2022-11-27 21:02:40.789011: \n",
      "epoch:  616\n",
      "2022-11-27 21:02:55.064418: train loss : -0.9249\n",
      "2022-11-27 21:02:56.050375: validation loss: -0.8399\n",
      "2022-11-27 21:02:56.050767: Average global foreground Dice: [0.8946, 0.8762]\n",
      "2022-11-27 21:02:56.050822: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:02:56.428215: lr: 0.004216\n",
      "2022-11-27 21:02:56.428320: This epoch took 15.639283 s\n",
      "\n",
      "2022-11-27 21:02:56.428349: \n",
      "epoch:  617\n",
      "2022-11-27 21:03:10.663080: train loss : -0.9274\n",
      "2022-11-27 21:03:11.695451: validation loss: -0.8363\n",
      "2022-11-27 21:03:11.695786: Average global foreground Dice: [0.8924, 0.8753]\n",
      "2022-11-27 21:03:11.695843: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:03:12.083724: lr: 0.004206\n",
      "2022-11-27 21:03:12.083844: This epoch took 15.655453 s\n",
      "\n",
      "2022-11-27 21:03:12.083874: \n",
      "epoch:  618\n",
      "2022-11-27 21:03:26.324127: train loss : -0.9277\n",
      "2022-11-27 21:03:27.333954: validation loss: -0.8380\n",
      "2022-11-27 21:03:27.334342: Average global foreground Dice: [0.8935, 0.8759]\n",
      "2022-11-27 21:03:27.334399: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:03:27.702564: lr: 0.004196\n",
      "2022-11-27 21:03:27.702784: This epoch took 15.618882 s\n",
      "\n",
      "2022-11-27 21:03:27.702816: \n",
      "epoch:  619\n",
      "2022-11-27 21:03:41.954401: train loss : -0.9256\n",
      "2022-11-27 21:03:42.967996: validation loss: -0.8405\n",
      "2022-11-27 21:03:42.968332: Average global foreground Dice: [0.8936, 0.8791]\n",
      "2022-11-27 21:03:42.968383: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:03:43.332694: lr: 0.004186\n",
      "2022-11-27 21:03:43.332792: This epoch took 15.629949 s\n",
      "\n",
      "2022-11-27 21:03:43.332818: \n",
      "epoch:  620\n",
      "2022-11-27 21:03:57.543273: train loss : -0.9272\n",
      "2022-11-27 21:03:58.547085: validation loss: -0.8390\n",
      "2022-11-27 21:03:58.547417: Average global foreground Dice: [0.894, 0.8788]\n",
      "2022-11-27 21:03:58.547473: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:03:59.043237: lr: 0.004176\n",
      "2022-11-27 21:03:59.043386: This epoch took 15.710528 s\n",
      "\n",
      "2022-11-27 21:03:59.043417: \n",
      "epoch:  621\n",
      "2022-11-27 21:04:13.286638: train loss : -0.9268\n",
      "2022-11-27 21:04:14.293956: validation loss: -0.8413\n",
      "2022-11-27 21:04:14.297103: Average global foreground Dice: [0.8969, 0.8771]\n",
      "2022-11-27 21:04:14.297200: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:04:14.662006: lr: 0.004166\n",
      "2022-11-27 21:04:14.662125: This epoch took 15.618666 s\n",
      "\n",
      "2022-11-27 21:04:14.662157: \n",
      "epoch:  622\n",
      "2022-11-27 21:04:29.018139: train loss : -0.9265\n",
      "2022-11-27 21:04:30.010614: validation loss: -0.8313\n",
      "2022-11-27 21:04:30.010948: Average global foreground Dice: [0.8897, 0.8714]\n",
      "2022-11-27 21:04:30.011003: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:04:30.377833: lr: 0.004156\n",
      "2022-11-27 21:04:30.377949: This epoch took 15.715765 s\n",
      "\n",
      "2022-11-27 21:04:30.377998: \n",
      "epoch:  623\n",
      "2022-11-27 21:04:44.626047: train loss : -0.9281\n",
      "2022-11-27 21:04:45.623203: validation loss: -0.8419\n",
      "2022-11-27 21:04:45.623529: Average global foreground Dice: [0.8973, 0.8806]\n",
      "2022-11-27 21:04:45.623582: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:04:45.997589: lr: 0.004146\n",
      "2022-11-27 21:04:45.997694: This epoch took 15.619669 s\n",
      "\n",
      "2022-11-27 21:04:45.997721: \n",
      "epoch:  624\n",
      "2022-11-27 21:05:00.251992: train loss : -0.9272\n",
      "2022-11-27 21:05:01.260361: validation loss: -0.8389\n",
      "2022-11-27 21:05:01.260763: Average global foreground Dice: [0.8929, 0.8768]\n",
      "2022-11-27 21:05:01.260824: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:05:01.627713: lr: 0.004136\n",
      "2022-11-27 21:05:01.627816: This epoch took 15.630071 s\n",
      "\n",
      "2022-11-27 21:05:01.627843: \n",
      "epoch:  625\n",
      "2022-11-27 21:05:15.870714: train loss : -0.9257\n",
      "2022-11-27 21:05:16.880409: validation loss: -0.8357\n",
      "2022-11-27 21:05:16.880839: Average global foreground Dice: [0.8926, 0.8758]\n",
      "2022-11-27 21:05:16.881032: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:05:17.257708: lr: 0.004127\n",
      "2022-11-27 21:05:17.257829: This epoch took 15.629945 s\n",
      "\n",
      "2022-11-27 21:05:17.257861: \n",
      "epoch:  626\n",
      "2022-11-27 21:05:31.487317: train loss : -0.9251\n",
      "2022-11-27 21:05:32.519160: validation loss: -0.8431\n",
      "2022-11-27 21:05:32.519499: Average global foreground Dice: [0.8961, 0.8807]\n",
      "2022-11-27 21:05:32.519553: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:05:32.884248: lr: 0.004117\n",
      "2022-11-27 21:05:32.884368: This epoch took 15.626480 s\n",
      "\n",
      "2022-11-27 21:05:32.884397: \n",
      "epoch:  627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:05:47.190457: train loss : -0.9254\n",
      "2022-11-27 21:05:48.202874: validation loss: -0.8363\n",
      "2022-11-27 21:05:48.203259: Average global foreground Dice: [0.894, 0.8739]\n",
      "2022-11-27 21:05:48.203323: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:05:48.584068: lr: 0.004107\n",
      "2022-11-27 21:05:48.584170: This epoch took 15.699747 s\n",
      "\n",
      "2022-11-27 21:05:48.584198: \n",
      "epoch:  628\n",
      "2022-11-27 21:06:02.824185: train loss : -0.9262\n",
      "2022-11-27 21:06:03.795654: validation loss: -0.8329\n",
      "2022-11-27 21:06:03.795991: Average global foreground Dice: [0.8917, 0.8737]\n",
      "2022-11-27 21:06:03.796050: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:06:04.160071: lr: 0.004097\n",
      "2022-11-27 21:06:04.160188: This epoch took 15.575947 s\n",
      "\n",
      "2022-11-27 21:06:04.160218: \n",
      "epoch:  629\n",
      "2022-11-27 21:06:18.399730: train loss : -0.9245\n",
      "2022-11-27 21:06:19.411642: validation loss: -0.8428\n",
      "2022-11-27 21:06:19.411981: Average global foreground Dice: [0.8965, 0.8797]\n",
      "2022-11-27 21:06:19.412066: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:06:19.776263: lr: 0.004087\n",
      "2022-11-27 21:06:19.776371: This epoch took 15.616124 s\n",
      "\n",
      "2022-11-27 21:06:19.776400: \n",
      "epoch:  630\n",
      "2022-11-27 21:06:34.069526: train loss : -0.9261\n",
      "2022-11-27 21:06:35.082862: validation loss: -0.8370\n",
      "2022-11-27 21:06:35.083251: Average global foreground Dice: [0.8935, 0.8752]\n",
      "2022-11-27 21:06:35.083312: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:06:35.560714: lr: 0.004077\n",
      "2022-11-27 21:06:35.560838: This epoch took 15.784390 s\n",
      "\n",
      "2022-11-27 21:06:35.560872: \n",
      "epoch:  631\n",
      "2022-11-27 21:06:49.883072: train loss : -0.9267\n",
      "2022-11-27 21:06:50.882377: validation loss: -0.8361\n",
      "2022-11-27 21:06:50.882719: Average global foreground Dice: [0.8938, 0.8743]\n",
      "2022-11-27 21:06:50.882779: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:06:51.244623: lr: 0.004067\n",
      "2022-11-27 21:06:51.244737: This epoch took 15.683839 s\n",
      "\n",
      "2022-11-27 21:06:51.244766: \n",
      "epoch:  632\n",
      "2022-11-27 21:07:05.451412: train loss : -0.9277\n",
      "2022-11-27 21:07:06.454386: validation loss: -0.8458\n",
      "2022-11-27 21:07:06.454710: Average global foreground Dice: [0.8969, 0.8822]\n",
      "2022-11-27 21:07:06.454767: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:07:06.814862: lr: 0.004057\n",
      "2022-11-27 21:07:06.814972: This epoch took 15.570180 s\n",
      "\n",
      "2022-11-27 21:07:06.815001: \n",
      "epoch:  633\n",
      "2022-11-27 21:07:21.101413: train loss : -0.9260\n",
      "2022-11-27 21:07:22.107258: validation loss: -0.8427\n",
      "2022-11-27 21:07:22.107636: Average global foreground Dice: [0.8961, 0.8811]\n",
      "2022-11-27 21:07:22.107694: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:07:22.488860: lr: 0.004047\n",
      "2022-11-27 21:07:22.488966: This epoch took 15.673938 s\n",
      "\n",
      "2022-11-27 21:07:22.488997: \n",
      "epoch:  634\n",
      "2022-11-27 21:07:36.781308: train loss : -0.9275\n",
      "2022-11-27 21:07:37.773771: validation loss: -0.8415\n",
      "2022-11-27 21:07:37.774117: Average global foreground Dice: [0.8952, 0.8791]\n",
      "2022-11-27 21:07:37.774176: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:07:38.133442: lr: 0.004037\n",
      "2022-11-27 21:07:38.133550: This epoch took 15.644526 s\n",
      "\n",
      "2022-11-27 21:07:38.133576: \n",
      "epoch:  635\n",
      "2022-11-27 21:07:52.372132: train loss : -0.9261\n",
      "2022-11-27 21:07:53.388720: validation loss: -0.8385\n",
      "2022-11-27 21:07:53.389172: Average global foreground Dice: [0.8945, 0.8773]\n",
      "2022-11-27 21:07:53.389270: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:07:53.750156: lr: 0.004027\n",
      "2022-11-27 21:07:53.750267: This epoch took 15.616666 s\n",
      "\n",
      "2022-11-27 21:07:53.750297: \n",
      "epoch:  636\n",
      "2022-11-27 21:08:08.031411: train loss : -0.9268\n",
      "2022-11-27 21:08:09.031951: validation loss: -0.8398\n",
      "2022-11-27 21:08:09.032458: Average global foreground Dice: [0.894, 0.879]\n",
      "2022-11-27 21:08:09.032576: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:08:09.434963: lr: 0.004017\n",
      "2022-11-27 21:08:09.435073: This epoch took 15.684749 s\n",
      "\n",
      "2022-11-27 21:08:09.435101: \n",
      "epoch:  637\n",
      "2022-11-27 21:08:23.683458: train loss : -0.9273\n",
      "2022-11-27 21:08:24.683360: validation loss: -0.8395\n",
      "2022-11-27 21:08:24.683743: Average global foreground Dice: [0.8935, 0.8766]\n",
      "2022-11-27 21:08:24.683800: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:08:25.042220: lr: 0.004007\n",
      "2022-11-27 21:08:25.042325: This epoch took 15.607198 s\n",
      "\n",
      "2022-11-27 21:08:25.042352: \n",
      "epoch:  638\n",
      "2022-11-27 21:08:39.405903: train loss : -0.9269\n",
      "2022-11-27 21:08:40.436724: validation loss: -0.8425\n",
      "2022-11-27 21:08:40.437090: Average global foreground Dice: [0.8969, 0.8798]\n",
      "2022-11-27 21:08:40.437147: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:08:40.798038: lr: 0.003997\n",
      "2022-11-27 21:08:40.798149: This epoch took 15.755772 s\n",
      "\n",
      "2022-11-27 21:08:40.798179: \n",
      "epoch:  639\n",
      "2022-11-27 21:08:55.136831: train loss : -0.9282\n",
      "2022-11-27 21:08:56.123221: validation loss: -0.8370\n",
      "2022-11-27 21:08:56.123564: Average global foreground Dice: [0.8949, 0.877]\n",
      "2022-11-27 21:08:56.123629: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:08:56.486221: lr: 0.003987\n",
      "2022-11-27 21:08:56.486325: This epoch took 15.688119 s\n",
      "\n",
      "2022-11-27 21:08:56.486352: \n",
      "epoch:  640\n",
      "2022-11-27 21:09:10.747714: train loss : -0.9270\n",
      "2022-11-27 21:09:11.775094: validation loss: -0.8424\n",
      "2022-11-27 21:09:11.775436: Average global foreground Dice: [0.8947, 0.8821]\n",
      "2022-11-27 21:09:11.775496: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:09:12.138139: lr: 0.003977\n",
      "2022-11-27 21:09:12.138244: This epoch took 15.651865 s\n",
      "\n",
      "2022-11-27 21:09:12.138274: \n",
      "epoch:  641\n",
      "2022-11-27 21:09:26.427948: train loss : -0.9274\n",
      "2022-11-27 21:09:27.442902: validation loss: -0.8393\n",
      "2022-11-27 21:09:27.443281: Average global foreground Dice: [0.8943, 0.8784]\n",
      "2022-11-27 21:09:27.443340: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:09:27.947209: lr: 0.003967\n",
      "2022-11-27 21:09:27.947434: This epoch took 15.809133 s\n",
      "\n",
      "2022-11-27 21:09:27.947469: \n",
      "epoch:  642\n",
      "2022-11-27 21:09:42.208364: train loss : -0.9275\n",
      "2022-11-27 21:09:43.196150: validation loss: -0.8414\n",
      "2022-11-27 21:09:43.196473: Average global foreground Dice: [0.896, 0.879]\n",
      "2022-11-27 21:09:43.196528: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:09:43.566655: lr: 0.003957\n",
      "2022-11-27 21:09:43.566776: This epoch took 15.619264 s\n",
      "\n",
      "2022-11-27 21:09:43.566808: \n",
      "epoch:  643\n",
      "2022-11-27 21:09:57.875161: train loss : -0.9261\n",
      "2022-11-27 21:09:58.857973: validation loss: -0.8420\n",
      "2022-11-27 21:09:58.858427: Average global foreground Dice: [0.8978, 0.8793]\n",
      "2022-11-27 21:09:58.858597: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:09:59.251390: lr: 0.003947\n",
      "2022-11-27 21:09:59.251499: This epoch took 15.684665 s\n",
      "\n",
      "2022-11-27 21:09:59.251529: \n",
      "epoch:  644\n",
      "2022-11-27 21:10:13.503144: train loss : -0.9270\n",
      "2022-11-27 21:10:14.528257: validation loss: -0.8366\n",
      "2022-11-27 21:10:14.528623: Average global foreground Dice: [0.8925, 0.8747]\n",
      "2022-11-27 21:10:14.528705: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:10:14.892046: lr: 0.003937\n",
      "2022-11-27 21:10:14.892149: This epoch took 15.640592 s\n",
      "\n",
      "2022-11-27 21:10:14.892176: \n",
      "epoch:  645\n",
      "2022-11-27 21:10:29.161607: train loss : -0.9268\n",
      "2022-11-27 21:10:30.179302: validation loss: -0.8405\n",
      "2022-11-27 21:10:30.179691: Average global foreground Dice: [0.8941, 0.8799]\n",
      "2022-11-27 21:10:30.179770: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:10:30.546484: lr: 0.003927\n",
      "2022-11-27 21:10:30.546594: This epoch took 15.654394 s\n",
      "\n",
      "2022-11-27 21:10:30.546628: \n",
      "epoch:  646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:10:44.831144: train loss : -0.9266\n",
      "2022-11-27 21:10:45.826399: validation loss: -0.8382\n",
      "2022-11-27 21:10:45.826738: Average global foreground Dice: [0.8936, 0.8781]\n",
      "2022-11-27 21:10:45.826793: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:10:46.213395: lr: 0.003917\n",
      "2022-11-27 21:10:46.213515: This epoch took 15.666841 s\n",
      "\n",
      "2022-11-27 21:10:46.213545: \n",
      "epoch:  647\n",
      "2022-11-27 21:11:00.571235: train loss : -0.9285\n",
      "2022-11-27 21:11:01.592867: validation loss: -0.8403\n",
      "2022-11-27 21:11:01.593251: Average global foreground Dice: [0.8973, 0.8788]\n",
      "2022-11-27 21:11:01.593308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:11:01.958271: lr: 0.003907\n",
      "2022-11-27 21:11:01.958392: This epoch took 15.744805 s\n",
      "\n",
      "2022-11-27 21:11:01.958422: \n",
      "epoch:  648\n",
      "2022-11-27 21:11:16.215776: train loss : -0.9283\n",
      "2022-11-27 21:11:17.207288: validation loss: -0.8377\n",
      "2022-11-27 21:11:17.207664: Average global foreground Dice: [0.8953, 0.8751]\n",
      "2022-11-27 21:11:17.207849: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:11:17.583087: lr: 0.003897\n",
      "2022-11-27 21:11:17.583192: This epoch took 15.624743 s\n",
      "\n",
      "2022-11-27 21:11:17.583222: \n",
      "epoch:  649\n",
      "2022-11-27 21:11:31.827518: train loss : -0.9290\n",
      "2022-11-27 21:11:32.839621: validation loss: -0.8371\n",
      "2022-11-27 21:11:32.839953: Average global foreground Dice: [0.8943, 0.878]\n",
      "2022-11-27 21:11:32.840010: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:11:33.205654: lr: 0.003887\n",
      "2022-11-27 21:11:33.205757: saving scheduled checkpoint file...\n",
      "2022-11-27 21:11:33.209806: saving checkpoint...\n",
      "2022-11-27 21:11:33.277243: done, saving took 0.07 seconds\n",
      "2022-11-27 21:11:33.282537: done\n",
      "2022-11-27 21:11:33.282717: This epoch took 15.699466 s\n",
      "\n",
      "2022-11-27 21:11:33.282809: \n",
      "epoch:  650\n",
      "2022-11-27 21:11:47.590716: train loss : -0.9273\n",
      "2022-11-27 21:11:48.637127: validation loss: -0.8468\n",
      "2022-11-27 21:11:48.637459: Average global foreground Dice: [0.8987, 0.8826]\n",
      "2022-11-27 21:11:48.637513: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:11:49.107716: lr: 0.003877\n",
      "2022-11-27 21:11:49.107847: This epoch took 15.824930 s\n",
      "\n",
      "2022-11-27 21:11:49.107880: \n",
      "epoch:  651\n",
      "2022-11-27 21:12:03.360910: train loss : -0.9279\n",
      "2022-11-27 21:12:04.361249: validation loss: -0.8397\n",
      "2022-11-27 21:12:04.361630: Average global foreground Dice: [0.8957, 0.8793]\n",
      "2022-11-27 21:12:04.361801: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:12:04.726329: lr: 0.003867\n",
      "2022-11-27 21:12:04.726448: This epoch took 15.618541 s\n",
      "\n",
      "2022-11-27 21:12:04.726483: \n",
      "epoch:  652\n",
      "2022-11-27 21:12:18.950148: train loss : -0.9279\n",
      "2022-11-27 21:12:19.970660: validation loss: -0.8459\n",
      "2022-11-27 21:12:19.970995: Average global foreground Dice: [0.8994, 0.8813]\n",
      "2022-11-27 21:12:19.971280: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:12:20.335023: lr: 0.003857\n",
      "2022-11-27 21:12:20.335150: This epoch took 15.608636 s\n",
      "\n",
      "2022-11-27 21:12:20.335200: \n",
      "epoch:  653\n",
      "2022-11-27 21:12:34.552309: train loss : -0.9267\n",
      "2022-11-27 21:12:35.551780: validation loss: -0.8327\n",
      "2022-11-27 21:12:35.552192: Average global foreground Dice: [0.8905, 0.8744]\n",
      "2022-11-27 21:12:35.552262: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:12:35.942608: lr: 0.003847\n",
      "2022-11-27 21:12:35.942735: This epoch took 15.607490 s\n",
      "\n",
      "2022-11-27 21:12:35.942765: \n",
      "epoch:  654\n",
      "2022-11-27 21:12:50.221580: train loss : -0.9283\n",
      "2022-11-27 21:12:51.236070: validation loss: -0.8419\n",
      "2022-11-27 21:12:51.236444: Average global foreground Dice: [0.8955, 0.8818]\n",
      "2022-11-27 21:12:51.236516: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:12:51.611260: lr: 0.003837\n",
      "2022-11-27 21:12:51.611390: This epoch took 15.668583 s\n",
      "\n",
      "2022-11-27 21:12:51.611429: \n",
      "epoch:  655\n",
      "2022-11-27 21:13:05.910720: train loss : -0.9265\n",
      "2022-11-27 21:13:06.924986: validation loss: -0.8437\n",
      "2022-11-27 21:13:06.925319: Average global foreground Dice: [0.8964, 0.8826]\n",
      "2022-11-27 21:13:06.925374: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:13:07.306861: lr: 0.003827\n",
      "2022-11-27 21:13:07.306971: This epoch took 15.695500 s\n",
      "\n",
      "2022-11-27 21:13:07.307001: \n",
      "epoch:  656\n",
      "2022-11-27 21:13:21.575620: train loss : -0.9274\n",
      "2022-11-27 21:13:22.565749: validation loss: -0.8385\n",
      "2022-11-27 21:13:22.566096: Average global foreground Dice: [0.8948, 0.8782]\n",
      "2022-11-27 21:13:22.566154: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:13:22.926576: lr: 0.003817\n",
      "2022-11-27 21:13:22.926688: This epoch took 15.619659 s\n",
      "\n",
      "2022-11-27 21:13:22.926718: \n",
      "epoch:  657\n",
      "2022-11-27 21:13:37.203431: train loss : -0.9275\n",
      "2022-11-27 21:13:38.230219: validation loss: -0.8367\n",
      "2022-11-27 21:13:38.230558: Average global foreground Dice: [0.8934, 0.8754]\n",
      "2022-11-27 21:13:38.230621: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:13:38.591809: lr: 0.003807\n",
      "2022-11-27 21:13:38.591913: This epoch took 15.665169 s\n",
      "\n",
      "2022-11-27 21:13:38.591938: \n",
      "epoch:  658\n",
      "2022-11-27 21:13:52.866503: train loss : -0.9273\n",
      "2022-11-27 21:13:53.860650: validation loss: -0.8469\n",
      "2022-11-27 21:13:53.861062: Average global foreground Dice: [0.8997, 0.8849]\n",
      "2022-11-27 21:13:53.861146: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:13:54.245797: lr: 0.003797\n",
      "2022-11-27 21:13:54.245919: This epoch took 15.653955 s\n",
      "\n",
      "2022-11-27 21:13:54.245948: \n",
      "epoch:  659\n",
      "2022-11-27 21:14:08.499344: train loss : -0.9274\n",
      "2022-11-27 21:14:09.505339: validation loss: -0.8358\n",
      "2022-11-27 21:14:09.505715: Average global foreground Dice: [0.8928, 0.8744]\n",
      "2022-11-27 21:14:09.505771: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:14:09.874814: lr: 0.003787\n",
      "2022-11-27 21:14:09.874921: This epoch took 15.628931 s\n",
      "\n",
      "2022-11-27 21:14:09.874971: \n",
      "epoch:  660\n",
      "2022-11-27 21:14:24.159520: train loss : -0.9272\n",
      "2022-11-27 21:14:25.183600: validation loss: -0.8458\n",
      "2022-11-27 21:14:25.183996: Average global foreground Dice: [0.8999, 0.8813]\n",
      "2022-11-27 21:14:25.184055: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:14:25.551168: lr: 0.003777\n",
      "2022-11-27 21:14:25.551287: This epoch took 15.676269 s\n",
      "\n",
      "2022-11-27 21:14:25.551319: \n",
      "epoch:  661\n",
      "2022-11-27 21:14:39.833099: train loss : -0.9278\n",
      "2022-11-27 21:14:40.822422: validation loss: -0.8356\n",
      "2022-11-27 21:14:40.822804: Average global foreground Dice: [0.894, 0.874]\n",
      "2022-11-27 21:14:40.822869: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:14:41.349840: lr: 0.003767\n",
      "2022-11-27 21:14:41.349971: This epoch took 15.798626 s\n",
      "\n",
      "2022-11-27 21:14:41.350004: \n",
      "epoch:  662\n",
      "2022-11-27 21:14:55.652338: train loss : -0.9275\n",
      "2022-11-27 21:14:56.657971: validation loss: -0.8403\n",
      "2022-11-27 21:14:56.658310: Average global foreground Dice: [0.8943, 0.8791]\n",
      "2022-11-27 21:14:56.658365: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:14:57.023772: lr: 0.003757\n",
      "2022-11-27 21:14:57.023896: This epoch took 15.673850 s\n",
      "\n",
      "2022-11-27 21:14:57.023926: \n",
      "epoch:  663\n",
      "2022-11-27 21:15:11.268407: train loss : -0.9274\n",
      "2022-11-27 21:15:12.264265: validation loss: -0.8425\n",
      "2022-11-27 21:15:12.264637: Average global foreground Dice: [0.8965, 0.8809]\n",
      "2022-11-27 21:15:12.264695: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:15:12.633287: lr: 0.003747\n",
      "2022-11-27 21:15:12.633395: This epoch took 15.609441 s\n",
      "\n",
      "2022-11-27 21:15:12.633424: \n",
      "epoch:  664\n",
      "2022-11-27 21:15:26.886659: train loss : -0.9272\n",
      "2022-11-27 21:15:27.865793: validation loss: -0.8405\n",
      "2022-11-27 21:15:27.866179: Average global foreground Dice: [0.8952, 0.8768]\n",
      "2022-11-27 21:15:27.866240: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:15:28.255634: lr: 0.003737\n",
      "2022-11-27 21:15:28.255774: This epoch took 15.622274 s\n",
      "\n",
      "2022-11-27 21:15:28.255819: \n",
      "epoch:  665\n",
      "2022-11-27 21:15:42.516304: train loss : -0.9271\n",
      "2022-11-27 21:15:43.508951: validation loss: -0.8387\n",
      "2022-11-27 21:15:43.509339: Average global foreground Dice: [0.8954, 0.878]\n",
      "2022-11-27 21:15:43.509400: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:15:43.876235: lr: 0.003727\n",
      "2022-11-27 21:15:43.876342: This epoch took 15.620484 s\n",
      "\n",
      "2022-11-27 21:15:43.876369: \n",
      "epoch:  666\n",
      "2022-11-27 21:15:58.182538: train loss : -0.9292\n",
      "2022-11-27 21:15:59.244443: validation loss: -0.8422\n",
      "2022-11-27 21:15:59.244822: Average global foreground Dice: [0.8971, 0.8806]\n",
      "2022-11-27 21:15:59.244889: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:15:59.610200: lr: 0.003717\n",
      "2022-11-27 21:15:59.610302: This epoch took 15.733909 s\n",
      "\n",
      "2022-11-27 21:15:59.610330: \n",
      "epoch:  667\n",
      "2022-11-27 21:16:13.873273: train loss : -0.9278\n",
      "2022-11-27 21:16:14.882556: validation loss: -0.8371\n",
      "2022-11-27 21:16:14.882939: Average global foreground Dice: [0.8955, 0.8777]\n",
      "2022-11-27 21:16:14.883003: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:16:15.250069: lr: 0.003707\n",
      "2022-11-27 21:16:15.250180: This epoch took 15.639824 s\n",
      "\n",
      "2022-11-27 21:16:15.250213: \n",
      "epoch:  668\n",
      "2022-11-27 21:16:29.568348: train loss : -0.9279\n",
      "2022-11-27 21:16:30.557040: validation loss: -0.8392\n",
      "2022-11-27 21:16:30.557372: Average global foreground Dice: [0.8957, 0.8778]\n",
      "2022-11-27 21:16:30.557430: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:16:30.956423: lr: 0.003697\n",
      "2022-11-27 21:16:30.956553: This epoch took 15.706295 s\n",
      "\n",
      "2022-11-27 21:16:30.956583: \n",
      "epoch:  669\n",
      "2022-11-27 21:16:45.151670: train loss : -0.9302\n",
      "2022-11-27 21:16:46.160357: validation loss: -0.8406\n",
      "2022-11-27 21:16:46.160690: Average global foreground Dice: [0.8961, 0.8796]\n",
      "2022-11-27 21:16:46.160744: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:16:46.526403: lr: 0.003687\n",
      "2022-11-27 21:16:46.526508: This epoch took 15.569899 s\n",
      "\n",
      "2022-11-27 21:16:46.526536: \n",
      "epoch:  670\n",
      "2022-11-27 21:17:00.817720: train loss : -0.9266\n",
      "2022-11-27 21:17:01.827489: validation loss: -0.8454\n",
      "2022-11-27 21:17:01.827877: Average global foreground Dice: [0.898, 0.8831]\n",
      "2022-11-27 21:17:01.827933: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:17:02.193924: lr: 0.003677\n",
      "2022-11-27 21:17:02.194030: This epoch took 15.667467 s\n",
      "\n",
      "2022-11-27 21:17:02.194057: \n",
      "epoch:  671\n",
      "2022-11-27 21:17:16.438377: train loss : -0.9289\n",
      "2022-11-27 21:17:17.466274: validation loss: -0.8392\n",
      "2022-11-27 21:17:17.466604: Average global foreground Dice: [0.8969, 0.8775]\n",
      "2022-11-27 21:17:17.466660: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:17:17.962689: lr: 0.003667\n",
      "2022-11-27 21:17:17.962804: This epoch took 15.768719 s\n",
      "\n",
      "2022-11-27 21:17:17.962833: \n",
      "epoch:  672\n",
      "2022-11-27 21:17:32.273474: train loss : -0.9291\n",
      "2022-11-27 21:17:33.289438: validation loss: -0.8451\n",
      "2022-11-27 21:17:33.289858: Average global foreground Dice: [0.8984, 0.8809]\n",
      "2022-11-27 21:17:33.289948: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:17:33.657249: lr: 0.003657\n",
      "2022-11-27 21:17:33.661332: saving checkpoint...\n",
      "2022-11-27 21:17:33.730745: done, saving took 0.07 seconds\n",
      "2022-11-27 21:17:33.732692: This epoch took 15.769832 s\n",
      "\n",
      "2022-11-27 21:17:33.732752: \n",
      "epoch:  673\n",
      "2022-11-27 21:17:47.994843: train loss : -0.9294\n",
      "2022-11-27 21:17:49.011002: validation loss: -0.8366\n",
      "2022-11-27 21:17:49.011383: Average global foreground Dice: [0.893, 0.877]\n",
      "2022-11-27 21:17:49.011464: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:17:49.378901: lr: 0.003647\n",
      "2022-11-27 21:17:49.379012: This epoch took 15.646230 s\n",
      "\n",
      "2022-11-27 21:17:49.379041: \n",
      "epoch:  674\n",
      "2022-11-27 21:18:03.679537: train loss : -0.9292\n",
      "2022-11-27 21:18:04.666974: validation loss: -0.8380\n",
      "2022-11-27 21:18:04.667360: Average global foreground Dice: [0.895, 0.8767]\n",
      "2022-11-27 21:18:04.667420: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:18:05.039858: lr: 0.003637\n",
      "2022-11-27 21:18:05.039968: This epoch took 15.660900 s\n",
      "\n",
      "2022-11-27 21:18:05.039998: \n",
      "epoch:  675\n",
      "2022-11-27 21:18:19.264889: train loss : -0.9277\n",
      "2022-11-27 21:18:20.252539: validation loss: -0.8310\n",
      "2022-11-27 21:18:20.252873: Average global foreground Dice: [0.8897, 0.8711]\n",
      "2022-11-27 21:18:20.252927: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:18:20.641342: lr: 0.003627\n",
      "2022-11-27 21:18:20.641452: This epoch took 15.601428 s\n",
      "\n",
      "2022-11-27 21:18:20.641480: \n",
      "epoch:  676\n",
      "2022-11-27 21:18:34.879173: train loss : -0.9265\n",
      "2022-11-27 21:18:35.884081: validation loss: -0.8352\n",
      "2022-11-27 21:18:35.884440: Average global foreground Dice: [0.8909, 0.8775]\n",
      "2022-11-27 21:18:35.884523: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:18:36.251275: lr: 0.003616\n",
      "2022-11-27 21:18:36.251381: This epoch took 15.609875 s\n",
      "\n",
      "2022-11-27 21:18:36.251410: \n",
      "epoch:  677\n",
      "2022-11-27 21:18:50.565490: train loss : -0.9278\n",
      "2022-11-27 21:18:51.574892: validation loss: -0.8377\n",
      "2022-11-27 21:18:51.575282: Average global foreground Dice: [0.893, 0.8767]\n",
      "2022-11-27 21:18:51.575338: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:18:51.946211: lr: 0.003606\n",
      "2022-11-27 21:18:51.946437: This epoch took 15.694993 s\n",
      "\n",
      "2022-11-27 21:18:51.946472: \n",
      "epoch:  678\n",
      "2022-11-27 21:19:06.199754: train loss : -0.9287\n",
      "2022-11-27 21:19:07.198241: validation loss: -0.8391\n",
      "2022-11-27 21:19:07.198611: Average global foreground Dice: [0.8949, 0.8805]\n",
      "2022-11-27 21:19:07.198671: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:19:07.568406: lr: 0.003596\n",
      "2022-11-27 21:19:07.568511: This epoch took 15.622011 s\n",
      "\n",
      "2022-11-27 21:19:07.568539: \n",
      "epoch:  679\n",
      "2022-11-27 21:19:21.838485: train loss : -0.9270\n",
      "2022-11-27 21:19:22.859366: validation loss: -0.8357\n",
      "2022-11-27 21:19:22.859723: Average global foreground Dice: [0.8932, 0.876]\n",
      "2022-11-27 21:19:22.859815: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:19:23.251766: lr: 0.003586\n",
      "2022-11-27 21:19:23.251872: This epoch took 15.683306 s\n",
      "\n",
      "2022-11-27 21:19:23.251900: \n",
      "epoch:  680\n",
      "2022-11-27 21:19:37.494890: train loss : -0.9281\n",
      "2022-11-27 21:19:38.481592: validation loss: -0.8374\n",
      "2022-11-27 21:19:38.481940: Average global foreground Dice: [0.8957, 0.877]\n",
      "2022-11-27 21:19:38.482000: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:19:38.859797: lr: 0.003576\n",
      "2022-11-27 21:19:38.859897: This epoch took 15.607972 s\n",
      "\n",
      "2022-11-27 21:19:38.859923: \n",
      "epoch:  681\n",
      "2022-11-27 21:19:53.107113: train loss : -0.9290\n",
      "2022-11-27 21:19:54.091678: validation loss: -0.8411\n",
      "2022-11-27 21:19:54.092035: Average global foreground Dice: [0.8991, 0.8806]\n",
      "2022-11-27 21:19:54.092088: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:19:54.592791: lr: 0.003566\n",
      "2022-11-27 21:19:54.592906: This epoch took 15.732958 s\n",
      "\n",
      "2022-11-27 21:19:54.592935: \n",
      "epoch:  682\n",
      "2022-11-27 21:20:08.828939: train loss : -0.9286\n",
      "2022-11-27 21:20:09.833005: validation loss: -0.8385\n",
      "2022-11-27 21:20:09.833367: Average global foreground Dice: [0.897, 0.8774]\n",
      "2022-11-27 21:20:09.833462: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:20:10.210710: lr: 0.003556\n",
      "2022-11-27 21:20:10.210825: This epoch took 15.617863 s\n",
      "\n",
      "2022-11-27 21:20:10.210854: \n",
      "epoch:  683\n",
      "2022-11-27 21:20:24.500117: train loss : -0.9290\n",
      "2022-11-27 21:20:25.495713: validation loss: -0.8372\n",
      "2022-11-27 21:20:25.496096: Average global foreground Dice: [0.8944, 0.8771]\n",
      "2022-11-27 21:20:25.496155: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:20:25.866898: lr: 0.003546\n",
      "2022-11-27 21:20:25.867000: This epoch took 15.656120 s\n",
      "\n",
      "2022-11-27 21:20:25.867026: \n",
      "epoch:  684\n",
      "2022-11-27 21:20:40.134835: train loss : -0.9272\n",
      "2022-11-27 21:20:41.143629: validation loss: -0.8337\n",
      "2022-11-27 21:20:41.144018: Average global foreground Dice: [0.8929, 0.8729]\n",
      "2022-11-27 21:20:41.144081: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:20:41.532999: lr: 0.003536\n",
      "2022-11-27 21:20:41.533119: This epoch took 15.666067 s\n",
      "\n",
      "2022-11-27 21:20:41.533166: \n",
      "epoch:  685\n",
      "2022-11-27 21:20:55.852181: train loss : -0.9295\n",
      "2022-11-27 21:20:56.842177: validation loss: -0.8383\n",
      "2022-11-27 21:20:56.842743: Average global foreground Dice: [0.8941, 0.8759]\n",
      "2022-11-27 21:20:56.843063: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:20:57.214152: lr: 0.003526\n",
      "2022-11-27 21:20:57.214260: This epoch took 15.681064 s\n",
      "\n",
      "2022-11-27 21:20:57.214288: \n",
      "epoch:  686\n",
      "2022-11-27 21:21:11.468843: train loss : -0.9297\n",
      "2022-11-27 21:21:12.463065: validation loss: -0.8331\n",
      "2022-11-27 21:21:12.463431: Average global foreground Dice: [0.8927, 0.8731]\n",
      "2022-11-27 21:21:12.463515: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:21:12.857905: lr: 0.003516\n",
      "2022-11-27 21:21:12.858029: This epoch took 15.643714 s\n",
      "\n",
      "2022-11-27 21:21:12.858057: \n",
      "epoch:  687\n",
      "2022-11-27 21:21:27.168851: train loss : -0.9290\n",
      "2022-11-27 21:21:28.194553: validation loss: -0.8361\n",
      "2022-11-27 21:21:28.194937: Average global foreground Dice: [0.8942, 0.876]\n",
      "2022-11-27 21:21:28.194994: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:21:28.563132: lr: 0.003505\n",
      "2022-11-27 21:21:28.563237: This epoch took 15.705155 s\n",
      "\n",
      "2022-11-27 21:21:28.563282: \n",
      "epoch:  688\n",
      "2022-11-27 21:21:42.794912: train loss : -0.9278\n",
      "2022-11-27 21:21:43.802958: validation loss: -0.8357\n",
      "2022-11-27 21:21:43.803364: Average global foreground Dice: [0.8945, 0.8759]\n",
      "2022-11-27 21:21:43.803423: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:21:44.173837: lr: 0.003495\n",
      "2022-11-27 21:21:44.173965: This epoch took 15.610656 s\n",
      "\n",
      "2022-11-27 21:21:44.173996: \n",
      "epoch:  689\n",
      "2022-11-27 21:21:58.427558: train loss : -0.9285\n",
      "2022-11-27 21:21:59.438388: validation loss: -0.8399\n",
      "2022-11-27 21:21:59.438770: Average global foreground Dice: [0.8964, 0.8803]\n",
      "2022-11-27 21:21:59.438828: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:21:59.810861: lr: 0.003485\n",
      "2022-11-27 21:21:59.810963: This epoch took 15.636941 s\n",
      "\n",
      "2022-11-27 21:21:59.810992: \n",
      "epoch:  690\n",
      "2022-11-27 21:22:14.093061: train loss : -0.9289\n",
      "2022-11-27 21:22:15.154989: validation loss: -0.8395\n",
      "2022-11-27 21:22:15.155376: Average global foreground Dice: [0.8941, 0.88]\n",
      "2022-11-27 21:22:15.155432: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:22:15.527327: lr: 0.003475\n",
      "2022-11-27 21:22:15.527438: This epoch took 15.716413 s\n",
      "\n",
      "2022-11-27 21:22:15.527467: \n",
      "epoch:  691\n",
      "2022-11-27 21:22:29.790655: train loss : -0.9297\n",
      "2022-11-27 21:22:30.787991: validation loss: -0.8428\n",
      "2022-11-27 21:22:30.788388: Average global foreground Dice: [0.8974, 0.8812]\n",
      "2022-11-27 21:22:30.788664: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:22:31.296412: lr: 0.003465\n",
      "2022-11-27 21:22:31.296540: This epoch took 15.769030 s\n",
      "\n",
      "2022-11-27 21:22:31.296570: \n",
      "epoch:  692\n",
      "2022-11-27 21:22:45.626019: train loss : -0.9286\n",
      "2022-11-27 21:22:46.626333: validation loss: -0.8442\n",
      "2022-11-27 21:22:46.626745: Average global foreground Dice: [0.8982, 0.8826]\n",
      "2022-11-27 21:22:46.626806: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:22:46.995158: lr: 0.003455\n",
      "2022-11-27 21:22:46.995274: This epoch took 15.698678 s\n",
      "\n",
      "2022-11-27 21:22:46.995311: \n",
      "epoch:  693\n",
      "2022-11-27 21:23:01.251681: train loss : -0.9285\n",
      "2022-11-27 21:23:02.285535: validation loss: -0.8384\n",
      "2022-11-27 21:23:02.286076: Average global foreground Dice: [0.8948, 0.8789]\n",
      "2022-11-27 21:23:02.286194: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:23:02.659575: lr: 0.003445\n",
      "2022-11-27 21:23:02.659687: This epoch took 15.664348 s\n",
      "\n",
      "2022-11-27 21:23:02.659714: \n",
      "epoch:  694\n",
      "2022-11-27 21:23:16.934926: train loss : -0.9294\n",
      "2022-11-27 21:23:17.935124: validation loss: -0.8436\n",
      "2022-11-27 21:23:17.935463: Average global foreground Dice: [0.8979, 0.8807]\n",
      "2022-11-27 21:23:17.935520: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:23:18.300992: lr: 0.003435\n",
      "2022-11-27 21:23:18.301129: This epoch took 15.641375 s\n",
      "\n",
      "2022-11-27 21:23:18.301162: \n",
      "epoch:  695\n",
      "2022-11-27 21:23:32.578841: train loss : -0.9294\n",
      "2022-11-27 21:23:33.594299: validation loss: -0.8381\n",
      "2022-11-27 21:23:33.594689: Average global foreground Dice: [0.8935, 0.8768]\n",
      "2022-11-27 21:23:33.594748: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:23:33.980000: lr: 0.003424\n",
      "2022-11-27 21:23:33.980114: This epoch took 15.678926 s\n",
      "\n",
      "2022-11-27 21:23:33.980143: \n",
      "epoch:  696\n",
      "2022-11-27 21:23:48.267665: train loss : -0.9283\n",
      "2022-11-27 21:23:49.281188: validation loss: -0.8423\n",
      "2022-11-27 21:23:49.281567: Average global foreground Dice: [0.8961, 0.8813]\n",
      "2022-11-27 21:23:49.281628: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:23:49.649460: lr: 0.003414\n",
      "2022-11-27 21:23:49.649565: This epoch took 15.669395 s\n",
      "\n",
      "2022-11-27 21:23:49.649591: \n",
      "epoch:  697\n",
      "2022-11-27 21:24:03.899094: train loss : -0.9293\n",
      "2022-11-27 21:24:04.930400: validation loss: -0.8393\n",
      "2022-11-27 21:24:04.930781: Average global foreground Dice: [0.8958, 0.8784]\n",
      "2022-11-27 21:24:04.930842: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:24:05.302646: lr: 0.003404\n",
      "2022-11-27 21:24:05.302754: This epoch took 15.653139 s\n",
      "\n",
      "2022-11-27 21:24:05.302785: \n",
      "epoch:  698\n",
      "2022-11-27 21:24:19.538306: train loss : -0.9283\n",
      "2022-11-27 21:24:20.534845: validation loss: -0.8459\n",
      "2022-11-27 21:24:20.535180: Average global foreground Dice: [0.8986, 0.8817]\n",
      "2022-11-27 21:24:20.535239: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:24:20.903753: lr: 0.003394\n",
      "2022-11-27 21:24:20.903969: This epoch took 15.601157 s\n",
      "\n",
      "2022-11-27 21:24:20.904001: \n",
      "epoch:  699\n",
      "2022-11-27 21:24:35.156439: train loss : -0.9305\n",
      "2022-11-27 21:24:36.140936: validation loss: -0.8391\n",
      "2022-11-27 21:24:36.141421: Average global foreground Dice: [0.8967, 0.8783]\n",
      "2022-11-27 21:24:36.141504: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:24:36.519010: lr: 0.003384\n",
      "2022-11-27 21:24:36.519101: saving scheduled checkpoint file...\n",
      "2022-11-27 21:24:36.523026: saving checkpoint...\n",
      "2022-11-27 21:24:36.590087: done, saving took 0.07 seconds\n",
      "2022-11-27 21:24:36.591931: done\n",
      "2022-11-27 21:24:36.592003: This epoch took 15.687976 s\n",
      "\n",
      "2022-11-27 21:24:36.592032: \n",
      "epoch:  700\n",
      "2022-11-27 21:24:50.860755: train loss : -0.9282\n",
      "2022-11-27 21:24:51.895606: validation loss: -0.8389\n",
      "2022-11-27 21:24:51.896071: Average global foreground Dice: [0.8944, 0.8775]\n",
      "2022-11-27 21:24:51.896277: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:24:52.274642: lr: 0.003374\n",
      "2022-11-27 21:24:52.274760: This epoch took 15.682683 s\n",
      "\n",
      "2022-11-27 21:24:52.274790: \n",
      "epoch:  701\n",
      "2022-11-27 21:25:06.517570: train loss : -0.9297\n",
      "2022-11-27 21:25:07.526827: validation loss: -0.8418\n",
      "2022-11-27 21:25:07.527206: Average global foreground Dice: [0.8939, 0.8814]\n",
      "2022-11-27 21:25:07.527266: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:25:08.029423: lr: 0.003364\n",
      "2022-11-27 21:25:08.029641: This epoch took 15.754809 s\n",
      "\n",
      "2022-11-27 21:25:08.029674: \n",
      "epoch:  702\n",
      "2022-11-27 21:25:22.320850: train loss : -0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:25:23.350009: validation loss: -0.8350\n",
      "2022-11-27 21:25:23.350517: Average global foreground Dice: [0.8925, 0.8747]\n",
      "2022-11-27 21:25:23.350646: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:25:23.724181: lr: 0.003353\n",
      "2022-11-27 21:25:23.724307: This epoch took 15.694606 s\n",
      "\n",
      "2022-11-27 21:25:23.724341: \n",
      "epoch:  703\n",
      "2022-11-27 21:25:37.984217: train loss : -0.9290\n",
      "2022-11-27 21:25:38.993706: validation loss: -0.8423\n",
      "2022-11-27 21:25:38.994112: Average global foreground Dice: [0.8987, 0.881]\n",
      "2022-11-27 21:25:38.994185: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:25:39.368252: lr: 0.003343\n",
      "2022-11-27 21:25:39.368372: This epoch took 15.643989 s\n",
      "\n",
      "2022-11-27 21:25:39.368402: \n",
      "epoch:  704\n",
      "2022-11-27 21:25:53.721302: train loss : -0.9297\n",
      "2022-11-27 21:25:54.739661: validation loss: -0.8412\n",
      "2022-11-27 21:25:54.740004: Average global foreground Dice: [0.8961, 0.8794]\n",
      "2022-11-27 21:25:54.740061: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:25:55.110558: lr: 0.003333\n",
      "2022-11-27 21:25:55.110671: This epoch took 15.742242 s\n",
      "\n",
      "2022-11-27 21:25:55.110699: \n",
      "epoch:  705\n",
      "2022-11-27 21:26:09.380455: train loss : -0.9284\n",
      "2022-11-27 21:26:10.370857: validation loss: -0.8323\n",
      "2022-11-27 21:26:10.371244: Average global foreground Dice: [0.8916, 0.8722]\n",
      "2022-11-27 21:26:10.371328: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:26:10.760364: lr: 0.003323\n",
      "2022-11-27 21:26:10.760479: This epoch took 15.649753 s\n",
      "\n",
      "2022-11-27 21:26:10.760509: \n",
      "epoch:  706\n",
      "2022-11-27 21:26:25.010394: train loss : -0.9292\n",
      "2022-11-27 21:26:26.007026: validation loss: -0.8374\n",
      "2022-11-27 21:26:26.007413: Average global foreground Dice: [0.8939, 0.8769]\n",
      "2022-11-27 21:26:26.007472: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:26:26.384872: lr: 0.003313\n",
      "2022-11-27 21:26:26.384977: This epoch took 15.624441 s\n",
      "\n",
      "2022-11-27 21:26:26.385005: \n",
      "epoch:  707\n",
      "2022-11-27 21:26:40.652615: train loss : -0.9284\n",
      "2022-11-27 21:26:41.645258: validation loss: -0.8385\n",
      "2022-11-27 21:26:41.645640: Average global foreground Dice: [0.8949, 0.8788]\n",
      "2022-11-27 21:26:41.645700: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:26:42.021911: lr: 0.003303\n",
      "2022-11-27 21:26:42.022128: This epoch took 15.637096 s\n",
      "\n",
      "2022-11-27 21:26:42.022160: \n",
      "epoch:  708\n",
      "2022-11-27 21:26:56.318836: train loss : -0.9289\n",
      "2022-11-27 21:26:57.313398: validation loss: -0.8370\n",
      "2022-11-27 21:26:57.313782: Average global foreground Dice: [0.8932, 0.8774]\n",
      "2022-11-27 21:26:57.313838: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:26:57.683537: lr: 0.003292\n",
      "2022-11-27 21:26:57.683767: This epoch took 15.661579 s\n",
      "\n",
      "2022-11-27 21:26:57.683814: \n",
      "epoch:  709\n",
      "2022-11-27 21:27:11.932115: train loss : -0.9295\n",
      "2022-11-27 21:27:12.926748: validation loss: -0.8398\n",
      "2022-11-27 21:27:12.927130: Average global foreground Dice: [0.8955, 0.8777]\n",
      "2022-11-27 21:27:12.927187: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:27:13.297259: lr: 0.003282\n",
      "2022-11-27 21:27:13.297362: This epoch took 15.613522 s\n",
      "\n",
      "2022-11-27 21:27:13.297391: \n",
      "epoch:  710\n",
      "2022-11-27 21:27:27.608911: train loss : -0.9278\n",
      "2022-11-27 21:27:28.595514: validation loss: -0.8372\n",
      "2022-11-27 21:27:28.595899: Average global foreground Dice: [0.8946, 0.877]\n",
      "2022-11-27 21:27:28.595981: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:27:28.968326: lr: 0.003272\n",
      "2022-11-27 21:27:28.968434: This epoch took 15.671016 s\n",
      "\n",
      "2022-11-27 21:27:28.968463: \n",
      "epoch:  711\n",
      "2022-11-27 21:27:43.197308: train loss : -0.9292\n",
      "2022-11-27 21:27:44.223290: validation loss: -0.8406\n",
      "2022-11-27 21:27:44.223632: Average global foreground Dice: [0.897, 0.8795]\n",
      "2022-11-27 21:27:44.223688: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:27:44.730386: lr: 0.003262\n",
      "2022-11-27 21:27:44.730504: This epoch took 15.762014 s\n",
      "\n",
      "2022-11-27 21:27:44.730530: \n",
      "epoch:  712\n",
      "2022-11-27 21:27:59.170774: train loss : -0.9285\n",
      "2022-11-27 21:28:00.178611: validation loss: -0.8424\n",
      "2022-11-27 21:28:00.178939: Average global foreground Dice: [0.8973, 0.8809]\n",
      "2022-11-27 21:28:00.178993: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:28:00.545504: lr: 0.003252\n",
      "2022-11-27 21:28:00.545612: This epoch took 15.815057 s\n",
      "\n",
      "2022-11-27 21:28:00.545640: \n",
      "epoch:  713\n",
      "2022-11-27 21:28:14.829855: train loss : -0.9295\n",
      "2022-11-27 21:28:15.834581: validation loss: -0.8394\n",
      "2022-11-27 21:28:15.834954: Average global foreground Dice: [0.8948, 0.8778]\n",
      "2022-11-27 21:28:15.835014: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:28:16.205840: lr: 0.003241\n",
      "2022-11-27 21:28:16.205964: This epoch took 15.660296 s\n",
      "\n",
      "2022-11-27 21:28:16.205996: \n",
      "epoch:  714\n",
      "2022-11-27 21:28:30.505755: train loss : -0.9313\n",
      "2022-11-27 21:28:31.515944: validation loss: -0.8368\n",
      "2022-11-27 21:28:31.516303: Average global foreground Dice: [0.8926, 0.8776]\n",
      "2022-11-27 21:28:31.516395: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:28:31.885704: lr: 0.003231\n",
      "2022-11-27 21:28:31.885813: This epoch took 15.679790 s\n",
      "\n",
      "2022-11-27 21:28:31.885842: \n",
      "epoch:  715\n",
      "2022-11-27 21:28:46.178411: train loss : -0.9294\n",
      "2022-11-27 21:28:47.180499: validation loss: -0.8367\n",
      "2022-11-27 21:28:47.180869: Average global foreground Dice: [0.8934, 0.8771]\n",
      "2022-11-27 21:28:47.180928: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:28:47.551602: lr: 0.003221\n",
      "2022-11-27 21:28:47.551723: This epoch took 15.665838 s\n",
      "\n",
      "2022-11-27 21:28:47.551752: \n",
      "epoch:  716\n",
      "2022-11-27 21:29:01.872559: train loss : -0.9282\n",
      "2022-11-27 21:29:02.884612: validation loss: -0.8418\n",
      "2022-11-27 21:29:02.885085: Average global foreground Dice: [0.8969, 0.8808]\n",
      "2022-11-27 21:29:02.885171: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:29:03.257933: lr: 0.003211\n",
      "2022-11-27 21:29:03.258056: This epoch took 15.706277 s\n",
      "\n",
      "2022-11-27 21:29:03.258085: \n",
      "epoch:  717\n",
      "2022-11-27 21:29:17.569795: train loss : -0.9309\n",
      "2022-11-27 21:29:18.564265: validation loss: -0.8376\n",
      "2022-11-27 21:29:18.564657: Average global foreground Dice: [0.8937, 0.8772]\n",
      "2022-11-27 21:29:18.564717: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:29:18.957253: lr: 0.003201\n",
      "2022-11-27 21:29:18.957373: This epoch took 15.699246 s\n",
      "\n",
      "2022-11-27 21:29:18.957405: \n",
      "epoch:  718\n",
      "2022-11-27 21:29:33.207950: train loss : -0.9289\n",
      "2022-11-27 21:29:34.204494: validation loss: -0.8395\n",
      "2022-11-27 21:29:34.204886: Average global foreground Dice: [0.8948, 0.8783]\n",
      "2022-11-27 21:29:34.204961: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:29:34.583553: lr: 0.00319\n",
      "2022-11-27 21:29:34.583672: This epoch took 15.626225 s\n",
      "\n",
      "2022-11-27 21:29:34.583702: \n",
      "epoch:  719\n",
      "2022-11-27 21:29:48.830123: train loss : -0.9284\n",
      "2022-11-27 21:29:49.836766: validation loss: -0.8373\n",
      "2022-11-27 21:29:49.837104: Average global foreground Dice: [0.8935, 0.8773]\n",
      "2022-11-27 21:29:49.837159: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:29:50.207139: lr: 0.00318\n",
      "2022-11-27 21:29:50.207356: This epoch took 15.623629 s\n",
      "\n",
      "2022-11-27 21:29:50.207388: \n",
      "epoch:  720\n",
      "2022-11-27 21:30:04.478850: train loss : -0.9294\n",
      "2022-11-27 21:30:05.465486: validation loss: -0.8411\n",
      "2022-11-27 21:30:05.465912: Average global foreground Dice: [0.8952, 0.8804]\n",
      "2022-11-27 21:30:05.465993: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:30:05.836805: lr: 0.00317\n",
      "2022-11-27 21:30:05.836908: This epoch took 15.629493 s\n",
      "\n",
      "2022-11-27 21:30:05.837024: \n",
      "epoch:  721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:30:20.116493: train loss : -0.9308\n",
      "2022-11-27 21:30:21.117632: validation loss: -0.8357\n",
      "2022-11-27 21:30:21.118029: Average global foreground Dice: [0.8916, 0.8758]\n",
      "2022-11-27 21:30:21.118101: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:30:21.617632: lr: 0.00316\n",
      "2022-11-27 21:30:21.617741: This epoch took 15.780686 s\n",
      "\n",
      "2022-11-27 21:30:21.617772: \n",
      "epoch:  722\n",
      "2022-11-27 21:30:35.864346: train loss : -0.9302\n",
      "2022-11-27 21:30:36.886514: validation loss: -0.8456\n",
      "2022-11-27 21:30:36.886892: Average global foreground Dice: [0.8986, 0.8824]\n",
      "2022-11-27 21:30:36.886955: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:30:37.257966: lr: 0.003149\n",
      "2022-11-27 21:30:37.258075: This epoch took 15.640277 s\n",
      "\n",
      "2022-11-27 21:30:37.258107: \n",
      "epoch:  723\n",
      "2022-11-27 21:30:51.587691: train loss : -0.9295\n",
      "2022-11-27 21:30:52.579082: validation loss: -0.8358\n",
      "2022-11-27 21:30:52.579460: Average global foreground Dice: [0.892, 0.8756]\n",
      "2022-11-27 21:30:52.579545: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:30:52.952703: lr: 0.003139\n",
      "2022-11-27 21:30:52.952811: This epoch took 15.694679 s\n",
      "\n",
      "2022-11-27 21:30:52.952838: \n",
      "epoch:  724\n",
      "2022-11-27 21:31:07.227470: train loss : -0.9285\n",
      "2022-11-27 21:31:08.237756: validation loss: -0.8343\n",
      "2022-11-27 21:31:08.238102: Average global foreground Dice: [0.8947, 0.875]\n",
      "2022-11-27 21:31:08.238159: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:31:08.605668: lr: 0.003129\n",
      "2022-11-27 21:31:08.605774: This epoch took 15.652911 s\n",
      "\n",
      "2022-11-27 21:31:08.605801: \n",
      "epoch:  725\n",
      "2022-11-27 21:31:22.846209: train loss : -0.9310\n",
      "2022-11-27 21:31:23.855089: validation loss: -0.8448\n",
      "2022-11-27 21:31:23.855417: Average global foreground Dice: [0.8986, 0.8827]\n",
      "2022-11-27 21:31:23.855475: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:31:24.246434: lr: 0.003119\n",
      "2022-11-27 21:31:24.246543: This epoch took 15.640717 s\n",
      "\n",
      "2022-11-27 21:31:24.246572: \n",
      "epoch:  726\n",
      "2022-11-27 21:31:38.507973: train loss : -0.9299\n",
      "2022-11-27 21:31:39.523073: validation loss: -0.8367\n",
      "2022-11-27 21:31:39.523407: Average global foreground Dice: [0.8943, 0.8771]\n",
      "2022-11-27 21:31:39.523466: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:31:39.902475: lr: 0.003108\n",
      "2022-11-27 21:31:39.902582: This epoch took 15.655984 s\n",
      "\n",
      "2022-11-27 21:31:39.902610: \n",
      "epoch:  727\n",
      "2022-11-27 21:31:54.178807: train loss : -0.9300\n",
      "2022-11-27 21:31:55.175728: validation loss: -0.8345\n",
      "2022-11-27 21:31:55.176115: Average global foreground Dice: [0.8933, 0.8746]\n",
      "2022-11-27 21:31:55.176172: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:31:55.545119: lr: 0.003098\n",
      "2022-11-27 21:31:55.545223: This epoch took 15.642587 s\n",
      "\n",
      "2022-11-27 21:31:55.545249: \n",
      "epoch:  728\n",
      "2022-11-27 21:32:09.785652: train loss : -0.9291\n",
      "2022-11-27 21:32:10.796831: validation loss: -0.8327\n",
      "2022-11-27 21:32:10.797200: Average global foreground Dice: [0.8918, 0.8728]\n",
      "2022-11-27 21:32:10.797258: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:32:11.180307: lr: 0.003088\n",
      "2022-11-27 21:32:11.180428: This epoch took 15.635137 s\n",
      "\n",
      "2022-11-27 21:32:11.180459: \n",
      "epoch:  729\n",
      "2022-11-27 21:32:25.486869: train loss : -0.9302\n",
      "2022-11-27 21:32:26.519607: validation loss: -0.8356\n",
      "2022-11-27 21:32:26.519955: Average global foreground Dice: [0.8938, 0.8772]\n",
      "2022-11-27 21:32:26.520015: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:32:26.930166: lr: 0.003078\n",
      "2022-11-27 21:32:26.930274: This epoch took 15.749787 s\n",
      "\n",
      "2022-11-27 21:32:26.930302: \n",
      "epoch:  730\n",
      "2022-11-27 21:32:41.182204: train loss : -0.9300\n",
      "2022-11-27 21:32:42.194314: validation loss: -0.8359\n",
      "2022-11-27 21:32:42.194706: Average global foreground Dice: [0.8924, 0.8777]\n",
      "2022-11-27 21:32:42.194768: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:32:42.577611: lr: 0.003067\n",
      "2022-11-27 21:32:42.577730: This epoch took 15.647386 s\n",
      "\n",
      "2022-11-27 21:32:42.577759: \n",
      "epoch:  731\n",
      "2022-11-27 21:32:56.882946: train loss : -0.9303\n",
      "2022-11-27 21:32:57.915339: validation loss: -0.8403\n",
      "2022-11-27 21:32:57.915677: Average global foreground Dice: [0.896, 0.88]\n",
      "2022-11-27 21:32:57.915734: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:32:58.424496: lr: 0.003057\n",
      "2022-11-27 21:32:58.424626: This epoch took 15.846825 s\n",
      "\n",
      "2022-11-27 21:32:58.424663: \n",
      "epoch:  732\n",
      "2022-11-27 21:33:12.702089: train loss : -0.9302\n",
      "2022-11-27 21:33:13.690472: validation loss: -0.8395\n",
      "2022-11-27 21:33:13.690830: Average global foreground Dice: [0.897, 0.8814]\n",
      "2022-11-27 21:33:13.690890: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:33:14.056798: lr: 0.003047\n",
      "2022-11-27 21:33:14.056906: This epoch took 15.632212 s\n",
      "\n",
      "2022-11-27 21:33:14.056936: \n",
      "epoch:  733\n",
      "2022-11-27 21:33:28.362516: train loss : -0.9303\n",
      "2022-11-27 21:33:29.399751: validation loss: -0.8413\n",
      "2022-11-27 21:33:29.400123: Average global foreground Dice: [0.895, 0.8807]\n",
      "2022-11-27 21:33:29.400182: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:33:29.762193: lr: 0.003037\n",
      "2022-11-27 21:33:29.762304: This epoch took 15.705342 s\n",
      "\n",
      "2022-11-27 21:33:29.762333: \n",
      "epoch:  734\n",
      "2022-11-27 21:33:44.027727: train loss : -0.9298\n",
      "2022-11-27 21:33:45.048659: validation loss: -0.8359\n",
      "2022-11-27 21:33:45.049140: Average global foreground Dice: [0.8939, 0.8756]\n",
      "2022-11-27 21:33:45.049230: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:33:45.411140: lr: 0.003026\n",
      "2022-11-27 21:33:45.411250: This epoch took 15.648890 s\n",
      "\n",
      "2022-11-27 21:33:45.411281: \n",
      "epoch:  735\n",
      "2022-11-27 21:33:59.716434: train loss : -0.9297\n",
      "2022-11-27 21:34:00.702996: validation loss: -0.8390\n",
      "2022-11-27 21:34:00.703344: Average global foreground Dice: [0.8957, 0.877]\n",
      "2022-11-27 21:34:00.703401: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:34:01.084838: lr: 0.003016\n",
      "2022-11-27 21:34:01.084952: This epoch took 15.673645 s\n",
      "\n",
      "2022-11-27 21:34:01.085002: \n",
      "epoch:  736\n",
      "2022-11-27 21:34:15.442240: train loss : -0.9302\n",
      "2022-11-27 21:34:16.445690: validation loss: -0.8400\n",
      "2022-11-27 21:34:16.446039: Average global foreground Dice: [0.8963, 0.8783]\n",
      "2022-11-27 21:34:16.446099: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:34:16.810995: lr: 0.003006\n",
      "2022-11-27 21:34:16.811106: This epoch took 15.726074 s\n",
      "\n",
      "2022-11-27 21:34:16.811137: \n",
      "epoch:  737\n",
      "2022-11-27 21:34:31.096817: train loss : -0.9292\n",
      "2022-11-27 21:34:32.124842: validation loss: -0.8385\n",
      "2022-11-27 21:34:32.125218: Average global foreground Dice: [0.8956, 0.88]\n",
      "2022-11-27 21:34:32.125276: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:34:32.542084: lr: 0.002996\n",
      "2022-11-27 21:34:32.542190: This epoch took 15.731025 s\n",
      "\n",
      "2022-11-27 21:34:32.542219: \n",
      "epoch:  738\n",
      "2022-11-27 21:34:46.788004: train loss : -0.9310\n",
      "2022-11-27 21:34:47.791936: validation loss: -0.8409\n",
      "2022-11-27 21:34:47.792507: Average global foreground Dice: [0.8973, 0.8807]\n",
      "2022-11-27 21:34:47.792620: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:34:48.158169: lr: 0.002985\n",
      "2022-11-27 21:34:48.158273: This epoch took 15.616027 s\n",
      "\n",
      "2022-11-27 21:34:48.158302: \n",
      "epoch:  739\n",
      "2022-11-27 21:35:02.424915: train loss : -0.9306\n",
      "2022-11-27 21:35:03.431326: validation loss: -0.8380\n",
      "2022-11-27 21:35:03.431793: Average global foreground Dice: [0.8964, 0.8779]\n",
      "2022-11-27 21:35:03.431917: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:35:03.800331: lr: 0.002975\n",
      "2022-11-27 21:35:03.800435: This epoch took 15.642107 s\n",
      "\n",
      "2022-11-27 21:35:03.800471: \n",
      "epoch:  740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:35:18.053168: train loss : -0.9304\n",
      "2022-11-27 21:35:19.063239: validation loss: -0.8498\n",
      "2022-11-27 21:35:19.063587: Average global foreground Dice: [0.9026, 0.8874]\n",
      "2022-11-27 21:35:19.063645: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:35:19.429294: lr: 0.002965\n",
      "2022-11-27 21:35:19.429397: This epoch took 15.628897 s\n",
      "\n",
      "2022-11-27 21:35:19.429426: \n",
      "epoch:  741\n",
      "2022-11-27 21:35:33.675202: train loss : -0.9290\n",
      "2022-11-27 21:35:34.688826: validation loss: -0.8377\n",
      "2022-11-27 21:35:34.689161: Average global foreground Dice: [0.8939, 0.8781]\n",
      "2022-11-27 21:35:34.689222: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:35:35.174593: lr: 0.002954\n",
      "2022-11-27 21:35:35.174704: This epoch took 15.745252 s\n",
      "\n",
      "2022-11-27 21:35:35.174736: \n",
      "epoch:  742\n",
      "2022-11-27 21:35:49.460428: train loss : -0.9303\n",
      "2022-11-27 21:35:50.459181: validation loss: -0.8386\n",
      "2022-11-27 21:35:50.459522: Average global foreground Dice: [0.8948, 0.8769]\n",
      "2022-11-27 21:35:50.459579: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:35:50.823922: lr: 0.002944\n",
      "2022-11-27 21:35:50.824045: This epoch took 15.649268 s\n",
      "\n",
      "2022-11-27 21:35:50.824079: \n",
      "epoch:  743\n",
      "2022-11-27 21:36:05.100798: train loss : -0.9318\n",
      "2022-11-27 21:36:06.108743: validation loss: -0.8415\n",
      "2022-11-27 21:36:06.109126: Average global foreground Dice: [0.8977, 0.8811]\n",
      "2022-11-27 21:36:06.109216: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:36:06.518851: lr: 0.002934\n",
      "2022-11-27 21:36:06.518957: This epoch took 15.694851 s\n",
      "\n",
      "2022-11-27 21:36:06.518987: \n",
      "epoch:  744\n",
      "2022-11-27 21:36:20.821991: train loss : -0.9300\n",
      "2022-11-27 21:36:21.826422: validation loss: -0.8390\n",
      "2022-11-27 21:36:21.826859: Average global foreground Dice: [0.8949, 0.8792]\n",
      "2022-11-27 21:36:21.826935: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:36:22.213089: lr: 0.002923\n",
      "2022-11-27 21:36:22.213194: This epoch took 15.694180 s\n",
      "\n",
      "2022-11-27 21:36:22.213222: \n",
      "epoch:  745\n",
      "2022-11-27 21:36:36.513975: train loss : -0.9310\n",
      "2022-11-27 21:36:37.519601: validation loss: -0.8402\n",
      "2022-11-27 21:36:37.519934: Average global foreground Dice: [0.8977, 0.8797]\n",
      "2022-11-27 21:36:37.519995: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:36:37.884684: lr: 0.002913\n",
      "2022-11-27 21:36:37.884799: This epoch took 15.671551 s\n",
      "\n",
      "2022-11-27 21:36:37.884827: \n",
      "epoch:  746\n",
      "2022-11-27 21:36:52.179344: train loss : -0.9305\n",
      "2022-11-27 21:36:53.165627: validation loss: -0.8388\n",
      "2022-11-27 21:36:53.166008: Average global foreground Dice: [0.8968, 0.879]\n",
      "2022-11-27 21:36:53.166070: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:36:53.575416: lr: 0.002903\n",
      "2022-11-27 21:36:53.575533: This epoch took 15.690680 s\n",
      "\n",
      "2022-11-27 21:36:53.575578: \n",
      "epoch:  747\n",
      "2022-11-27 21:37:07.814113: train loss : -0.9288\n",
      "2022-11-27 21:37:08.818312: validation loss: -0.8361\n",
      "2022-11-27 21:37:08.818651: Average global foreground Dice: [0.8936, 0.8763]\n",
      "2022-11-27 21:37:08.818707: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:37:09.181125: lr: 0.002892\n",
      "2022-11-27 21:37:09.181228: This epoch took 15.605623 s\n",
      "\n",
      "2022-11-27 21:37:09.181255: \n",
      "epoch:  748\n",
      "2022-11-27 21:37:23.444367: train loss : -0.9307\n",
      "2022-11-27 21:37:24.447214: validation loss: -0.8378\n",
      "2022-11-27 21:37:24.447605: Average global foreground Dice: [0.8959, 0.8777]\n",
      "2022-11-27 21:37:24.447666: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:37:24.814212: lr: 0.002882\n",
      "2022-11-27 21:37:24.814317: This epoch took 15.633038 s\n",
      "\n",
      "2022-11-27 21:37:24.814346: \n",
      "epoch:  749\n",
      "2022-11-27 21:37:39.071290: train loss : -0.9295\n",
      "2022-11-27 21:37:40.077587: validation loss: -0.8388\n",
      "2022-11-27 21:37:40.077972: Average global foreground Dice: [0.8939, 0.8779]\n",
      "2022-11-27 21:37:40.078034: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:37:40.463823: lr: 0.002872\n",
      "2022-11-27 21:37:40.463923: saving scheduled checkpoint file...\n",
      "2022-11-27 21:37:40.467981: saving checkpoint...\n",
      "2022-11-27 21:37:40.536968: done, saving took 0.07 seconds\n",
      "2022-11-27 21:37:40.538806: done\n",
      "2022-11-27 21:37:40.538876: This epoch took 15.724504 s\n",
      "\n",
      "2022-11-27 21:37:40.538903: \n",
      "epoch:  750\n",
      "2022-11-27 21:37:54.785754: train loss : -0.9303\n",
      "2022-11-27 21:37:55.802229: validation loss: -0.8368\n",
      "2022-11-27 21:37:55.802606: Average global foreground Dice: [0.8948, 0.8768]\n",
      "2022-11-27 21:37:55.802665: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:37:56.184513: lr: 0.002861\n",
      "2022-11-27 21:37:56.184619: This epoch took 15.645690 s\n",
      "\n",
      "2022-11-27 21:37:56.184647: \n",
      "epoch:  751\n",
      "2022-11-27 21:38:10.454470: train loss : -0.9312\n",
      "2022-11-27 21:38:11.469312: validation loss: -0.8361\n",
      "2022-11-27 21:38:11.469661: Average global foreground Dice: [0.8919, 0.8763]\n",
      "2022-11-27 21:38:11.469802: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:38:11.978122: lr: 0.002851\n",
      "2022-11-27 21:38:11.978234: This epoch took 15.793560 s\n",
      "\n",
      "2022-11-27 21:38:11.978261: \n",
      "epoch:  752\n",
      "2022-11-27 21:38:26.238095: train loss : -0.9315\n",
      "2022-11-27 21:38:27.255239: validation loss: -0.8383\n",
      "2022-11-27 21:38:27.255573: Average global foreground Dice: [0.8947, 0.8781]\n",
      "2022-11-27 21:38:27.255626: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:38:27.626651: lr: 0.002841\n",
      "2022-11-27 21:38:27.626762: This epoch took 15.648476 s\n",
      "\n",
      "2022-11-27 21:38:27.626793: \n",
      "epoch:  753\n",
      "2022-11-27 21:38:41.949568: train loss : -0.9318\n",
      "2022-11-27 21:38:42.934266: validation loss: -0.8403\n",
      "2022-11-27 21:38:42.934592: Average global foreground Dice: [0.896, 0.881]\n",
      "2022-11-27 21:38:42.934646: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:38:43.309173: lr: 0.00283\n",
      "2022-11-27 21:38:43.309277: This epoch took 15.682457 s\n",
      "\n",
      "2022-11-27 21:38:43.309303: \n",
      "epoch:  754\n",
      "2022-11-27 21:38:57.665192: train loss : -0.9328\n",
      "2022-11-27 21:38:58.682462: validation loss: -0.8409\n",
      "2022-11-27 21:38:58.682836: Average global foreground Dice: [0.8972, 0.8811]\n",
      "2022-11-27 21:38:58.682922: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:38:59.056520: lr: 0.00282\n",
      "2022-11-27 21:38:59.056624: This epoch took 15.747297 s\n",
      "\n",
      "2022-11-27 21:38:59.056651: \n",
      "epoch:  755\n",
      "2022-11-27 21:39:13.320755: train loss : -0.9320\n",
      "2022-11-27 21:39:14.328695: validation loss: -0.8386\n",
      "2022-11-27 21:39:14.329074: Average global foreground Dice: [0.8963, 0.8786]\n",
      "2022-11-27 21:39:14.329129: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:39:14.719711: lr: 0.00281\n",
      "2022-11-27 21:39:14.719821: This epoch took 15.663146 s\n",
      "\n",
      "2022-11-27 21:39:14.719851: \n",
      "epoch:  756\n",
      "2022-11-27 21:39:28.985748: train loss : -0.9317\n",
      "2022-11-27 21:39:29.969007: validation loss: -0.8327\n",
      "2022-11-27 21:39:29.969525: Average global foreground Dice: [0.8917, 0.874]\n",
      "2022-11-27 21:39:29.969613: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:39:30.350934: lr: 0.002799\n",
      "2022-11-27 21:39:30.351039: This epoch took 15.631162 s\n",
      "\n",
      "2022-11-27 21:39:30.351070: \n",
      "epoch:  757\n",
      "2022-11-27 21:39:44.606541: train loss : -0.9326\n",
      "2022-11-27 21:39:45.599849: validation loss: -0.8329\n",
      "2022-11-27 21:39:45.600231: Average global foreground Dice: [0.8909, 0.8737]\n",
      "2022-11-27 21:39:45.600286: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:39:45.969793: lr: 0.002789\n",
      "2022-11-27 21:39:45.969919: This epoch took 15.618801 s\n",
      "\n",
      "2022-11-27 21:39:45.969957: \n",
      "epoch:  758\n",
      "2022-11-27 21:40:00.277344: train loss : -0.9320\n",
      "2022-11-27 21:40:01.284985: validation loss: -0.8378\n",
      "2022-11-27 21:40:01.285442: Average global foreground Dice: [0.8946, 0.8777]\n",
      "2022-11-27 21:40:01.285511: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:40:01.667938: lr: 0.002779\n",
      "2022-11-27 21:40:01.668044: This epoch took 15.698059 s\n",
      "\n",
      "2022-11-27 21:40:01.668070: \n",
      "epoch:  759\n",
      "2022-11-27 21:40:15.913780: train loss : -0.9312\n",
      "2022-11-27 21:40:16.929242: validation loss: -0.8370\n",
      "2022-11-27 21:40:16.929628: Average global foreground Dice: [0.8945, 0.8798]\n",
      "2022-11-27 21:40:16.929689: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:40:17.303078: lr: 0.002768\n",
      "2022-11-27 21:40:17.303184: This epoch took 15.635089 s\n",
      "\n",
      "2022-11-27 21:40:17.303214: \n",
      "epoch:  760\n",
      "2022-11-27 21:40:31.586041: train loss : -0.9314\n",
      "2022-11-27 21:40:32.579589: validation loss: -0.8413\n",
      "2022-11-27 21:40:32.579933: Average global foreground Dice: [0.8965, 0.8799]\n",
      "2022-11-27 21:40:32.579989: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:40:32.955193: lr: 0.002758\n",
      "2022-11-27 21:40:32.955297: This epoch took 15.652056 s\n",
      "\n",
      "2022-11-27 21:40:32.955325: \n",
      "epoch:  761\n",
      "2022-11-27 21:40:47.173147: train loss : -0.9321\n",
      "2022-11-27 21:40:48.188780: validation loss: -0.8381\n",
      "2022-11-27 21:40:48.189120: Average global foreground Dice: [0.8956, 0.8794]\n",
      "2022-11-27 21:40:48.189267: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:40:48.687368: lr: 0.002747\n",
      "2022-11-27 21:40:48.687480: This epoch took 15.732129 s\n",
      "\n",
      "2022-11-27 21:40:48.687510: \n",
      "epoch:  762\n",
      "2022-11-27 21:41:02.948519: train loss : -0.9315\n",
      "2022-11-27 21:41:03.943573: validation loss: -0.8423\n",
      "2022-11-27 21:41:03.943956: Average global foreground Dice: [0.8971, 0.881]\n",
      "2022-11-27 21:41:03.944018: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:41:04.316587: lr: 0.002737\n",
      "2022-11-27 21:41:04.316695: This epoch took 15.629158 s\n",
      "\n",
      "2022-11-27 21:41:04.316725: \n",
      "epoch:  763\n",
      "2022-11-27 21:41:18.593315: train loss : -0.9325\n",
      "2022-11-27 21:41:19.580625: validation loss: -0.8389\n",
      "2022-11-27 21:41:19.580953: Average global foreground Dice: [0.8956, 0.8795]\n",
      "2022-11-27 21:41:19.581009: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:41:19.971910: lr: 0.002727\n",
      "2022-11-27 21:41:19.972019: This epoch took 15.655267 s\n",
      "\n",
      "2022-11-27 21:41:19.972048: \n",
      "epoch:  764\n",
      "2022-11-27 21:41:34.224055: train loss : -0.9318\n",
      "2022-11-27 21:41:35.219473: validation loss: -0.8363\n",
      "2022-11-27 21:41:35.219848: Average global foreground Dice: [0.8945, 0.8774]\n",
      "2022-11-27 21:41:35.219907: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:41:35.592376: lr: 0.002716\n",
      "2022-11-27 21:41:35.592485: This epoch took 15.620410 s\n",
      "\n",
      "2022-11-27 21:41:35.592511: \n",
      "epoch:  765\n",
      "2022-11-27 21:41:49.801133: train loss : -0.9324\n",
      "2022-11-27 21:41:50.821697: validation loss: -0.8413\n",
      "2022-11-27 21:41:50.822091: Average global foreground Dice: [0.8958, 0.8791]\n",
      "2022-11-27 21:41:50.822154: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:41:51.195903: lr: 0.002706\n",
      "2022-11-27 21:41:51.196009: This epoch took 15.603450 s\n",
      "\n",
      "2022-11-27 21:41:51.196038: \n",
      "epoch:  766\n",
      "2022-11-27 21:42:05.481240: train loss : -0.9317\n",
      "2022-11-27 21:42:06.475887: validation loss: -0.8369\n",
      "2022-11-27 21:42:06.476222: Average global foreground Dice: [0.8952, 0.878]\n",
      "2022-11-27 21:42:06.476278: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:42:06.876286: lr: 0.002695\n",
      "2022-11-27 21:42:06.876419: This epoch took 15.680339 s\n",
      "\n",
      "2022-11-27 21:42:06.876449: \n",
      "epoch:  767\n",
      "2022-11-27 21:42:21.115089: train loss : -0.9325\n",
      "2022-11-27 21:42:22.142151: validation loss: -0.8379\n",
      "2022-11-27 21:42:22.142540: Average global foreground Dice: [0.8949, 0.8768]\n",
      "2022-11-27 21:42:22.142605: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:42:22.515260: lr: 0.002685\n",
      "2022-11-27 21:42:22.515367: This epoch took 15.638891 s\n",
      "\n",
      "2022-11-27 21:42:22.515395: \n",
      "epoch:  768\n",
      "2022-11-27 21:42:36.778435: train loss : -0.9319\n",
      "2022-11-27 21:42:37.770017: validation loss: -0.8369\n",
      "2022-11-27 21:42:37.770389: Average global foreground Dice: [0.8935, 0.8782]\n",
      "2022-11-27 21:42:37.770448: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:42:38.183436: lr: 0.002675\n",
      "2022-11-27 21:42:38.183562: This epoch took 15.668123 s\n",
      "\n",
      "2022-11-27 21:42:38.183594: \n",
      "epoch:  769\n",
      "2022-11-27 21:42:52.510494: train loss : -0.9326\n",
      "2022-11-27 21:42:53.495557: validation loss: -0.8365\n",
      "2022-11-27 21:42:53.495933: Average global foreground Dice: [0.8924, 0.8769]\n",
      "2022-11-27 21:42:53.495991: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:42:53.869261: lr: 0.002664\n",
      "2022-11-27 21:42:53.869377: This epoch took 15.685738 s\n",
      "\n",
      "2022-11-27 21:42:53.869410: \n",
      "epoch:  770\n",
      "2022-11-27 21:43:08.129170: train loss : -0.9321\n",
      "2022-11-27 21:43:09.118059: validation loss: -0.8362\n",
      "2022-11-27 21:43:09.118385: Average global foreground Dice: [0.8948, 0.8749]\n",
      "2022-11-27 21:43:09.118437: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:43:09.489454: lr: 0.002654\n",
      "2022-11-27 21:43:09.489558: This epoch took 15.620120 s\n",
      "\n",
      "2022-11-27 21:43:09.489586: \n",
      "epoch:  771\n",
      "2022-11-27 21:43:23.800027: train loss : -0.9321\n",
      "2022-11-27 21:43:24.792837: validation loss: -0.8357\n",
      "2022-11-27 21:43:24.793179: Average global foreground Dice: [0.8938, 0.8754]\n",
      "2022-11-27 21:43:24.793236: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:43:25.297058: lr: 0.002643\n",
      "2022-11-27 21:43:25.297304: This epoch took 15.807690 s\n",
      "\n",
      "2022-11-27 21:43:25.297343: \n",
      "epoch:  772\n",
      "2022-11-27 21:43:39.586374: train loss : -0.9317\n",
      "2022-11-27 21:43:40.633755: validation loss: -0.8393\n",
      "2022-11-27 21:43:40.634136: Average global foreground Dice: [0.8973, 0.8777]\n",
      "2022-11-27 21:43:40.634200: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:43:41.007984: lr: 0.002633\n",
      "2022-11-27 21:43:41.008094: This epoch took 15.710722 s\n",
      "\n",
      "2022-11-27 21:43:41.008121: \n",
      "epoch:  773\n",
      "2022-11-27 21:43:55.240788: train loss : -0.9304\n",
      "2022-11-27 21:43:56.276264: validation loss: -0.8365\n",
      "2022-11-27 21:43:56.276599: Average global foreground Dice: [0.8952, 0.8782]\n",
      "2022-11-27 21:43:56.276657: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:43:56.647552: lr: 0.002622\n",
      "2022-11-27 21:43:56.647660: This epoch took 15.639514 s\n",
      "\n",
      "2022-11-27 21:43:56.647688: \n",
      "epoch:  774\n",
      "2022-11-27 21:44:10.885059: train loss : -0.9319\n",
      "2022-11-27 21:44:11.896803: validation loss: -0.8354\n",
      "2022-11-27 21:44:11.897134: Average global foreground Dice: [0.8927, 0.8778]\n",
      "2022-11-27 21:44:11.897188: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:44:12.269610: lr: 0.002612\n",
      "2022-11-27 21:44:12.269719: This epoch took 15.622005 s\n",
      "\n",
      "2022-11-27 21:44:12.269748: \n",
      "epoch:  775\n",
      "2022-11-27 21:44:26.559318: train loss : -0.9300\n",
      "2022-11-27 21:44:27.554584: validation loss: -0.8383\n",
      "2022-11-27 21:44:27.554917: Average global foreground Dice: [0.8943, 0.8759]\n",
      "2022-11-27 21:44:27.554967: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:44:27.927487: lr: 0.002601\n",
      "2022-11-27 21:44:27.927595: This epoch took 15.657820 s\n",
      "\n",
      "2022-11-27 21:44:27.927624: \n",
      "epoch:  776\n",
      "2022-11-27 21:44:42.180251: train loss : -0.9315\n",
      "2022-11-27 21:44:43.189726: validation loss: -0.8345\n",
      "2022-11-27 21:44:43.190117: Average global foreground Dice: [0.8931, 0.8765]\n",
      "2022-11-27 21:44:43.190185: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:44:43.562533: lr: 0.002591\n",
      "2022-11-27 21:44:43.562644: This epoch took 15.634994 s\n",
      "\n",
      "2022-11-27 21:44:43.562683: \n",
      "epoch:  777\n",
      "2022-11-27 21:44:57.874914: train loss : -0.9320\n",
      "2022-11-27 21:44:58.904489: validation loss: -0.8374\n",
      "2022-11-27 21:44:58.904823: Average global foreground Dice: [0.8944, 0.878]\n",
      "2022-11-27 21:44:58.904879: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:44:59.278007: lr: 0.002581\n",
      "2022-11-27 21:44:59.278114: This epoch took 15.715396 s\n",
      "\n",
      "2022-11-27 21:44:59.278144: \n",
      "epoch:  778\n",
      "2022-11-27 21:45:13.585598: train loss : -0.9333\n",
      "2022-11-27 21:45:14.633270: validation loss: -0.8401\n",
      "2022-11-27 21:45:14.633611: Average global foreground Dice: [0.8957, 0.879]\n",
      "2022-11-27 21:45:14.633666: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:45:15.006126: lr: 0.00257\n",
      "2022-11-27 21:45:15.006233: This epoch took 15.728063 s\n",
      "\n",
      "2022-11-27 21:45:15.006263: \n",
      "epoch:  779\n",
      "2022-11-27 21:45:29.306514: train loss : -0.9306\n",
      "2022-11-27 21:45:30.319258: validation loss: -0.8410\n",
      "2022-11-27 21:45:30.319659: Average global foreground Dice: [0.8955, 0.8806]\n",
      "2022-11-27 21:45:30.319756: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:45:30.713875: lr: 0.00256\n",
      "2022-11-27 21:45:30.713992: This epoch took 15.707701 s\n",
      "\n",
      "2022-11-27 21:45:30.714021: \n",
      "epoch:  780\n",
      "2022-11-27 21:45:44.906003: train loss : -0.9333\n",
      "2022-11-27 21:45:45.923549: validation loss: -0.8367\n",
      "2022-11-27 21:45:45.923937: Average global foreground Dice: [0.8939, 0.8797]\n",
      "2022-11-27 21:45:45.923994: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:45:46.295649: lr: 0.002549\n",
      "2022-11-27 21:45:46.295754: This epoch took 15.581706 s\n",
      "\n",
      "2022-11-27 21:45:46.295786: \n",
      "epoch:  781\n",
      "2022-11-27 21:46:00.557460: train loss : -0.9333\n",
      "2022-11-27 21:46:01.551512: validation loss: -0.8327\n",
      "2022-11-27 21:46:01.552020: Average global foreground Dice: [0.8917, 0.8758]\n",
      "2022-11-27 21:46:01.552099: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:46:02.057078: lr: 0.002539\n",
      "2022-11-27 21:46:02.057194: This epoch took 15.761378 s\n",
      "\n",
      "2022-11-27 21:46:02.057223: \n",
      "epoch:  782\n",
      "2022-11-27 21:46:16.348972: train loss : -0.9319\n",
      "2022-11-27 21:46:17.345387: validation loss: -0.8371\n",
      "2022-11-27 21:46:17.345771: Average global foreground Dice: [0.8935, 0.8787]\n",
      "2022-11-27 21:46:17.345835: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:46:17.726271: lr: 0.002528\n",
      "2022-11-27 21:46:17.726386: This epoch took 15.669137 s\n",
      "\n",
      "2022-11-27 21:46:17.726422: \n",
      "epoch:  783\n",
      "2022-11-27 21:46:31.972081: train loss : -0.9317\n",
      "2022-11-27 21:46:32.977736: validation loss: -0.8415\n",
      "2022-11-27 21:46:32.978127: Average global foreground Dice: [0.8976, 0.8818]\n",
      "2022-11-27 21:46:32.978187: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:46:33.354915: lr: 0.002518\n",
      "2022-11-27 21:46:33.355033: This epoch took 15.628579 s\n",
      "\n",
      "2022-11-27 21:46:33.355072: \n",
      "epoch:  784\n",
      "2022-11-27 21:46:47.677973: train loss : -0.9330\n",
      "2022-11-27 21:46:48.709029: validation loss: -0.8374\n",
      "2022-11-27 21:46:48.709404: Average global foreground Dice: [0.8943, 0.8789]\n",
      "2022-11-27 21:46:48.709463: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:46:49.079722: lr: 0.002507\n",
      "2022-11-27 21:46:49.079832: This epoch took 15.724723 s\n",
      "\n",
      "2022-11-27 21:46:49.079862: \n",
      "epoch:  785\n",
      "2022-11-27 21:47:03.391302: train loss : -0.9325\n",
      "2022-11-27 21:47:04.366860: validation loss: -0.8399\n",
      "2022-11-27 21:47:04.367185: Average global foreground Dice: [0.8965, 0.8785]\n",
      "2022-11-27 21:47:04.367240: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:47:04.739423: lr: 0.002497\n",
      "2022-11-27 21:47:04.739532: This epoch took 15.659642 s\n",
      "\n",
      "2022-11-27 21:47:04.739561: \n",
      "epoch:  786\n",
      "2022-11-27 21:47:18.977883: train loss : -0.9320\n",
      "2022-11-27 21:47:20.009509: validation loss: -0.8347\n",
      "2022-11-27 21:47:20.009879: Average global foreground Dice: [0.8936, 0.8753]\n",
      "2022-11-27 21:47:20.010005: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:47:20.418332: lr: 0.002486\n",
      "2022-11-27 21:47:20.418432: This epoch took 15.678845 s\n",
      "\n",
      "2022-11-27 21:47:20.418457: \n",
      "epoch:  787\n",
      "2022-11-27 21:47:34.702209: train loss : -0.9305\n",
      "2022-11-27 21:47:35.704436: validation loss: -0.8437\n",
      "2022-11-27 21:47:35.704775: Average global foreground Dice: [0.8973, 0.8825]\n",
      "2022-11-27 21:47:35.704848: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:47:36.080769: lr: 0.002476\n",
      "2022-11-27 21:47:36.080876: This epoch took 15.662394 s\n",
      "\n",
      "2022-11-27 21:47:36.080906: \n",
      "epoch:  788\n",
      "2022-11-27 21:47:50.355356: train loss : -0.9324\n",
      "2022-11-27 21:47:51.364915: validation loss: -0.8396\n",
      "2022-11-27 21:47:51.365277: Average global foreground Dice: [0.8971, 0.8801]\n",
      "2022-11-27 21:47:51.365358: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:47:51.738566: lr: 0.002465\n",
      "2022-11-27 21:47:51.738673: This epoch took 15.657740 s\n",
      "\n",
      "2022-11-27 21:47:51.738706: \n",
      "epoch:  789\n",
      "2022-11-27 21:48:06.001392: train loss : -0.9328\n",
      "2022-11-27 21:48:07.009787: validation loss: -0.8395\n",
      "2022-11-27 21:48:07.010190: Average global foreground Dice: [0.8964, 0.8797]\n",
      "2022-11-27 21:48:07.010252: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:48:07.396016: lr: 0.002455\n",
      "2022-11-27 21:48:07.396122: This epoch took 15.657384 s\n",
      "\n",
      "2022-11-27 21:48:07.396151: \n",
      "epoch:  790\n",
      "2022-11-27 21:48:21.671705: train loss : -0.9332\n",
      "2022-11-27 21:48:22.664854: validation loss: -0.8380\n",
      "2022-11-27 21:48:22.665173: Average global foreground Dice: [0.8954, 0.8774]\n",
      "2022-11-27 21:48:22.665226: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:48:23.093220: lr: 0.002444\n",
      "2022-11-27 21:48:23.093348: This epoch took 15.697149 s\n",
      "\n",
      "2022-11-27 21:48:23.093378: \n",
      "epoch:  791\n",
      "2022-11-27 21:48:37.327862: train loss : -0.9337\n",
      "2022-11-27 21:48:38.322322: validation loss: -0.8404\n",
      "2022-11-27 21:48:38.322653: Average global foreground Dice: [0.8969, 0.8806]\n",
      "2022-11-27 21:48:38.322708: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:48:38.823750: lr: 0.002434\n",
      "2022-11-27 21:48:38.823861: This epoch took 15.730456 s\n",
      "\n",
      "2022-11-27 21:48:38.823895: \n",
      "epoch:  792\n",
      "2022-11-27 21:48:53.212786: train loss : -0.9333\n",
      "2022-11-27 21:48:54.198738: validation loss: -0.8430\n",
      "2022-11-27 21:48:54.199057: Average global foreground Dice: [0.8983, 0.8811]\n",
      "2022-11-27 21:48:54.199112: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:48:54.572699: lr: 0.002423\n",
      "2022-11-27 21:48:54.572811: This epoch took 15.748848 s\n",
      "\n",
      "2022-11-27 21:48:54.572841: \n",
      "epoch:  793\n",
      "2022-11-27 21:49:08.845608: train loss : -0.9341\n",
      "2022-11-27 21:49:09.836375: validation loss: -0.8365\n",
      "2022-11-27 21:49:09.836719: Average global foreground Dice: [0.8954, 0.8773]\n",
      "2022-11-27 21:49:09.836814: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:49:10.210694: lr: 0.002413\n",
      "2022-11-27 21:49:10.210808: This epoch took 15.637940 s\n",
      "\n",
      "2022-11-27 21:49:10.210838: \n",
      "epoch:  794\n",
      "2022-11-27 21:49:24.479264: train loss : -0.9335\n",
      "2022-11-27 21:49:25.497968: validation loss: -0.8388\n",
      "2022-11-27 21:49:25.498362: Average global foreground Dice: [0.8938, 0.8808]\n",
      "2022-11-27 21:49:25.498427: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:49:25.874672: lr: 0.002402\n",
      "2022-11-27 21:49:25.874779: This epoch took 15.663913 s\n",
      "\n",
      "2022-11-27 21:49:25.874829: \n",
      "epoch:  795\n",
      "2022-11-27 21:49:40.215292: train loss : -0.9328\n",
      "2022-11-27 21:49:41.208377: validation loss: -0.8362\n",
      "2022-11-27 21:49:41.208755: Average global foreground Dice: [0.8938, 0.8787]\n",
      "2022-11-27 21:49:41.208817: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:49:41.585291: lr: 0.002391\n",
      "2022-11-27 21:49:41.585405: This epoch took 15.710546 s\n",
      "\n",
      "2022-11-27 21:49:41.585435: \n",
      "epoch:  796\n",
      "2022-11-27 21:49:55.828418: train loss : -0.9333\n",
      "2022-11-27 21:49:56.865509: validation loss: -0.8392\n",
      "2022-11-27 21:49:56.865906: Average global foreground Dice: [0.8965, 0.878]\n",
      "2022-11-27 21:49:56.865969: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:49:57.243821: lr: 0.002381\n",
      "2022-11-27 21:49:57.243932: This epoch took 15.658470 s\n",
      "\n",
      "2022-11-27 21:49:57.243963: \n",
      "epoch:  797\n",
      "2022-11-27 21:50:11.509269: train loss : -0.9337\n",
      "2022-11-27 21:50:12.497039: validation loss: -0.8356\n",
      "2022-11-27 21:50:12.497407: Average global foreground Dice: [0.8941, 0.8779]\n",
      "2022-11-27 21:50:12.497466: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:50:12.869735: lr: 0.00237\n",
      "2022-11-27 21:50:12.869855: This epoch took 15.625850 s\n",
      "\n",
      "2022-11-27 21:50:12.869884: \n",
      "epoch:  798\n",
      "2022-11-27 21:50:27.096069: train loss : -0.9326\n",
      "2022-11-27 21:50:28.081038: validation loss: -0.8419\n",
      "2022-11-27 21:50:28.081600: Average global foreground Dice: [0.8982, 0.8804]\n",
      "2022-11-27 21:50:28.081697: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:50:28.472931: lr: 0.00236\n",
      "2022-11-27 21:50:28.473037: This epoch took 15.603121 s\n",
      "\n",
      "2022-11-27 21:50:28.473067: \n",
      "epoch:  799\n",
      "2022-11-27 21:50:42.712827: train loss : -0.9334\n",
      "2022-11-27 21:50:43.720973: validation loss: -0.8352\n",
      "2022-11-27 21:50:43.721309: Average global foreground Dice: [0.8929, 0.877]\n",
      "2022-11-27 21:50:43.721364: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:50:44.106556: lr: 0.002349\n",
      "2022-11-27 21:50:44.106650: saving scheduled checkpoint file...\n",
      "2022-11-27 21:50:44.110617: saving checkpoint...\n",
      "2022-11-27 21:50:44.201092: done, saving took 0.09 seconds\n",
      "2022-11-27 21:50:44.203049: done\n",
      "2022-11-27 21:50:44.203126: This epoch took 15.730032 s\n",
      "\n",
      "2022-11-27 21:50:44.203157: \n",
      "epoch:  800\n",
      "2022-11-27 21:50:58.454923: train loss : -0.9343\n",
      "2022-11-27 21:50:59.453535: validation loss: -0.8355\n",
      "2022-11-27 21:50:59.453977: Average global foreground Dice: [0.8947, 0.879]\n",
      "2022-11-27 21:50:59.454046: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:50:59.968467: lr: 0.002339\n",
      "2022-11-27 21:50:59.968578: This epoch took 15.765388 s\n",
      "\n",
      "2022-11-27 21:50:59.968604: \n",
      "epoch:  801\n",
      "2022-11-27 21:51:14.230105: train loss : -0.9332\n",
      "2022-11-27 21:51:15.224993: validation loss: -0.8399\n",
      "2022-11-27 21:51:15.225400: Average global foreground Dice: [0.8974, 0.8772]\n",
      "2022-11-27 21:51:15.225483: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:51:15.608189: lr: 0.002328\n",
      "2022-11-27 21:51:15.608291: This epoch took 15.639663 s\n",
      "\n",
      "2022-11-27 21:51:15.608342: \n",
      "epoch:  802\n",
      "2022-11-27 21:51:29.944410: train loss : -0.9345\n",
      "2022-11-27 21:51:30.944789: validation loss: -0.8360\n",
      "2022-11-27 21:51:30.945216: Average global foreground Dice: [0.8945, 0.8765]\n",
      "2022-11-27 21:51:30.945365: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:51:31.317694: lr: 0.002317\n",
      "2022-11-27 21:51:31.317923: This epoch took 15.709523 s\n",
      "\n",
      "2022-11-27 21:51:31.317959: \n",
      "epoch:  803\n",
      "2022-11-27 21:51:45.590196: train loss : -0.9346\n",
      "2022-11-27 21:51:46.570825: validation loss: -0.8407\n",
      "2022-11-27 21:51:46.571203: Average global foreground Dice: [0.8964, 0.8818]\n",
      "2022-11-27 21:51:46.571266: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:51:46.946774: lr: 0.002307\n",
      "2022-11-27 21:51:46.946902: This epoch took 15.628915 s\n",
      "\n",
      "2022-11-27 21:51:46.946930: \n",
      "epoch:  804\n",
      "2022-11-27 21:52:01.213403: train loss : -0.9328\n",
      "2022-11-27 21:52:02.241613: validation loss: -0.8422\n",
      "2022-11-27 21:52:02.242083: Average global foreground Dice: [0.8993, 0.8821]\n",
      "2022-11-27 21:52:02.242289: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:52:02.616353: lr: 0.002296\n",
      "2022-11-27 21:52:02.616474: This epoch took 15.669501 s\n",
      "\n",
      "2022-11-27 21:52:02.616507: \n",
      "epoch:  805\n",
      "2022-11-27 21:52:16.896609: train loss : -0.9324\n",
      "2022-11-27 21:52:17.896739: validation loss: -0.8353\n",
      "2022-11-27 21:52:17.897128: Average global foreground Dice: [0.892, 0.8772]\n",
      "2022-11-27 21:52:17.897290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:52:18.278899: lr: 0.002286\n",
      "2022-11-27 21:52:18.279011: This epoch took 15.662477 s\n",
      "\n",
      "2022-11-27 21:52:18.279049: \n",
      "epoch:  806\n",
      "2022-11-27 21:52:32.583609: train loss : -0.9333\n",
      "2022-11-27 21:52:33.579594: validation loss: -0.8332\n",
      "2022-11-27 21:52:33.579982: Average global foreground Dice: [0.8907, 0.8739]\n",
      "2022-11-27 21:52:33.580038: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:52:33.954531: lr: 0.002275\n",
      "2022-11-27 21:52:33.954644: This epoch took 15.675567 s\n",
      "\n",
      "2022-11-27 21:52:33.954679: \n",
      "epoch:  807\n",
      "2022-11-27 21:52:48.236695: train loss : -0.9338\n",
      "2022-11-27 21:52:49.240589: validation loss: -0.8352\n",
      "2022-11-27 21:52:49.241098: Average global foreground Dice: [0.8938, 0.8766]\n",
      "2022-11-27 21:52:49.241237: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:52:49.625233: lr: 0.002264\n",
      "2022-11-27 21:52:49.625343: This epoch took 15.670635 s\n",
      "\n",
      "2022-11-27 21:52:49.625369: \n",
      "epoch:  808\n",
      "2022-11-27 21:53:03.892744: train loss : -0.9333\n",
      "2022-11-27 21:53:04.909812: validation loss: -0.8360\n",
      "2022-11-27 21:53:04.910157: Average global foreground Dice: [0.8932, 0.8784]\n",
      "2022-11-27 21:53:04.910217: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:53:05.282828: lr: 0.002254\n",
      "2022-11-27 21:53:05.282938: This epoch took 15.657543 s\n",
      "\n",
      "2022-11-27 21:53:05.282972: \n",
      "epoch:  809\n",
      "2022-11-27 21:53:19.535357: train loss : -0.9343\n",
      "2022-11-27 21:53:20.564487: validation loss: -0.8328\n",
      "2022-11-27 21:53:20.564830: Average global foreground Dice: [0.8919, 0.8724]\n",
      "2022-11-27 21:53:20.564895: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:53:20.973032: lr: 0.002243\n",
      "2022-11-27 21:53:20.973139: This epoch took 15.690136 s\n",
      "\n",
      "2022-11-27 21:53:20.973167: \n",
      "epoch:  810\n",
      "2022-11-27 21:53:35.254369: train loss : -0.9331\n",
      "2022-11-27 21:53:36.284035: validation loss: -0.8405\n",
      "2022-11-27 21:53:36.284419: Average global foreground Dice: [0.8962, 0.8788]\n",
      "2022-11-27 21:53:36.284509: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:53:36.793686: lr: 0.002233\n",
      "2022-11-27 21:53:36.793796: This epoch took 15.820602 s\n",
      "\n",
      "2022-11-27 21:53:36.793833: \n",
      "epoch:  811\n",
      "2022-11-27 21:53:51.077783: train loss : -0.9344\n",
      "2022-11-27 21:53:52.079975: validation loss: -0.8382\n",
      "2022-11-27 21:53:52.080320: Average global foreground Dice: [0.8942, 0.8793]\n",
      "2022-11-27 21:53:52.080384: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:53:52.452317: lr: 0.002222\n",
      "2022-11-27 21:53:52.452423: This epoch took 15.658563 s\n",
      "\n",
      "2022-11-27 21:53:52.452449: \n",
      "epoch:  812\n",
      "2022-11-27 21:54:06.736181: train loss : -0.9334\n",
      "2022-11-27 21:54:07.741219: validation loss: -0.8390\n",
      "2022-11-27 21:54:07.741601: Average global foreground Dice: [0.8961, 0.879]\n",
      "2022-11-27 21:54:07.741661: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:54:08.144349: lr: 0.002211\n",
      "2022-11-27 21:54:08.144462: This epoch took 15.691988 s\n",
      "\n",
      "2022-11-27 21:54:08.144489: \n",
      "epoch:  813\n",
      "2022-11-27 21:54:22.403237: train loss : -0.9334\n",
      "2022-11-27 21:54:23.395923: validation loss: -0.8358\n",
      "2022-11-27 21:54:23.396417: Average global foreground Dice: [0.894, 0.8775]\n",
      "2022-11-27 21:54:23.396564: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:54:23.774137: lr: 0.002201\n",
      "2022-11-27 21:54:23.774246: This epoch took 15.629726 s\n",
      "\n",
      "2022-11-27 21:54:23.774274: \n",
      "epoch:  814\n",
      "2022-11-27 21:54:37.990964: train loss : -0.9345\n",
      "2022-11-27 21:54:39.020036: validation loss: -0.8386\n",
      "2022-11-27 21:54:39.020367: Average global foreground Dice: [0.8967, 0.8788]\n",
      "2022-11-27 21:54:39.020423: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:54:39.393206: lr: 0.00219\n",
      "2022-11-27 21:54:39.393312: This epoch took 15.619012 s\n",
      "\n",
      "2022-11-27 21:54:39.393337: \n",
      "epoch:  815\n",
      "2022-11-27 21:54:53.761909: train loss : -0.9328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:54:54.752212: validation loss: -0.8385\n",
      "2022-11-27 21:54:54.752594: Average global foreground Dice: [0.8956, 0.8785]\n",
      "2022-11-27 21:54:54.752651: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:54:55.123250: lr: 0.002179\n",
      "2022-11-27 21:54:55.123363: This epoch took 15.730000 s\n",
      "\n",
      "2022-11-27 21:54:55.123393: \n",
      "epoch:  816\n",
      "2022-11-27 21:55:09.390059: train loss : -0.9342\n",
      "2022-11-27 21:55:10.387495: validation loss: -0.8321\n",
      "2022-11-27 21:55:10.387834: Average global foreground Dice: [0.8918, 0.8752]\n",
      "2022-11-27 21:55:10.387892: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:55:10.762883: lr: 0.002169\n",
      "2022-11-27 21:55:10.762995: This epoch took 15.639575 s\n",
      "\n",
      "2022-11-27 21:55:10.763024: \n",
      "epoch:  817\n",
      "2022-11-27 21:55:25.024379: train loss : -0.9325\n",
      "2022-11-27 21:55:26.011075: validation loss: -0.8340\n",
      "2022-11-27 21:55:26.011411: Average global foreground Dice: [0.8926, 0.8751]\n",
      "2022-11-27 21:55:26.011467: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:55:26.403435: lr: 0.002158\n",
      "2022-11-27 21:55:26.403539: This epoch took 15.640488 s\n",
      "\n",
      "2022-11-27 21:55:26.403568: \n",
      "epoch:  818\n",
      "2022-11-27 21:55:40.628876: train loss : -0.9349\n",
      "2022-11-27 21:55:41.627075: validation loss: -0.8388\n",
      "2022-11-27 21:55:41.627406: Average global foreground Dice: [0.8964, 0.8786]\n",
      "2022-11-27 21:55:41.627460: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:55:42.001582: lr: 0.002147\n",
      "2022-11-27 21:55:42.001689: This epoch took 15.598094 s\n",
      "\n",
      "2022-11-27 21:55:42.001718: \n",
      "epoch:  819\n",
      "2022-11-27 21:55:56.289746: train loss : -0.9343\n",
      "2022-11-27 21:55:57.292319: validation loss: -0.8322\n",
      "2022-11-27 21:55:57.292669: Average global foreground Dice: [0.8912, 0.8745]\n",
      "2022-11-27 21:55:57.292729: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:55:57.685160: lr: 0.002137\n",
      "2022-11-27 21:55:57.685277: This epoch took 15.683533 s\n",
      "\n",
      "2022-11-27 21:55:57.685306: \n",
      "epoch:  820\n",
      "2022-11-27 21:56:11.957719: train loss : -0.9337\n",
      "2022-11-27 21:56:12.947709: validation loss: -0.8333\n",
      "2022-11-27 21:56:12.948109: Average global foreground Dice: [0.8931, 0.8743]\n",
      "2022-11-27 21:56:12.948169: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:56:13.426124: lr: 0.002126\n",
      "2022-11-27 21:56:13.426236: This epoch took 15.740904 s\n",
      "\n",
      "2022-11-27 21:56:13.426284: \n",
      "epoch:  821\n",
      "2022-11-27 21:56:27.686708: train loss : -0.9359\n",
      "2022-11-27 21:56:28.755359: validation loss: -0.8426\n",
      "2022-11-27 21:56:28.755693: Average global foreground Dice: [0.8983, 0.8817]\n",
      "2022-11-27 21:56:28.755753: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:56:29.119294: lr: 0.002115\n",
      "2022-11-27 21:56:29.119409: This epoch took 15.693095 s\n",
      "\n",
      "2022-11-27 21:56:29.119441: \n",
      "epoch:  822\n",
      "2022-11-27 21:56:43.353475: train loss : -0.9333\n",
      "2022-11-27 21:56:44.357401: validation loss: -0.8360\n",
      "2022-11-27 21:56:44.357798: Average global foreground Dice: [0.895, 0.8781]\n",
      "2022-11-27 21:56:44.357908: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:56:44.721808: lr: 0.002105\n",
      "2022-11-27 21:56:44.721923: This epoch took 15.602455 s\n",
      "\n",
      "2022-11-27 21:56:44.721969: \n",
      "epoch:  823\n",
      "2022-11-27 21:56:59.019819: train loss : -0.9344\n",
      "2022-11-27 21:57:00.025735: validation loss: -0.8373\n",
      "2022-11-27 21:57:00.026101: Average global foreground Dice: [0.8962, 0.877]\n",
      "2022-11-27 21:57:00.026165: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:57:00.385979: lr: 0.002094\n",
      "2022-11-27 21:57:00.386088: This epoch took 15.664093 s\n",
      "\n",
      "2022-11-27 21:57:00.386116: \n",
      "epoch:  824\n",
      "2022-11-27 21:57:14.616277: train loss : -0.9358\n",
      "2022-11-27 21:57:15.612543: validation loss: -0.8368\n",
      "2022-11-27 21:57:15.612920: Average global foreground Dice: [0.8949, 0.8777]\n",
      "2022-11-27 21:57:15.612986: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:57:15.973526: lr: 0.002083\n",
      "2022-11-27 21:57:15.973638: This epoch took 15.587495 s\n",
      "\n",
      "2022-11-27 21:57:15.973667: \n",
      "epoch:  825\n",
      "2022-11-27 21:57:30.272675: train loss : -0.9332\n",
      "2022-11-27 21:57:31.281498: validation loss: -0.8412\n",
      "2022-11-27 21:57:31.281828: Average global foreground Dice: [0.8972, 0.8827]\n",
      "2022-11-27 21:57:31.281883: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:57:31.643972: lr: 0.002072\n",
      "2022-11-27 21:57:31.644077: This epoch took 15.670378 s\n",
      "\n",
      "2022-11-27 21:57:31.644105: \n",
      "epoch:  826\n",
      "2022-11-27 21:57:45.934342: train loss : -0.9345\n",
      "2022-11-27 21:57:46.969555: validation loss: -0.8433\n",
      "2022-11-27 21:57:46.969949: Average global foreground Dice: [0.898, 0.8837]\n",
      "2022-11-27 21:57:46.970017: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:57:47.334932: lr: 0.002062\n",
      "2022-11-27 21:57:47.335045: This epoch took 15.690914 s\n",
      "\n",
      "2022-11-27 21:57:47.335074: \n",
      "epoch:  827\n",
      "2022-11-27 21:58:01.601153: train loss : -0.9341\n",
      "2022-11-27 21:58:02.602925: validation loss: -0.8353\n",
      "2022-11-27 21:58:02.603435: Average global foreground Dice: [0.8953, 0.8764]\n",
      "2022-11-27 21:58:02.603519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:58:02.982519: lr: 0.002051\n",
      "2022-11-27 21:58:02.982630: This epoch took 15.647530 s\n",
      "\n",
      "2022-11-27 21:58:02.982660: \n",
      "epoch:  828\n",
      "2022-11-27 21:58:17.244141: train loss : -0.9349\n",
      "2022-11-27 21:58:18.272390: validation loss: -0.8375\n",
      "2022-11-27 21:58:18.272779: Average global foreground Dice: [0.8956, 0.8782]\n",
      "2022-11-27 21:58:18.272842: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:58:18.639337: lr: 0.00204\n",
      "2022-11-27 21:58:18.639455: This epoch took 15.656753 s\n",
      "\n",
      "2022-11-27 21:58:18.639485: \n",
      "epoch:  829\n",
      "2022-11-27 21:58:32.888731: train loss : -0.9341\n",
      "2022-11-27 21:58:33.931165: validation loss: -0.8397\n",
      "2022-11-27 21:58:33.931500: Average global foreground Dice: [0.8957, 0.8796]\n",
      "2022-11-27 21:58:33.931557: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:58:34.292804: lr: 0.00203\n",
      "2022-11-27 21:58:34.292936: This epoch took 15.653408 s\n",
      "\n",
      "2022-11-27 21:58:34.292970: \n",
      "epoch:  830\n",
      "2022-11-27 21:58:48.534724: train loss : -0.9351\n",
      "2022-11-27 21:58:49.542105: validation loss: -0.8375\n",
      "2022-11-27 21:58:49.542498: Average global foreground Dice: [0.895, 0.878]\n",
      "2022-11-27 21:58:49.542554: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:58:49.915493: lr: 0.002019\n",
      "2022-11-27 21:58:49.915613: This epoch took 15.622601 s\n",
      "\n",
      "2022-11-27 21:58:49.915644: \n",
      "epoch:  831\n",
      "2022-11-27 21:59:04.170895: train loss : -0.9353\n",
      "2022-11-27 21:59:05.163987: validation loss: -0.8413\n",
      "2022-11-27 21:59:05.164326: Average global foreground Dice: [0.8966, 0.88]\n",
      "2022-11-27 21:59:05.164386: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:59:05.658043: lr: 0.002008\n",
      "2022-11-27 21:59:05.658164: This epoch took 15.742494 s\n",
      "\n",
      "2022-11-27 21:59:05.658192: \n",
      "epoch:  832\n",
      "2022-11-27 21:59:19.958995: train loss : -0.9344\n",
      "2022-11-27 21:59:20.971493: validation loss: -0.8380\n",
      "2022-11-27 21:59:20.971898: Average global foreground Dice: [0.8958, 0.879]\n",
      "2022-11-27 21:59:20.972106: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:59:21.395497: lr: 0.001997\n",
      "2022-11-27 21:59:21.395628: This epoch took 15.737395 s\n",
      "\n",
      "2022-11-27 21:59:21.395659: \n",
      "epoch:  833\n",
      "2022-11-27 21:59:35.652371: train loss : -0.9332\n",
      "2022-11-27 21:59:36.630594: validation loss: -0.8360\n",
      "2022-11-27 21:59:36.630955: Average global foreground Dice: [0.8937, 0.8784]\n",
      "2022-11-27 21:59:36.631048: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:59:36.995011: lr: 0.001987\n",
      "2022-11-27 21:59:36.995126: This epoch took 15.599441 s\n",
      "\n",
      "2022-11-27 21:59:36.995155: \n",
      "epoch:  834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:59:51.244090: train loss : -0.9351\n",
      "2022-11-27 21:59:52.249436: validation loss: -0.8418\n",
      "2022-11-27 21:59:52.249772: Average global foreground Dice: [0.8982, 0.8798]\n",
      "2022-11-27 21:59:52.249827: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 21:59:52.614030: lr: 0.001976\n",
      "2022-11-27 21:59:52.614138: This epoch took 15.618957 s\n",
      "\n",
      "2022-11-27 21:59:52.614166: \n",
      "epoch:  835\n",
      "2022-11-27 22:00:06.888013: train loss : -0.9341\n",
      "2022-11-27 22:00:07.872312: validation loss: -0.8407\n",
      "2022-11-27 22:00:07.872684: Average global foreground Dice: [0.896, 0.8804]\n",
      "2022-11-27 22:00:07.872760: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:00:08.239619: lr: 0.001965\n",
      "2022-11-27 22:00:08.239731: This epoch took 15.625538 s\n",
      "\n",
      "2022-11-27 22:00:08.239761: \n",
      "epoch:  836\n",
      "2022-11-27 22:00:22.485933: train loss : -0.9362\n",
      "2022-11-27 22:00:23.487426: validation loss: -0.8425\n",
      "2022-11-27 22:00:23.487761: Average global foreground Dice: [0.8978, 0.8823]\n",
      "2022-11-27 22:00:23.487817: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:00:23.852306: lr: 0.001954\n",
      "2022-11-27 22:00:23.852418: This epoch took 15.612631 s\n",
      "\n",
      "2022-11-27 22:00:23.852463: \n",
      "epoch:  837\n",
      "2022-11-27 22:00:38.158362: train loss : -0.9355\n",
      "2022-11-27 22:00:39.184251: validation loss: -0.8379\n",
      "2022-11-27 22:00:39.184574: Average global foreground Dice: [0.8952, 0.878]\n",
      "2022-11-27 22:00:39.184633: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:00:39.546454: lr: 0.001943\n",
      "2022-11-27 22:00:39.546561: This epoch took 15.694070 s\n",
      "\n",
      "2022-11-27 22:00:39.546589: \n",
      "epoch:  838\n",
      "2022-11-27 22:00:53.885972: train loss : -0.9350\n",
      "2022-11-27 22:00:54.873444: validation loss: -0.8332\n",
      "2022-11-27 22:00:54.873873: Average global foreground Dice: [0.8919, 0.8761]\n",
      "2022-11-27 22:00:54.874108: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:00:55.242511: lr: 0.001933\n",
      "2022-11-27 22:00:55.242618: This epoch took 15.696003 s\n",
      "\n",
      "2022-11-27 22:00:55.242646: \n",
      "epoch:  839\n",
      "2022-11-27 22:01:09.510315: train loss : -0.9350\n",
      "2022-11-27 22:01:10.518958: validation loss: -0.8396\n",
      "2022-11-27 22:01:10.519342: Average global foreground Dice: [0.8969, 0.88]\n",
      "2022-11-27 22:01:10.519399: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:01:10.885264: lr: 0.001922\n",
      "2022-11-27 22:01:10.885388: This epoch took 15.642700 s\n",
      "\n",
      "2022-11-27 22:01:10.885418: \n",
      "epoch:  840\n",
      "2022-11-27 22:01:25.161721: train loss : -0.9330\n",
      "2022-11-27 22:01:26.158232: validation loss: -0.8323\n",
      "2022-11-27 22:01:26.158615: Average global foreground Dice: [0.8914, 0.876]\n",
      "2022-11-27 22:01:26.158700: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:01:26.540286: lr: 0.001911\n",
      "2022-11-27 22:01:26.540395: This epoch took 15.654951 s\n",
      "\n",
      "2022-11-27 22:01:26.540423: \n",
      "epoch:  841\n",
      "2022-11-27 22:01:40.827235: train loss : -0.9360\n",
      "2022-11-27 22:01:41.819844: validation loss: -0.8368\n",
      "2022-11-27 22:01:41.820180: Average global foreground Dice: [0.8944, 0.8792]\n",
      "2022-11-27 22:01:41.820240: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:01:42.293703: lr: 0.0019\n",
      "2022-11-27 22:01:42.293830: This epoch took 15.753366 s\n",
      "\n",
      "2022-11-27 22:01:42.293861: \n",
      "epoch:  842\n",
      "2022-11-27 22:01:56.600912: train loss : -0.9350\n",
      "2022-11-27 22:01:57.588645: validation loss: -0.8314\n",
      "2022-11-27 22:01:57.588979: Average global foreground Dice: [0.8894, 0.8745]\n",
      "2022-11-27 22:01:57.589037: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:01:57.966867: lr: 0.001889\n",
      "2022-11-27 22:01:57.967000: This epoch took 15.673111 s\n",
      "\n",
      "2022-11-27 22:01:57.967029: \n",
      "epoch:  843\n",
      "2022-11-27 22:02:12.251284: train loss : -0.9361\n",
      "2022-11-27 22:02:13.270503: validation loss: -0.8373\n",
      "2022-11-27 22:02:13.270876: Average global foreground Dice: [0.8954, 0.8784]\n",
      "2022-11-27 22:02:13.270938: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:02:13.655247: lr: 0.001879\n",
      "2022-11-27 22:02:13.655373: This epoch took 15.688301 s\n",
      "\n",
      "2022-11-27 22:02:13.655403: \n",
      "epoch:  844\n",
      "2022-11-27 22:02:27.941658: train loss : -0.9355\n",
      "2022-11-27 22:02:28.957598: validation loss: -0.8372\n",
      "2022-11-27 22:02:28.958116: Average global foreground Dice: [0.8939, 0.8798]\n",
      "2022-11-27 22:02:28.958210: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:02:29.321949: lr: 0.001868\n",
      "2022-11-27 22:02:29.322067: This epoch took 15.666636 s\n",
      "\n",
      "2022-11-27 22:02:29.322107: \n",
      "epoch:  845\n",
      "2022-11-27 22:02:43.615230: train loss : -0.9355\n",
      "2022-11-27 22:02:44.604628: validation loss: -0.8403\n",
      "2022-11-27 22:02:44.604984: Average global foreground Dice: [0.8962, 0.8801]\n",
      "2022-11-27 22:02:44.605085: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:02:44.968848: lr: 0.001857\n",
      "2022-11-27 22:02:44.968967: This epoch took 15.646832 s\n",
      "\n",
      "2022-11-27 22:02:44.969001: \n",
      "epoch:  846\n",
      "2022-11-27 22:02:59.290644: train loss : -0.9354\n",
      "2022-11-27 22:03:00.324227: validation loss: -0.8345\n",
      "2022-11-27 22:03:00.324603: Average global foreground Dice: [0.8936, 0.8774]\n",
      "2022-11-27 22:03:00.324693: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:03:00.684293: lr: 0.001846\n",
      "2022-11-27 22:03:00.684402: This epoch took 15.715359 s\n",
      "\n",
      "2022-11-27 22:03:00.684432: \n",
      "epoch:  847\n",
      "2022-11-27 22:03:14.950057: train loss : -0.9366\n",
      "2022-11-27 22:03:15.958480: validation loss: -0.8373\n",
      "2022-11-27 22:03:15.958828: Average global foreground Dice: [0.8933, 0.8775]\n",
      "2022-11-27 22:03:15.958890: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:03:16.319986: lr: 0.001835\n",
      "2022-11-27 22:03:16.320096: This epoch took 15.635638 s\n",
      "\n",
      "2022-11-27 22:03:16.320144: \n",
      "epoch:  848\n",
      "2022-11-27 22:03:30.562236: train loss : -0.9340\n",
      "2022-11-27 22:03:31.565062: validation loss: -0.8381\n",
      "2022-11-27 22:03:31.565444: Average global foreground Dice: [0.8953, 0.8781]\n",
      "2022-11-27 22:03:31.565504: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:03:31.942416: lr: 0.001824\n",
      "2022-11-27 22:03:31.942552: This epoch took 15.622376 s\n",
      "\n",
      "2022-11-27 22:03:31.942581: \n",
      "epoch:  849\n",
      "2022-11-27 22:03:46.156935: train loss : -0.9353\n",
      "2022-11-27 22:03:47.169649: validation loss: -0.8367\n",
      "2022-11-27 22:03:47.170065: Average global foreground Dice: [0.8955, 0.8802]\n",
      "2022-11-27 22:03:47.170171: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:03:47.554025: lr: 0.001813\n",
      "2022-11-27 22:03:47.554124: saving scheduled checkpoint file...\n",
      "2022-11-27 22:03:47.558359: saving checkpoint...\n",
      "2022-11-27 22:03:47.627838: done, saving took 0.07 seconds\n",
      "2022-11-27 22:03:47.632840: done\n",
      "2022-11-27 22:03:47.633015: This epoch took 15.690404 s\n",
      "\n",
      "2022-11-27 22:03:47.633103: \n",
      "epoch:  850\n",
      "2022-11-27 22:04:01.893720: train loss : -0.9346\n",
      "2022-11-27 22:04:02.896866: validation loss: -0.8369\n",
      "2022-11-27 22:04:02.897258: Average global foreground Dice: [0.8949, 0.8791]\n",
      "2022-11-27 22:04:02.897322: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:04:03.279111: lr: 0.001802\n",
      "2022-11-27 22:04:03.279219: This epoch took 15.646034 s\n",
      "\n",
      "2022-11-27 22:04:03.279249: \n",
      "epoch:  851\n",
      "2022-11-27 22:04:17.528890: train loss : -0.9352\n",
      "2022-11-27 22:04:18.526385: validation loss: -0.8327\n",
      "2022-11-27 22:04:18.526898: Average global foreground Dice: [0.8918, 0.8752]\n",
      "2022-11-27 22:04:18.527035: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:04:19.010413: lr: 0.001792\n",
      "2022-11-27 22:04:19.010530: This epoch took 15.731253 s\n",
      "\n",
      "2022-11-27 22:04:19.010560: \n",
      "epoch:  852\n",
      "2022-11-27 22:04:33.320180: train loss : -0.9360\n",
      "2022-11-27 22:04:34.354957: validation loss: -0.8370\n",
      "2022-11-27 22:04:34.355285: Average global foreground Dice: [0.8949, 0.8784]\n",
      "2022-11-27 22:04:34.355343: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 22:04:34.731534: lr: 0.001781\n",
      "2022-11-27 22:04:34.731662: This epoch took 15.721061 s\n",
      "\n",
      "2022-11-27 22:04:34.731695: \n",
      "epoch:  853\n",
      "2022-11-27 22:04:49.049738: train loss : -0.9352\n",
      "2022-11-27 22:04:50.102279: validation loss: -0.8366\n",
      "2022-11-27 22:04:50.102612: Average global foreground Dice: [0.8928, 0.8783]\n",
      "2022-11-27 22:04:50.102668: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:04:50.496057: lr: 0.00177\n",
      "2022-11-27 22:04:50.496172: This epoch took 15.764451 s\n",
      "\n",
      "2022-11-27 22:04:50.496205: \n",
      "epoch:  854\n",
      "2022-11-27 22:05:04.803359: train loss : -0.9356\n",
      "2022-11-27 22:05:05.791710: validation loss: -0.8352\n",
      "2022-11-27 22:05:05.792046: Average global foreground Dice: [0.8938, 0.8776]\n",
      "2022-11-27 22:05:05.792105: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:05:06.175553: lr: 0.001759\n",
      "2022-11-27 22:05:06.175678: This epoch took 15.679430 s\n",
      "\n",
      "2022-11-27 22:05:06.175711: \n",
      "epoch:  855\n",
      "2022-11-27 22:05:20.458980: train loss : -0.9364\n",
      "2022-11-27 22:05:21.437231: validation loss: -0.8369\n",
      "2022-11-27 22:05:21.437560: Average global foreground Dice: [0.8948, 0.8787]\n",
      "2022-11-27 22:05:21.437615: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:05:21.869777: lr: 0.001748\n",
      "2022-11-27 22:05:21.869885: This epoch took 15.694140 s\n",
      "\n",
      "2022-11-27 22:05:21.869922: \n",
      "epoch:  856\n",
      "2022-11-27 22:05:36.206436: train loss : -0.9363\n",
      "2022-11-27 22:05:37.202380: validation loss: -0.8372\n",
      "2022-11-27 22:05:37.202801: Average global foreground Dice: [0.8954, 0.8776]\n",
      "2022-11-27 22:05:37.202874: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:05:37.566888: lr: 0.001737\n",
      "2022-11-27 22:05:37.566998: This epoch took 15.697049 s\n",
      "\n",
      "2022-11-27 22:05:37.567029: \n",
      "epoch:  857\n",
      "2022-11-27 22:05:51.825002: train loss : -0.9358\n",
      "2022-11-27 22:05:52.809319: validation loss: -0.8307\n",
      "2022-11-27 22:05:52.809696: Average global foreground Dice: [0.8921, 0.8747]\n",
      "2022-11-27 22:05:52.809786: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:05:53.172330: lr: 0.001726\n",
      "2022-11-27 22:05:53.172451: This epoch took 15.605379 s\n",
      "\n",
      "2022-11-27 22:05:53.172483: \n",
      "epoch:  858\n",
      "2022-11-27 22:06:07.437933: train loss : -0.9363\n",
      "2022-11-27 22:06:08.429580: validation loss: -0.8418\n",
      "2022-11-27 22:06:08.429925: Average global foreground Dice: [0.8979, 0.8812]\n",
      "2022-11-27 22:06:08.429986: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:06:08.790316: lr: 0.001715\n",
      "2022-11-27 22:06:08.790429: This epoch took 15.617919 s\n",
      "\n",
      "2022-11-27 22:06:08.790458: \n",
      "epoch:  859\n",
      "2022-11-27 22:06:23.130493: train loss : -0.9350\n",
      "2022-11-27 22:06:24.124442: validation loss: -0.8395\n",
      "2022-11-27 22:06:24.124810: Average global foreground Dice: [0.8957, 0.8786]\n",
      "2022-11-27 22:06:24.125132: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:06:24.492878: lr: 0.001704\n",
      "2022-11-27 22:06:24.492996: This epoch took 15.702511 s\n",
      "\n",
      "2022-11-27 22:06:24.493022: \n",
      "epoch:  860\n",
      "2022-11-27 22:06:38.751629: train loss : -0.9376\n",
      "2022-11-27 22:06:39.772255: validation loss: -0.8384\n",
      "2022-11-27 22:06:39.772634: Average global foreground Dice: [0.8949, 0.8801]\n",
      "2022-11-27 22:06:39.772694: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:06:40.137684: lr: 0.001693\n",
      "2022-11-27 22:06:40.137788: This epoch took 15.644741 s\n",
      "\n",
      "2022-11-27 22:06:40.137818: \n",
      "epoch:  861\n",
      "2022-11-27 22:06:54.437966: train loss : -0.9366\n",
      "2022-11-27 22:06:55.443912: validation loss: -0.8365\n",
      "2022-11-27 22:06:55.444300: Average global foreground Dice: [0.8943, 0.878]\n",
      "2022-11-27 22:06:55.444357: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:06:55.809872: lr: 0.001682\n",
      "2022-11-27 22:06:55.809983: This epoch took 15.672138 s\n",
      "\n",
      "2022-11-27 22:06:55.810014: \n",
      "epoch:  862\n",
      "2022-11-27 22:07:10.118399: train loss : -0.9351\n",
      "2022-11-27 22:07:11.114172: validation loss: -0.8388\n",
      "2022-11-27 22:07:11.114568: Average global foreground Dice: [0.895, 0.8797]\n",
      "2022-11-27 22:07:11.114785: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:07:11.637698: lr: 0.001671\n",
      "2022-11-27 22:07:11.637901: This epoch took 15.827855 s\n",
      "\n",
      "2022-11-27 22:07:11.637934: \n",
      "epoch:  863\n",
      "2022-11-27 22:07:25.911727: train loss : -0.9357\n",
      "2022-11-27 22:07:26.922420: validation loss: -0.8349\n",
      "2022-11-27 22:07:26.922797: Average global foreground Dice: [0.894, 0.8765]\n",
      "2022-11-27 22:07:26.922890: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:07:27.283707: lr: 0.00166\n",
      "2022-11-27 22:07:27.283832: This epoch took 15.645856 s\n",
      "\n",
      "2022-11-27 22:07:27.283863: \n",
      "epoch:  864\n",
      "2022-11-27 22:07:41.572904: train loss : -0.9364\n",
      "2022-11-27 22:07:42.565374: validation loss: -0.8379\n",
      "2022-11-27 22:07:42.565716: Average global foreground Dice: [0.8951, 0.8808]\n",
      "2022-11-27 22:07:42.565773: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:07:42.936842: lr: 0.001649\n",
      "2022-11-27 22:07:42.937064: This epoch took 15.653166 s\n",
      "\n",
      "2022-11-27 22:07:42.937099: \n",
      "epoch:  865\n",
      "2022-11-27 22:07:57.226778: train loss : -0.9364\n",
      "2022-11-27 22:07:58.226164: validation loss: -0.8383\n",
      "2022-11-27 22:07:58.226500: Average global foreground Dice: [0.8967, 0.88]\n",
      "2022-11-27 22:07:58.226559: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:07:58.589005: lr: 0.001638\n",
      "2022-11-27 22:07:58.589113: This epoch took 15.651983 s\n",
      "\n",
      "2022-11-27 22:07:58.589141: \n",
      "epoch:  866\n",
      "2022-11-27 22:08:12.884341: train loss : -0.9348\n",
      "2022-11-27 22:08:13.897949: validation loss: -0.8381\n",
      "2022-11-27 22:08:13.898343: Average global foreground Dice: [0.8929, 0.88]\n",
      "2022-11-27 22:08:13.898411: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:08:14.270825: lr: 0.001627\n",
      "2022-11-27 22:08:14.270934: This epoch took 15.681766 s\n",
      "\n",
      "2022-11-27 22:08:14.270963: \n",
      "epoch:  867\n",
      "2022-11-27 22:08:28.563290: train loss : -0.9371\n",
      "2022-11-27 22:08:29.561332: validation loss: -0.8312\n",
      "2022-11-27 22:08:29.561675: Average global foreground Dice: [0.8908, 0.8744]\n",
      "2022-11-27 22:08:29.561731: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:08:29.945187: lr: 0.001616\n",
      "2022-11-27 22:08:29.945311: This epoch took 15.674305 s\n",
      "\n",
      "2022-11-27 22:08:29.945341: \n",
      "epoch:  868\n",
      "2022-11-27 22:08:44.243353: train loss : -0.9378\n",
      "2022-11-27 22:08:45.237531: validation loss: -0.8354\n",
      "2022-11-27 22:08:45.237926: Average global foreground Dice: [0.8935, 0.8786]\n",
      "2022-11-27 22:08:45.237984: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:08:45.598040: lr: 0.001605\n",
      "2022-11-27 22:08:45.598150: This epoch took 15.652777 s\n",
      "\n",
      "2022-11-27 22:08:45.598180: \n",
      "epoch:  869\n",
      "2022-11-27 22:08:59.866733: train loss : -0.9374\n",
      "2022-11-27 22:09:00.897335: validation loss: -0.8335\n",
      "2022-11-27 22:09:00.897939: Average global foreground Dice: [0.8919, 0.8739]\n",
      "2022-11-27 22:09:00.898043: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:09:01.268014: lr: 0.001594\n",
      "2022-11-27 22:09:01.268138: This epoch took 15.669931 s\n",
      "\n",
      "2022-11-27 22:09:01.268167: \n",
      "epoch:  870\n",
      "2022-11-27 22:09:15.547974: train loss : -0.9355\n",
      "2022-11-27 22:09:16.556175: validation loss: -0.8375\n",
      "2022-11-27 22:09:16.556504: Average global foreground Dice: [0.8964, 0.8808]\n",
      "2022-11-27 22:09:16.556559: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:09:16.918867: lr: 0.001583\n",
      "2022-11-27 22:09:16.918976: This epoch took 15.650783 s\n",
      "\n",
      "2022-11-27 22:09:16.919004: \n",
      "epoch:  871\n",
      "2022-11-27 22:09:31.203583: train loss : -0.9379\n",
      "2022-11-27 22:09:32.182617: validation loss: -0.8334\n",
      "2022-11-27 22:09:32.182962: Average global foreground Dice: [0.8914, 0.8767]\n",
      "2022-11-27 22:09:32.183031: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 22:09:32.568824: lr: 0.001572\n",
      "2022-11-27 22:09:32.568936: This epoch took 15.649904 s\n",
      "\n",
      "2022-11-27 22:09:32.568966: \n",
      "epoch:  872\n",
      "2022-11-27 22:09:46.866602: train loss : -0.9375\n",
      "2022-11-27 22:09:47.916507: validation loss: -0.8342\n",
      "2022-11-27 22:09:47.917012: Average global foreground Dice: [0.8934, 0.8768]\n",
      "2022-11-27 22:09:47.917112: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:09:48.291547: lr: 0.001561\n",
      "2022-11-27 22:09:48.291667: This epoch took 15.722659 s\n",
      "\n",
      "2022-11-27 22:09:48.291696: \n",
      "epoch:  873\n",
      "2022-11-27 22:10:02.630678: train loss : -0.9367\n",
      "2022-11-27 22:10:03.659115: validation loss: -0.8356\n",
      "2022-11-27 22:10:03.659465: Average global foreground Dice: [0.8939, 0.8802]\n",
      "2022-11-27 22:10:03.659523: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:10:04.134551: lr: 0.00155\n",
      "2022-11-27 22:10:04.134666: This epoch took 15.842943 s\n",
      "\n",
      "2022-11-27 22:10:04.134697: \n",
      "epoch:  874\n",
      "2022-11-27 22:10:18.434723: train loss : -0.9359\n",
      "2022-11-27 22:10:19.428480: validation loss: -0.8340\n",
      "2022-11-27 22:10:19.428858: Average global foreground Dice: [0.8916, 0.8777]\n",
      "2022-11-27 22:10:19.428919: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:10:19.796612: lr: 0.001539\n",
      "2022-11-27 22:10:19.796722: This epoch took 15.661999 s\n",
      "\n",
      "2022-11-27 22:10:19.796751: \n",
      "epoch:  875\n",
      "2022-11-27 22:10:34.050886: train loss : -0.9356\n",
      "2022-11-27 22:10:35.054578: validation loss: -0.8342\n",
      "2022-11-27 22:10:35.055097: Average global foreground Dice: [0.8924, 0.8779]\n",
      "2022-11-27 22:10:35.055213: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:10:35.426084: lr: 0.001528\n",
      "2022-11-27 22:10:35.426201: This epoch took 15.629421 s\n",
      "\n",
      "2022-11-27 22:10:35.426243: \n",
      "epoch:  876\n",
      "2022-11-27 22:10:49.716850: train loss : -0.9347\n",
      "2022-11-27 22:10:50.727635: validation loss: -0.8335\n",
      "2022-11-27 22:10:50.728016: Average global foreground Dice: [0.8937, 0.8764]\n",
      "2022-11-27 22:10:50.728071: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:10:51.112525: lr: 0.001517\n",
      "2022-11-27 22:10:51.112636: This epoch took 15.686364 s\n",
      "\n",
      "2022-11-27 22:10:51.112666: \n",
      "epoch:  877\n",
      "2022-11-27 22:11:05.395817: train loss : -0.9364\n",
      "2022-11-27 22:11:06.416871: validation loss: -0.8283\n",
      "2022-11-27 22:11:06.417202: Average global foreground Dice: [0.89, 0.8719]\n",
      "2022-11-27 22:11:06.417258: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:11:06.785421: lr: 0.001506\n",
      "2022-11-27 22:11:06.785532: This epoch took 15.672840 s\n",
      "\n",
      "2022-11-27 22:11:06.785562: \n",
      "epoch:  878\n",
      "2022-11-27 22:11:21.052625: train loss : -0.9376\n",
      "2022-11-27 22:11:22.061728: validation loss: -0.8372\n",
      "2022-11-27 22:11:22.062078: Average global foreground Dice: [0.8963, 0.879]\n",
      "2022-11-27 22:11:22.062150: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:11:22.425093: lr: 0.001495\n",
      "2022-11-27 22:11:22.425204: This epoch took 15.639615 s\n",
      "\n",
      "2022-11-27 22:11:22.425232: \n",
      "epoch:  879\n",
      "2022-11-27 22:11:36.679869: train loss : -0.9369\n",
      "2022-11-27 22:11:37.695354: validation loss: -0.8281\n",
      "2022-11-27 22:11:37.695692: Average global foreground Dice: [0.8896, 0.8735]\n",
      "2022-11-27 22:11:37.695750: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:11:38.058473: lr: 0.001483\n",
      "2022-11-27 22:11:38.058593: This epoch took 15.633319 s\n",
      "\n",
      "2022-11-27 22:11:38.058622: \n",
      "epoch:  880\n",
      "2022-11-27 22:11:52.378140: train loss : -0.9374\n",
      "2022-11-27 22:11:53.364275: validation loss: -0.8320\n",
      "2022-11-27 22:11:53.364658: Average global foreground Dice: [0.8912, 0.8752]\n",
      "2022-11-27 22:11:53.364716: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:11:53.729444: lr: 0.001472\n",
      "2022-11-27 22:11:53.729565: This epoch took 15.670901 s\n",
      "\n",
      "2022-11-27 22:11:53.729595: \n",
      "epoch:  881\n",
      "2022-11-27 22:12:07.976224: train loss : -0.9374\n",
      "2022-11-27 22:12:08.996176: validation loss: -0.8384\n",
      "2022-11-27 22:12:08.996624: Average global foreground Dice: [0.8941, 0.8798]\n",
      "2022-11-27 22:12:08.996705: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:12:09.409829: lr: 0.001461\n",
      "2022-11-27 22:12:09.409957: This epoch took 15.680336 s\n",
      "\n",
      "2022-11-27 22:12:09.409986: \n",
      "epoch:  882\n",
      "2022-11-27 22:12:23.742707: train loss : -0.9371\n",
      "2022-11-27 22:12:24.734779: validation loss: -0.8340\n",
      "2022-11-27 22:12:24.735167: Average global foreground Dice: [0.8916, 0.8764]\n",
      "2022-11-27 22:12:24.735224: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:12:25.099477: lr: 0.00145\n",
      "2022-11-27 22:12:25.099581: This epoch took 15.689568 s\n",
      "\n",
      "2022-11-27 22:12:25.099609: \n",
      "epoch:  883\n",
      "2022-11-27 22:12:39.345119: train loss : -0.9376\n",
      "2022-11-27 22:12:40.322881: validation loss: -0.8370\n",
      "2022-11-27 22:12:40.323266: Average global foreground Dice: [0.894, 0.8761]\n",
      "2022-11-27 22:12:40.323323: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:12:40.799850: lr: 0.001439\n",
      "2022-11-27 22:12:40.799979: This epoch took 15.700327 s\n",
      "\n",
      "2022-11-27 22:12:40.800010: \n",
      "epoch:  884\n",
      "2022-11-27 22:12:55.148698: train loss : -0.9372\n",
      "2022-11-27 22:12:56.137821: validation loss: -0.8287\n",
      "2022-11-27 22:12:56.138233: Average global foreground Dice: [0.8901, 0.8751]\n",
      "2022-11-27 22:12:56.138319: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:12:56.499239: lr: 0.001428\n",
      "2022-11-27 22:12:56.499347: This epoch took 15.699311 s\n",
      "\n",
      "2022-11-27 22:12:56.499373: \n",
      "epoch:  885\n",
      "2022-11-27 22:13:10.791175: train loss : -0.9378\n",
      "2022-11-27 22:13:11.809407: validation loss: -0.8338\n",
      "2022-11-27 22:13:11.809781: Average global foreground Dice: [0.8927, 0.878]\n",
      "2022-11-27 22:13:11.809840: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:13:12.177649: lr: 0.001416\n",
      "2022-11-27 22:13:12.177840: This epoch took 15.678442 s\n",
      "\n",
      "2022-11-27 22:13:12.177869: \n",
      "epoch:  886\n",
      "2022-11-27 22:13:26.413316: train loss : -0.9367\n",
      "2022-11-27 22:13:27.412013: validation loss: -0.8303\n",
      "2022-11-27 22:13:27.412393: Average global foreground Dice: [0.891, 0.8745]\n",
      "2022-11-27 22:13:27.412453: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:13:27.776976: lr: 0.001405\n",
      "2022-11-27 22:13:27.777097: This epoch took 15.599185 s\n",
      "\n",
      "2022-11-27 22:13:27.777127: \n",
      "epoch:  887\n",
      "2022-11-27 22:13:42.121865: train loss : -0.9374\n",
      "2022-11-27 22:13:43.159530: validation loss: -0.8393\n",
      "2022-11-27 22:13:43.159879: Average global foreground Dice: [0.8958, 0.882]\n",
      "2022-11-27 22:13:43.159934: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:13:43.557580: lr: 0.001394\n",
      "2022-11-27 22:13:43.557690: This epoch took 15.780512 s\n",
      "\n",
      "2022-11-27 22:13:43.557720: \n",
      "epoch:  888\n",
      "2022-11-27 22:13:57.824929: train loss : -0.9376\n",
      "2022-11-27 22:13:58.847902: validation loss: -0.8350\n",
      "2022-11-27 22:13:58.848244: Average global foreground Dice: [0.8939, 0.8778]\n",
      "2022-11-27 22:13:58.848300: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:13:59.212132: lr: 0.001383\n",
      "2022-11-27 22:13:59.212243: This epoch took 15.654496 s\n",
      "\n",
      "2022-11-27 22:13:59.212270: \n",
      "epoch:  889\n",
      "2022-11-27 22:14:13.484774: train loss : -0.9382\n",
      "2022-11-27 22:14:14.510234: validation loss: -0.8385\n",
      "2022-11-27 22:14:14.510670: Average global foreground Dice: [0.8969, 0.8809]\n",
      "2022-11-27 22:14:14.510875: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:14:14.888836: lr: 0.001372\n",
      "2022-11-27 22:14:14.888942: This epoch took 15.676647 s\n",
      "\n",
      "2022-11-27 22:14:14.888972: \n",
      "epoch:  890\n",
      "2022-11-27 22:14:29.111053: train loss : -0.9369\n",
      "2022-11-27 22:14:30.123811: validation loss: -0.8358\n",
      "2022-11-27 22:14:30.124141: Average global foreground Dice: [0.8948, 0.879]\n",
      "2022-11-27 22:14:30.124196: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 22:14:30.515459: lr: 0.00136\n",
      "2022-11-27 22:14:30.515561: This epoch took 15.626563 s\n",
      "\n",
      "2022-11-27 22:14:30.515607: \n",
      "epoch:  891\n",
      "2022-11-27 22:14:44.794360: train loss : -0.9370\n",
      "2022-11-27 22:14:45.786783: validation loss: -0.8342\n",
      "2022-11-27 22:14:45.787117: Average global foreground Dice: [0.8942, 0.8781]\n",
      "2022-11-27 22:14:45.787172: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:14:46.150317: lr: 0.001349\n",
      "2022-11-27 22:14:46.150428: This epoch took 15.634788 s\n",
      "\n",
      "2022-11-27 22:14:46.150457: \n",
      "epoch:  892\n",
      "2022-11-27 22:15:00.445440: train loss : -0.9396\n",
      "2022-11-27 22:15:01.460131: validation loss: -0.8347\n",
      "2022-11-27 22:15:01.460559: Average global foreground Dice: [0.8939, 0.8785]\n",
      "2022-11-27 22:15:01.460624: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:15:01.834178: lr: 0.001338\n",
      "2022-11-27 22:15:01.834285: This epoch took 15.683802 s\n",
      "\n",
      "2022-11-27 22:15:01.834320: \n",
      "epoch:  893\n",
      "2022-11-27 22:15:16.172062: train loss : -0.9366\n",
      "2022-11-27 22:15:17.192110: validation loss: -0.8372\n",
      "2022-11-27 22:15:17.192455: Average global foreground Dice: [0.8959, 0.8767]\n",
      "2022-11-27 22:15:17.192511: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:15:17.556798: lr: 0.001327\n",
      "2022-11-27 22:15:17.556921: This epoch took 15.722570 s\n",
      "\n",
      "2022-11-27 22:15:17.556955: \n",
      "epoch:  894\n",
      "2022-11-27 22:15:31.821029: train loss : -0.9374\n",
      "2022-11-27 22:15:32.834353: validation loss: -0.8367\n",
      "2022-11-27 22:15:32.834848: Average global foreground Dice: [0.8953, 0.8807]\n",
      "2022-11-27 22:15:32.834967: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:15:33.333324: lr: 0.001315\n",
      "2022-11-27 22:15:33.333445: This epoch took 15.776460 s\n",
      "\n",
      "2022-11-27 22:15:33.333474: \n",
      "epoch:  895\n",
      "2022-11-27 22:15:47.647444: train loss : -0.9360\n",
      "2022-11-27 22:15:48.657946: validation loss: -0.8336\n",
      "2022-11-27 22:15:48.658322: Average global foreground Dice: [0.8936, 0.8754]\n",
      "2022-11-27 22:15:48.658379: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:15:49.025991: lr: 0.001304\n",
      "2022-11-27 22:15:49.026117: This epoch took 15.692617 s\n",
      "\n",
      "2022-11-27 22:15:49.026157: \n",
      "epoch:  896\n",
      "2022-11-27 22:16:03.300789: train loss : -0.9374\n",
      "2022-11-27 22:16:04.312291: validation loss: -0.8361\n",
      "2022-11-27 22:16:04.312622: Average global foreground Dice: [0.8943, 0.8778]\n",
      "2022-11-27 22:16:04.312682: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:16:04.673955: lr: 0.001293\n",
      "2022-11-27 22:16:04.674068: This epoch took 15.647884 s\n",
      "\n",
      "2022-11-27 22:16:04.674098: \n",
      "epoch:  897\n",
      "2022-11-27 22:16:18.985452: train loss : -0.9363\n",
      "2022-11-27 22:16:20.004499: validation loss: -0.8387\n",
      "2022-11-27 22:16:20.004928: Average global foreground Dice: [0.8961, 0.8798]\n",
      "2022-11-27 22:16:20.005108: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:16:20.396399: lr: 0.001282\n",
      "2022-11-27 22:16:20.396531: This epoch took 15.722391 s\n",
      "\n",
      "2022-11-27 22:16:20.396562: \n",
      "epoch:  898\n",
      "2022-11-27 22:16:34.682921: train loss : -0.9369\n",
      "2022-11-27 22:16:35.688456: validation loss: -0.8287\n",
      "2022-11-27 22:16:35.688843: Average global foreground Dice: [0.891, 0.8725]\n",
      "2022-11-27 22:16:35.688901: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:16:36.052226: lr: 0.00127\n",
      "2022-11-27 22:16:36.052335: This epoch took 15.655745 s\n",
      "\n",
      "2022-11-27 22:16:36.052361: \n",
      "epoch:  899\n",
      "2022-11-27 22:16:50.334949: train loss : -0.9370\n",
      "2022-11-27 22:16:51.346240: validation loss: -0.8396\n",
      "2022-11-27 22:16:51.346596: Average global foreground Dice: [0.8956, 0.8801]\n",
      "2022-11-27 22:16:51.346651: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:16:51.735296: lr: 0.001259\n",
      "2022-11-27 22:16:51.735396: saving scheduled checkpoint file...\n",
      "2022-11-27 22:16:51.739335: saving checkpoint...\n",
      "2022-11-27 22:16:51.809953: done, saving took 0.07 seconds\n",
      "2022-11-27 22:16:51.811931: done\n",
      "2022-11-27 22:16:51.812004: This epoch took 15.759619 s\n",
      "\n",
      "2022-11-27 22:16:51.812033: \n",
      "epoch:  900\n",
      "2022-11-27 22:17:06.060131: train loss : -0.9366\n",
      "2022-11-27 22:17:07.066536: validation loss: -0.8365\n",
      "2022-11-27 22:17:07.067005: Average global foreground Dice: [0.8962, 0.8804]\n",
      "2022-11-27 22:17:07.067091: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:17:07.430663: lr: 0.001248\n",
      "2022-11-27 22:17:07.430771: This epoch took 15.618703 s\n",
      "\n",
      "2022-11-27 22:17:07.430815: \n",
      "epoch:  901\n",
      "2022-11-27 22:17:21.733480: train loss : -0.9373\n",
      "2022-11-27 22:17:22.762123: validation loss: -0.8415\n",
      "2022-11-27 22:17:22.762413: Average global foreground Dice: [0.8971, 0.8804]\n",
      "2022-11-27 22:17:22.762465: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:17:23.148975: lr: 0.001236\n",
      "2022-11-27 22:17:23.149087: This epoch took 15.718245 s\n",
      "\n",
      "2022-11-27 22:17:23.149117: \n",
      "epoch:  902\n",
      "2022-11-27 22:17:37.435297: train loss : -0.9381\n",
      "2022-11-27 22:17:38.472763: validation loss: -0.8308\n",
      "2022-11-27 22:17:38.473140: Average global foreground Dice: [0.8925, 0.8747]\n",
      "2022-11-27 22:17:38.473197: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:17:38.848456: lr: 0.001225\n",
      "2022-11-27 22:17:38.848578: This epoch took 15.699419 s\n",
      "\n",
      "2022-11-27 22:17:38.848613: \n",
      "epoch:  903\n",
      "2022-11-27 22:17:53.137732: train loss : -0.9391\n",
      "2022-11-27 22:17:54.154611: validation loss: -0.8348\n",
      "2022-11-27 22:17:54.154951: Average global foreground Dice: [0.8946, 0.8782]\n",
      "2022-11-27 22:17:54.155007: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:17:54.519485: lr: 0.001214\n",
      "2022-11-27 22:17:54.519588: This epoch took 15.670942 s\n",
      "\n",
      "2022-11-27 22:17:54.519615: \n",
      "epoch:  904\n",
      "2022-11-27 22:18:08.856379: train loss : -0.9374\n",
      "2022-11-27 22:18:09.845591: validation loss: -0.8351\n",
      "2022-11-27 22:18:09.845962: Average global foreground Dice: [0.8932, 0.8776]\n",
      "2022-11-27 22:18:09.846128: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:18:10.342034: lr: 0.001202\n",
      "2022-11-27 22:18:10.342149: This epoch took 15.822510 s\n",
      "\n",
      "2022-11-27 22:18:10.342177: \n",
      "epoch:  905\n",
      "2022-11-27 22:18:24.639736: train loss : -0.9371\n",
      "2022-11-27 22:18:25.626786: validation loss: -0.8348\n",
      "2022-11-27 22:18:25.627110: Average global foreground Dice: [0.8928, 0.8784]\n",
      "2022-11-27 22:18:25.627168: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:18:26.007424: lr: 0.001191\n",
      "2022-11-27 22:18:26.007540: This epoch took 15.665336 s\n",
      "\n",
      "2022-11-27 22:18:26.007565: \n",
      "epoch:  906\n",
      "2022-11-27 22:18:40.313930: train loss : -0.9379\n",
      "2022-11-27 22:18:41.332201: validation loss: -0.8351\n",
      "2022-11-27 22:18:41.332530: Average global foreground Dice: [0.895, 0.8792]\n",
      "2022-11-27 22:18:41.332589: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:18:41.695333: lr: 0.001179\n",
      "2022-11-27 22:18:41.695460: This epoch took 15.687855 s\n",
      "\n",
      "2022-11-27 22:18:41.695493: \n",
      "epoch:  907\n",
      "2022-11-27 22:18:56.005973: train loss : -0.9377\n",
      "2022-11-27 22:18:57.007646: validation loss: -0.8307\n",
      "2022-11-27 22:18:57.008038: Average global foreground Dice: [0.891, 0.8755]\n",
      "2022-11-27 22:18:57.008214: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:18:57.404254: lr: 0.001168\n",
      "2022-11-27 22:18:57.404367: This epoch took 15.708848 s\n",
      "\n",
      "2022-11-27 22:18:57.404396: \n",
      "epoch:  908\n",
      "2022-11-27 22:19:11.692331: train loss : -0.9385\n",
      "2022-11-27 22:19:12.702044: validation loss: -0.8350\n",
      "2022-11-27 22:19:12.702428: Average global foreground Dice: [0.8945, 0.8767]\n",
      "2022-11-27 22:19:12.702489: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:19:13.065993: lr: 0.001156\n",
      "2022-11-27 22:19:13.066104: This epoch took 15.661681 s\n",
      "\n",
      "2022-11-27 22:19:13.066134: \n",
      "epoch:  909\n",
      "2022-11-27 22:19:27.280324: train loss : -0.9392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 22:19:28.266115: validation loss: -0.8403\n",
      "2022-11-27 22:19:28.266451: Average global foreground Dice: [0.8969, 0.8826]\n",
      "2022-11-27 22:19:28.266509: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:19:28.653789: lr: 0.001145\n",
      "2022-11-27 22:19:28.653924: This epoch took 15.587762 s\n",
      "\n",
      "2022-11-27 22:19:28.653971: \n",
      "epoch:  910\n",
      "2022-11-27 22:19:42.939922: train loss : -0.9393\n",
      "2022-11-27 22:19:43.945879: validation loss: -0.8333\n",
      "2022-11-27 22:19:43.946435: Average global foreground Dice: [0.8931, 0.8767]\n",
      "2022-11-27 22:19:43.946714: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:19:44.358884: lr: 0.001134\n",
      "2022-11-27 22:19:44.358993: This epoch took 15.704991 s\n",
      "\n",
      "2022-11-27 22:19:44.359027: \n",
      "epoch:  911\n",
      "2022-11-27 22:19:58.652936: train loss : -0.9392\n",
      "2022-11-27 22:19:59.662161: validation loss: -0.8391\n",
      "2022-11-27 22:19:59.662491: Average global foreground Dice: [0.8942, 0.8809]\n",
      "2022-11-27 22:19:59.662552: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:20:00.027072: lr: 0.001122\n",
      "2022-11-27 22:20:00.027180: This epoch took 15.668123 s\n",
      "\n",
      "2022-11-27 22:20:00.027209: \n",
      "epoch:  912\n",
      "2022-11-27 22:20:14.272449: train loss : -0.9381\n",
      "2022-11-27 22:20:15.289613: validation loss: -0.8362\n",
      "2022-11-27 22:20:15.290008: Average global foreground Dice: [0.894, 0.8789]\n",
      "2022-11-27 22:20:15.290073: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:20:15.674793: lr: 0.001111\n",
      "2022-11-27 22:20:15.674905: This epoch took 15.647670 s\n",
      "\n",
      "2022-11-27 22:20:15.674940: \n",
      "epoch:  913\n",
      "2022-11-27 22:20:29.993751: train loss : -0.9399\n",
      "2022-11-27 22:20:30.983519: validation loss: -0.8354\n",
      "2022-11-27 22:20:30.983895: Average global foreground Dice: [0.893, 0.8798]\n",
      "2022-11-27 22:20:30.983952: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:20:31.348277: lr: 0.001099\n",
      "2022-11-27 22:20:31.348400: This epoch took 15.673415 s\n",
      "\n",
      "2022-11-27 22:20:31.348431: \n",
      "epoch:  914\n",
      "2022-11-27 22:20:45.657828: train loss : -0.9376\n",
      "2022-11-27 22:20:46.663998: validation loss: -0.8344\n",
      "2022-11-27 22:20:46.664336: Average global foreground Dice: [0.8936, 0.8769]\n",
      "2022-11-27 22:20:46.664392: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:20:47.028310: lr: 0.001088\n",
      "2022-11-27 22:20:47.028431: This epoch took 15.679958 s\n",
      "\n",
      "2022-11-27 22:20:47.028461: \n",
      "epoch:  915\n",
      "2022-11-27 22:21:01.285726: train loss : -0.9391\n",
      "2022-11-27 22:21:02.302791: validation loss: -0.8361\n",
      "2022-11-27 22:21:02.303298: Average global foreground Dice: [0.8942, 0.8773]\n",
      "2022-11-27 22:21:02.303432: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:21:02.803628: lr: 0.001076\n",
      "2022-11-27 22:21:02.803752: This epoch took 15.775265 s\n",
      "\n",
      "2022-11-27 22:21:02.803781: \n",
      "epoch:  916\n",
      "2022-11-27 22:21:17.080231: train loss : -0.9383\n",
      "2022-11-27 22:21:18.107365: validation loss: -0.8328\n",
      "2022-11-27 22:21:18.107703: Average global foreground Dice: [0.8918, 0.8749]\n",
      "2022-11-27 22:21:18.107759: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:21:18.472827: lr: 0.001065\n",
      "2022-11-27 22:21:18.472943: This epoch took 15.669135 s\n",
      "\n",
      "2022-11-27 22:21:18.472971: \n",
      "epoch:  917\n",
      "2022-11-27 22:21:32.796344: train loss : -0.9389\n",
      "2022-11-27 22:21:33.825166: validation loss: -0.8378\n",
      "2022-11-27 22:21:33.825491: Average global foreground Dice: [0.8951, 0.8773]\n",
      "2022-11-27 22:21:33.825554: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:21:34.209563: lr: 0.001053\n",
      "2022-11-27 22:21:34.209678: This epoch took 15.736681 s\n",
      "\n",
      "2022-11-27 22:21:34.209707: \n",
      "epoch:  918\n",
      "2022-11-27 22:21:48.452890: train loss : -0.9398\n",
      "2022-11-27 22:21:49.455886: validation loss: -0.8321\n",
      "2022-11-27 22:21:49.456214: Average global foreground Dice: [0.8917, 0.8756]\n",
      "2022-11-27 22:21:49.456273: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:21:49.822249: lr: 0.001041\n",
      "2022-11-27 22:21:49.822438: This epoch took 15.612703 s\n",
      "\n",
      "2022-11-27 22:21:49.822470: \n",
      "epoch:  919\n",
      "2022-11-27 22:22:04.080833: train loss : -0.9396\n",
      "2022-11-27 22:22:05.108812: validation loss: -0.8353\n",
      "2022-11-27 22:22:05.109151: Average global foreground Dice: [0.8959, 0.878]\n",
      "2022-11-27 22:22:05.109207: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:22:05.472364: lr: 0.00103\n",
      "2022-11-27 22:22:05.472486: This epoch took 15.649974 s\n",
      "\n",
      "2022-11-27 22:22:05.472515: \n",
      "epoch:  920\n",
      "2022-11-27 22:22:19.669159: train loss : -0.9380\n",
      "2022-11-27 22:22:20.690542: validation loss: -0.8341\n",
      "2022-11-27 22:22:20.690866: Average global foreground Dice: [0.8941, 0.8771]\n",
      "2022-11-27 22:22:20.690926: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:22:21.051970: lr: 0.001018\n",
      "2022-11-27 22:22:21.052075: This epoch took 15.579535 s\n",
      "\n",
      "2022-11-27 22:22:21.052102: \n",
      "epoch:  921\n",
      "2022-11-27 22:22:35.290768: train loss : -0.9401\n",
      "2022-11-27 22:22:36.287666: validation loss: -0.8412\n",
      "2022-11-27 22:22:36.288004: Average global foreground Dice: [0.8976, 0.8833]\n",
      "2022-11-27 22:22:36.288060: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:22:36.652794: lr: 0.001007\n",
      "2022-11-27 22:22:36.653014: This epoch took 15.600887 s\n",
      "\n",
      "2022-11-27 22:22:36.653044: \n",
      "epoch:  922\n",
      "2022-11-27 22:22:50.913943: train loss : -0.9394\n",
      "2022-11-27 22:22:51.928938: validation loss: -0.8324\n",
      "2022-11-27 22:22:51.929316: Average global foreground Dice: [0.8932, 0.8752]\n",
      "2022-11-27 22:22:51.929385: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:22:52.293796: lr: 0.000995\n",
      "2022-11-27 22:22:52.293912: This epoch took 15.640837 s\n",
      "\n",
      "2022-11-27 22:22:52.293945: \n",
      "epoch:  923\n",
      "2022-11-27 22:23:06.573754: train loss : -0.9389\n",
      "2022-11-27 22:23:07.588758: validation loss: -0.8347\n",
      "2022-11-27 22:23:07.589189: Average global foreground Dice: [0.893, 0.8795]\n",
      "2022-11-27 22:23:07.589291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:23:07.968642: lr: 0.000983\n",
      "2022-11-27 22:23:07.968751: This epoch took 15.674778 s\n",
      "\n",
      "2022-11-27 22:23:07.968784: \n",
      "epoch:  924\n",
      "2022-11-27 22:23:22.225273: train loss : -0.9375\n",
      "2022-11-27 22:23:23.247623: validation loss: -0.8397\n",
      "2022-11-27 22:23:23.247984: Average global foreground Dice: [0.897, 0.8832]\n",
      "2022-11-27 22:23:23.248077: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:23:23.635761: lr: 0.000972\n",
      "2022-11-27 22:23:23.635865: This epoch took 15.667053 s\n",
      "\n",
      "2022-11-27 22:23:23.635893: \n",
      "epoch:  925\n",
      "2022-11-27 22:23:37.876925: train loss : -0.9406\n",
      "2022-11-27 22:23:38.881952: validation loss: -0.8360\n",
      "2022-11-27 22:23:38.882297: Average global foreground Dice: [0.8941, 0.8797]\n",
      "2022-11-27 22:23:38.882354: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:23:39.361445: lr: 0.00096\n",
      "2022-11-27 22:23:39.361560: This epoch took 15.725641 s\n",
      "\n",
      "2022-11-27 22:23:39.361589: \n",
      "epoch:  926\n",
      "2022-11-27 22:23:53.621428: train loss : -0.9396\n",
      "2022-11-27 22:23:54.607115: validation loss: -0.8371\n",
      "2022-11-27 22:23:54.607505: Average global foreground Dice: [0.8961, 0.8805]\n",
      "2022-11-27 22:23:54.607567: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:23:54.974815: lr: 0.000948\n",
      "2022-11-27 22:23:54.974932: This epoch took 15.613316 s\n",
      "\n",
      "2022-11-27 22:23:54.974964: \n",
      "epoch:  927\n",
      "2022-11-27 22:24:09.223680: train loss : -0.9400\n",
      "2022-11-27 22:24:10.260815: validation loss: -0.8342\n",
      "2022-11-27 22:24:10.261142: Average global foreground Dice: [0.8944, 0.8781]\n",
      "2022-11-27 22:24:10.261198: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:24:10.636155: lr: 0.000937\n",
      "2022-11-27 22:24:10.636267: This epoch took 15.661272 s\n",
      "\n",
      "2022-11-27 22:24:10.636297: \n",
      "epoch:  928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 22:24:24.930384: train loss : -0.9385\n",
      "2022-11-27 22:24:25.922425: validation loss: -0.8298\n",
      "2022-11-27 22:24:25.922782: Average global foreground Dice: [0.8909, 0.874]\n",
      "2022-11-27 22:24:25.922878: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:24:26.288964: lr: 0.000925\n",
      "2022-11-27 22:24:26.289090: This epoch took 15.652766 s\n",
      "\n",
      "2022-11-27 22:24:26.289140: \n",
      "epoch:  929\n",
      "2022-11-27 22:24:40.546801: train loss : -0.9396\n",
      "2022-11-27 22:24:41.608630: validation loss: -0.8410\n",
      "2022-11-27 22:24:41.609087: Average global foreground Dice: [0.8988, 0.8835]\n",
      "2022-11-27 22:24:41.609280: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:24:41.980563: lr: 0.000913\n",
      "2022-11-27 22:24:41.980687: This epoch took 15.691504 s\n",
      "\n",
      "2022-11-27 22:24:41.980724: \n",
      "epoch:  930\n",
      "2022-11-27 22:24:56.292340: train loss : -0.9392\n",
      "2022-11-27 22:24:57.269736: validation loss: -0.8394\n",
      "2022-11-27 22:24:57.270104: Average global foreground Dice: [0.897, 0.8813]\n",
      "2022-11-27 22:24:57.270167: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:24:57.634457: lr: 0.000901\n",
      "2022-11-27 22:24:57.634563: This epoch took 15.653797 s\n",
      "\n",
      "2022-11-27 22:24:57.634591: \n",
      "epoch:  931\n",
      "2022-11-27 22:25:11.878644: train loss : -0.9391\n",
      "2022-11-27 22:25:12.878038: validation loss: -0.8381\n",
      "2022-11-27 22:25:12.878373: Average global foreground Dice: [0.8951, 0.8806]\n",
      "2022-11-27 22:25:12.878440: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:25:13.251533: lr: 0.00089\n",
      "2022-11-27 22:25:13.251657: This epoch took 15.617023 s\n",
      "\n",
      "2022-11-27 22:25:13.251689: \n",
      "epoch:  932\n",
      "2022-11-27 22:25:27.518967: train loss : -0.9416\n",
      "2022-11-27 22:25:28.534396: validation loss: -0.8313\n",
      "2022-11-27 22:25:28.534734: Average global foreground Dice: [0.8916, 0.8758]\n",
      "2022-11-27 22:25:28.534797: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:25:28.914954: lr: 0.000878\n",
      "2022-11-27 22:25:28.915059: This epoch took 15.663344 s\n",
      "\n",
      "2022-11-27 22:25:28.915088: \n",
      "epoch:  933\n",
      "2022-11-27 22:25:43.179481: train loss : -0.9400\n",
      "2022-11-27 22:25:44.178922: validation loss: -0.8354\n",
      "2022-11-27 22:25:44.179299: Average global foreground Dice: [0.8946, 0.8775]\n",
      "2022-11-27 22:25:44.179357: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:25:44.568429: lr: 0.000866\n",
      "2022-11-27 22:25:44.568539: This epoch took 15.653425 s\n",
      "\n",
      "2022-11-27 22:25:44.568568: \n",
      "epoch:  934\n",
      "2022-11-27 22:25:58.816250: train loss : -0.9398\n",
      "2022-11-27 22:25:59.818938: validation loss: -0.8425\n",
      "2022-11-27 22:25:59.819389: Average global foreground Dice: [0.8993, 0.8826]\n",
      "2022-11-27 22:25:59.819460: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:26:00.189467: lr: 0.000854\n",
      "2022-11-27 22:26:00.189574: This epoch took 15.620980 s\n",
      "\n",
      "2022-11-27 22:26:00.189601: \n",
      "epoch:  935\n",
      "2022-11-27 22:26:14.499045: train loss : -0.9402\n",
      "2022-11-27 22:26:15.499162: validation loss: -0.8367\n",
      "2022-11-27 22:26:15.499627: Average global foreground Dice: [0.8941, 0.881]\n",
      "2022-11-27 22:26:15.499700: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:26:15.869969: lr: 0.000842\n",
      "2022-11-27 22:26:15.870075: This epoch took 15.680449 s\n",
      "\n",
      "2022-11-27 22:26:15.870105: \n",
      "epoch:  936\n",
      "2022-11-27 22:26:30.128369: train loss : -0.9409\n",
      "2022-11-27 22:26:31.107811: validation loss: -0.8327\n",
      "2022-11-27 22:26:31.108278: Average global foreground Dice: [0.8929, 0.8763]\n",
      "2022-11-27 22:26:31.108381: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:26:31.597872: lr: 0.000831\n",
      "2022-11-27 22:26:31.598007: This epoch took 15.727860 s\n",
      "\n",
      "2022-11-27 22:26:31.598039: \n",
      "epoch:  937\n",
      "2022-11-27 22:26:45.903747: train loss : -0.9420\n",
      "2022-11-27 22:26:46.893383: validation loss: -0.8325\n",
      "2022-11-27 22:26:46.893713: Average global foreground Dice: [0.8929, 0.8771]\n",
      "2022-11-27 22:26:46.893770: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:26:47.270668: lr: 0.000819\n",
      "2022-11-27 22:26:47.270782: This epoch took 15.672715 s\n",
      "\n",
      "2022-11-27 22:26:47.270810: \n",
      "epoch:  938\n",
      "2022-11-27 22:27:01.543238: train loss : -0.9391\n",
      "2022-11-27 22:27:02.524104: validation loss: -0.8388\n",
      "2022-11-27 22:27:02.524482: Average global foreground Dice: [0.8956, 0.8812]\n",
      "2022-11-27 22:27:02.524541: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:27:02.893798: lr: 0.000807\n",
      "2022-11-27 22:27:02.893912: This epoch took 15.623075 s\n",
      "\n",
      "2022-11-27 22:27:02.893949: \n",
      "epoch:  939\n",
      "2022-11-27 22:27:17.143516: train loss : -0.9402\n",
      "2022-11-27 22:27:18.146437: validation loss: -0.8374\n",
      "2022-11-27 22:27:18.146772: Average global foreground Dice: [0.8956, 0.8809]\n",
      "2022-11-27 22:27:18.146825: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:27:18.511974: lr: 0.000795\n",
      "2022-11-27 22:27:18.512083: This epoch took 15.618103 s\n",
      "\n",
      "2022-11-27 22:27:18.512112: \n",
      "epoch:  940\n",
      "2022-11-27 22:27:32.810011: train loss : -0.9414\n",
      "2022-11-27 22:27:33.802885: validation loss: -0.8402\n",
      "2022-11-27 22:27:33.803216: Average global foreground Dice: [0.8973, 0.882]\n",
      "2022-11-27 22:27:33.803279: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:27:34.167158: lr: 0.000783\n",
      "2022-11-27 22:27:34.167266: This epoch took 15.655128 s\n",
      "\n",
      "2022-11-27 22:27:34.167295: \n",
      "epoch:  941\n",
      "2022-11-27 22:27:48.449603: train loss : -0.9408\n",
      "2022-11-27 22:27:49.486495: validation loss: -0.8311\n",
      "2022-11-27 22:27:49.486943: Average global foreground Dice: [0.8933, 0.8758]\n",
      "2022-11-27 22:27:49.487068: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:27:49.851558: lr: 0.000771\n",
      "2022-11-27 22:27:49.851679: This epoch took 15.684342 s\n",
      "\n",
      "2022-11-27 22:27:49.851711: \n",
      "epoch:  942\n",
      "2022-11-27 22:28:04.091273: train loss : -0.9410\n",
      "2022-11-27 22:28:05.110812: validation loss: -0.8346\n",
      "2022-11-27 22:28:05.111169: Average global foreground Dice: [0.8946, 0.8781]\n",
      "2022-11-27 22:28:05.111229: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:28:05.475564: lr: 0.000759\n",
      "2022-11-27 22:28:05.475673: This epoch took 15.623934 s\n",
      "\n",
      "2022-11-27 22:28:05.475705: \n",
      "epoch:  943\n",
      "2022-11-27 22:28:19.731165: train loss : -0.9401\n",
      "2022-11-27 22:28:20.743742: validation loss: -0.8395\n",
      "2022-11-27 22:28:20.744146: Average global foreground Dice: [0.8967, 0.8817]\n",
      "2022-11-27 22:28:20.744220: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:28:21.113069: lr: 0.000747\n",
      "2022-11-27 22:28:21.113175: This epoch took 15.637442 s\n",
      "\n",
      "2022-11-27 22:28:21.113206: \n",
      "epoch:  944\n",
      "2022-11-27 22:28:35.386234: train loss : -0.9397\n",
      "2022-11-27 22:28:36.400185: validation loss: -0.8368\n",
      "2022-11-27 22:28:36.400557: Average global foreground Dice: [0.8934, 0.8786]\n",
      "2022-11-27 22:28:36.400699: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:28:36.767588: lr: 0.000735\n",
      "2022-11-27 22:28:36.767708: This epoch took 15.654461 s\n",
      "\n",
      "2022-11-27 22:28:36.767740: \n",
      "epoch:  945\n",
      "2022-11-27 22:28:51.068938: train loss : -0.9416\n",
      "2022-11-27 22:28:52.085974: validation loss: -0.8349\n",
      "2022-11-27 22:28:52.086357: Average global foreground Dice: [0.8931, 0.8778]\n",
      "2022-11-27 22:28:52.086435: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:28:52.468477: lr: 0.000723\n",
      "2022-11-27 22:28:52.468576: This epoch took 15.700810 s\n",
      "\n",
      "2022-11-27 22:28:52.468602: \n",
      "epoch:  946\n",
      "2022-11-27 22:29:06.689005: train loss : -0.9412\n",
      "2022-11-27 22:29:07.685677: validation loss: -0.8360\n",
      "2022-11-27 22:29:07.686378: Average global foreground Dice: [0.8942, 0.8778]\n",
      "2022-11-27 22:29:07.686505: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:29:08.057308: lr: 0.000711\n",
      "2022-11-27 22:29:08.057425: This epoch took 15.588782 s\n",
      "\n",
      "2022-11-27 22:29:08.057456: \n",
      "epoch:  947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 22:29:22.425487: train loss : -0.9395\n",
      "2022-11-27 22:29:23.448888: validation loss: -0.8413\n",
      "2022-11-27 22:29:23.449272: Average global foreground Dice: [0.8974, 0.8834]\n",
      "2022-11-27 22:29:23.449332: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:29:23.934169: lr: 0.000699\n",
      "2022-11-27 22:29:23.934402: This epoch took 15.876919 s\n",
      "\n",
      "2022-11-27 22:29:23.934438: \n",
      "epoch:  948\n",
      "2022-11-27 22:29:38.232547: train loss : -0.9399\n",
      "2022-11-27 22:29:39.230699: validation loss: -0.8381\n",
      "2022-11-27 22:29:39.231096: Average global foreground Dice: [0.8971, 0.8798]\n",
      "2022-11-27 22:29:39.231230: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:29:39.598367: lr: 0.000687\n",
      "2022-11-27 22:29:39.598481: This epoch took 15.664017 s\n",
      "\n",
      "2022-11-27 22:29:39.598511: \n",
      "epoch:  949\n",
      "2022-11-27 22:29:53.840718: train loss : -0.9405\n",
      "2022-11-27 22:29:54.832560: validation loss: -0.8355\n",
      "2022-11-27 22:29:54.832935: Average global foreground Dice: [0.8932, 0.8796]\n",
      "2022-11-27 22:29:54.833003: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:29:55.212251: lr: 0.000675\n",
      "2022-11-27 22:29:55.212341: saving scheduled checkpoint file...\n",
      "2022-11-27 22:29:55.216387: saving checkpoint...\n",
      "2022-11-27 22:29:55.288481: done, saving took 0.08 seconds\n",
      "2022-11-27 22:29:55.290397: done\n",
      "2022-11-27 22:29:55.290488: This epoch took 15.691952 s\n",
      "\n",
      "2022-11-27 22:29:55.290517: \n",
      "epoch:  950\n",
      "2022-11-27 22:30:09.509212: train loss : -0.9398\n",
      "2022-11-27 22:30:10.546627: validation loss: -0.8333\n",
      "2022-11-27 22:30:10.547155: Average global foreground Dice: [0.8918, 0.8769]\n",
      "2022-11-27 22:30:10.547300: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:30:10.964484: lr: 0.000662\n",
      "2022-11-27 22:30:10.964600: This epoch took 15.674057 s\n",
      "\n",
      "2022-11-27 22:30:10.964628: \n",
      "epoch:  951\n",
      "2022-11-27 22:30:25.264997: train loss : -0.9413\n",
      "2022-11-27 22:30:26.256794: validation loss: -0.8371\n",
      "2022-11-27 22:30:26.257179: Average global foreground Dice: [0.8957, 0.8805]\n",
      "2022-11-27 22:30:26.257240: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:30:26.622865: lr: 0.00065\n",
      "2022-11-27 22:30:26.622976: This epoch took 15.658321 s\n",
      "\n",
      "2022-11-27 22:30:26.623006: \n",
      "epoch:  952\n",
      "2022-11-27 22:30:40.932972: train loss : -0.9409\n",
      "2022-11-27 22:30:41.960171: validation loss: -0.8341\n",
      "2022-11-27 22:30:41.960690: Average global foreground Dice: [0.8936, 0.8783]\n",
      "2022-11-27 22:30:41.960792: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:30:42.336543: lr: 0.000638\n",
      "2022-11-27 22:30:42.336688: This epoch took 15.713655 s\n",
      "\n",
      "2022-11-27 22:30:42.336718: \n",
      "epoch:  953\n",
      "2022-11-27 22:30:56.642940: train loss : -0.9405\n",
      "2022-11-27 22:30:57.679518: validation loss: -0.8389\n",
      "2022-11-27 22:30:57.679866: Average global foreground Dice: [0.8953, 0.8816]\n",
      "2022-11-27 22:30:57.680133: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:30:58.051763: lr: 0.000626\n",
      "2022-11-27 22:30:58.051865: This epoch took 15.715112 s\n",
      "\n",
      "2022-11-27 22:30:58.051911: \n",
      "epoch:  954\n",
      "2022-11-27 22:31:12.326870: train loss : -0.9404\n",
      "2022-11-27 22:31:13.351954: validation loss: -0.8385\n",
      "2022-11-27 22:31:13.352348: Average global foreground Dice: [0.8948, 0.881]\n",
      "2022-11-27 22:31:13.352412: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:31:13.721601: lr: 0.000614\n",
      "2022-11-27 22:31:13.721733: This epoch took 15.669780 s\n",
      "\n",
      "2022-11-27 22:31:13.721763: \n",
      "epoch:  955\n",
      "2022-11-27 22:31:27.974022: train loss : -0.9406\n",
      "2022-11-27 22:31:28.964073: validation loss: -0.8313\n",
      "2022-11-27 22:31:28.964427: Average global foreground Dice: [0.8927, 0.8765]\n",
      "2022-11-27 22:31:28.964487: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:31:29.344616: lr: 0.000601\n",
      "2022-11-27 22:31:29.344724: This epoch took 15.622935 s\n",
      "\n",
      "2022-11-27 22:31:29.344753: \n",
      "epoch:  956\n",
      "2022-11-27 22:31:43.624200: train loss : -0.9405\n",
      "2022-11-27 22:31:44.642034: validation loss: -0.8367\n",
      "2022-11-27 22:31:44.642437: Average global foreground Dice: [0.8952, 0.8805]\n",
      "2022-11-27 22:31:44.642503: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:31:45.021596: lr: 0.000589\n",
      "2022-11-27 22:31:45.021698: This epoch took 15.676919 s\n",
      "\n",
      "2022-11-27 22:31:45.021728: \n",
      "epoch:  957\n",
      "2022-11-27 22:31:59.336626: train loss : -0.9419\n",
      "2022-11-27 22:32:00.355157: validation loss: -0.8363\n",
      "2022-11-27 22:32:00.355493: Average global foreground Dice: [0.8949, 0.8796]\n",
      "2022-11-27 22:32:00.355627: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:32:00.851126: lr: 0.000577\n",
      "2022-11-27 22:32:00.851245: This epoch took 15.829491 s\n",
      "\n",
      "2022-11-27 22:32:00.851274: \n",
      "epoch:  958\n",
      "2022-11-27 22:32:15.167180: train loss : -0.9412\n",
      "2022-11-27 22:32:16.159486: validation loss: -0.8350\n",
      "2022-11-27 22:32:16.159860: Average global foreground Dice: [0.8943, 0.8788]\n",
      "2022-11-27 22:32:16.159921: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:32:16.524354: lr: 0.000564\n",
      "2022-11-27 22:32:16.524464: This epoch took 15.673163 s\n",
      "\n",
      "2022-11-27 22:32:16.524489: \n",
      "epoch:  959\n",
      "2022-11-27 22:32:30.835150: train loss : -0.9418\n",
      "2022-11-27 22:32:31.835622: validation loss: -0.8389\n",
      "2022-11-27 22:32:31.836081: Average global foreground Dice: [0.8979, 0.8813]\n",
      "2022-11-27 22:32:31.836245: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:32:32.212813: lr: 0.000552\n",
      "2022-11-27 22:32:32.212924: This epoch took 15.688410 s\n",
      "\n",
      "2022-11-27 22:32:32.212953: \n",
      "epoch:  960\n",
      "2022-11-27 22:32:46.436611: train loss : -0.9432\n",
      "2022-11-27 22:32:47.436994: validation loss: -0.8333\n",
      "2022-11-27 22:32:47.437376: Average global foreground Dice: [0.8922, 0.8773]\n",
      "2022-11-27 22:32:47.437433: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:32:47.808083: lr: 0.000539\n",
      "2022-11-27 22:32:47.808192: This epoch took 15.595214 s\n",
      "\n",
      "2022-11-27 22:32:47.808220: \n",
      "epoch:  961\n",
      "2022-11-27 22:33:02.151406: train loss : -0.9412\n",
      "2022-11-27 22:33:03.179321: validation loss: -0.8327\n",
      "2022-11-27 22:33:03.179652: Average global foreground Dice: [0.8924, 0.8778]\n",
      "2022-11-27 22:33:03.179709: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:33:03.551549: lr: 0.000527\n",
      "2022-11-27 22:33:03.551657: This epoch took 15.743412 s\n",
      "\n",
      "2022-11-27 22:33:03.551685: \n",
      "epoch:  962\n",
      "2022-11-27 22:33:17.880783: train loss : -0.9415\n",
      "2022-11-27 22:33:18.887811: validation loss: -0.8380\n",
      "2022-11-27 22:33:18.888158: Average global foreground Dice: [0.8958, 0.8817]\n",
      "2022-11-27 22:33:18.888220: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:33:19.255672: lr: 0.000514\n",
      "2022-11-27 22:33:19.255798: This epoch took 15.704071 s\n",
      "\n",
      "2022-11-27 22:33:19.255831: \n",
      "epoch:  963\n",
      "2022-11-27 22:33:33.523483: train loss : -0.9401\n",
      "2022-11-27 22:33:34.530709: validation loss: -0.8394\n",
      "2022-11-27 22:33:34.531090: Average global foreground Dice: [0.8966, 0.8816]\n",
      "2022-11-27 22:33:34.531150: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:33:34.899377: lr: 0.000502\n",
      "2022-11-27 22:33:34.899488: This epoch took 15.643620 s\n",
      "\n",
      "2022-11-27 22:33:34.899518: \n",
      "epoch:  964\n",
      "2022-11-27 22:33:49.195658: train loss : -0.9412\n",
      "2022-11-27 22:33:50.204350: validation loss: -0.8371\n",
      "2022-11-27 22:33:50.204680: Average global foreground Dice: [0.8953, 0.8797]\n",
      "2022-11-27 22:33:50.204736: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:33:50.622843: lr: 0.000489\n",
      "2022-11-27 22:33:50.622949: This epoch took 15.723405 s\n",
      "\n",
      "2022-11-27 22:33:50.622981: \n",
      "epoch:  965\n",
      "2022-11-27 22:34:04.893717: train loss : -0.9404\n",
      "2022-11-27 22:34:05.894071: validation loss: -0.8334\n",
      "2022-11-27 22:34:05.894429: Average global foreground Dice: [0.8924, 0.8789]\n",
      "2022-11-27 22:34:05.894533: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 22:34:06.266765: lr: 0.000477\n",
      "2022-11-27 22:34:06.266876: This epoch took 15.643867 s\n",
      "\n",
      "2022-11-27 22:34:06.266906: \n",
      "epoch:  966\n",
      "2022-11-27 22:34:20.560940: train loss : -0.9415\n",
      "2022-11-27 22:34:21.555699: validation loss: -0.8310\n",
      "2022-11-27 22:34:21.556038: Average global foreground Dice: [0.8912, 0.8776]\n",
      "2022-11-27 22:34:21.556096: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:34:21.966727: lr: 0.000464\n",
      "2022-11-27 22:34:21.966833: This epoch took 15.699900 s\n",
      "\n",
      "2022-11-27 22:34:21.966863: \n",
      "epoch:  967\n",
      "2022-11-27 22:34:36.277703: train loss : -0.9431\n",
      "2022-11-27 22:34:37.286662: validation loss: -0.8339\n",
      "2022-11-27 22:34:37.287041: Average global foreground Dice: [0.894, 0.8788]\n",
      "2022-11-27 22:34:37.287100: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:34:37.790350: lr: 0.000451\n",
      "2022-11-27 22:34:37.790464: This epoch took 15.823573 s\n",
      "\n",
      "2022-11-27 22:34:37.790504: \n",
      "epoch:  968\n",
      "2022-11-27 22:34:52.156561: train loss : -0.9427\n",
      "2022-11-27 22:34:53.151183: validation loss: -0.8345\n",
      "2022-11-27 22:34:53.151563: Average global foreground Dice: [0.8943, 0.8788]\n",
      "2022-11-27 22:34:53.151628: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:34:53.542960: lr: 0.000439\n",
      "2022-11-27 22:34:53.543071: This epoch took 15.752538 s\n",
      "\n",
      "2022-11-27 22:34:53.543108: \n",
      "epoch:  969\n",
      "2022-11-27 22:35:07.810522: train loss : -0.9425\n",
      "2022-11-27 22:35:08.809426: validation loss: -0.8347\n",
      "2022-11-27 22:35:08.809777: Average global foreground Dice: [0.8936, 0.8782]\n",
      "2022-11-27 22:35:08.809832: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:35:09.176867: lr: 0.000426\n",
      "2022-11-27 22:35:09.176992: This epoch took 15.633842 s\n",
      "\n",
      "2022-11-27 22:35:09.177032: \n",
      "epoch:  970\n",
      "2022-11-27 22:35:23.504122: train loss : -0.9427\n",
      "2022-11-27 22:35:24.514396: validation loss: -0.8340\n",
      "2022-11-27 22:35:24.514748: Average global foreground Dice: [0.8926, 0.8774]\n",
      "2022-11-27 22:35:24.514809: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:35:24.910228: lr: 0.000413\n",
      "2022-11-27 22:35:24.910342: This epoch took 15.733268 s\n",
      "\n",
      "2022-11-27 22:35:24.910371: \n",
      "epoch:  971\n",
      "2022-11-27 22:35:39.193714: train loss : -0.9418\n",
      "2022-11-27 22:35:40.201902: validation loss: -0.8363\n",
      "2022-11-27 22:35:40.202238: Average global foreground Dice: [0.8966, 0.8791]\n",
      "2022-11-27 22:35:40.202291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:35:40.566144: lr: 0.0004\n",
      "2022-11-27 22:35:40.566257: This epoch took 15.655859 s\n",
      "\n",
      "2022-11-27 22:35:40.566286: \n",
      "epoch:  972\n",
      "2022-11-27 22:35:54.820352: train loss : -0.9415\n",
      "2022-11-27 22:35:55.841063: validation loss: -0.8395\n",
      "2022-11-27 22:35:55.841588: Average global foreground Dice: [0.8968, 0.883]\n",
      "2022-11-27 22:35:55.841693: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:35:56.211093: lr: 0.000387\n",
      "2022-11-27 22:35:56.211203: This epoch took 15.644892 s\n",
      "\n",
      "2022-11-27 22:35:56.211232: \n",
      "epoch:  973\n",
      "2022-11-27 22:36:10.480420: train loss : -0.9407\n",
      "2022-11-27 22:36:11.493059: validation loss: -0.8356\n",
      "2022-11-27 22:36:11.493456: Average global foreground Dice: [0.8955, 0.8785]\n",
      "2022-11-27 22:36:11.493515: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:36:11.862056: lr: 0.000375\n",
      "2022-11-27 22:36:11.862164: This epoch took 15.650905 s\n",
      "\n",
      "2022-11-27 22:36:11.862193: \n",
      "epoch:  974\n",
      "2022-11-27 22:36:26.150600: train loss : -0.9409\n",
      "2022-11-27 22:36:27.163135: validation loss: -0.8332\n",
      "2022-11-27 22:36:27.163548: Average global foreground Dice: [0.8959, 0.8772]\n",
      "2022-11-27 22:36:27.163716: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:36:27.531102: lr: 0.000362\n",
      "2022-11-27 22:36:27.531209: This epoch took 15.668989 s\n",
      "\n",
      "2022-11-27 22:36:27.531238: \n",
      "epoch:  975\n",
      "2022-11-27 22:36:41.842469: train loss : -0.9413\n",
      "2022-11-27 22:36:42.844879: validation loss: -0.8342\n",
      "2022-11-27 22:36:42.845339: Average global foreground Dice: [0.8934, 0.8796]\n",
      "2022-11-27 22:36:42.845424: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:36:43.212880: lr: 0.000348\n",
      "2022-11-27 22:36:43.212984: This epoch took 15.681720 s\n",
      "\n",
      "2022-11-27 22:36:43.213034: \n",
      "epoch:  976\n",
      "2022-11-27 22:36:57.521636: train loss : -0.9409\n",
      "2022-11-27 22:36:58.513486: validation loss: -0.8383\n",
      "2022-11-27 22:36:58.513878: Average global foreground Dice: [0.897, 0.8793]\n",
      "2022-11-27 22:36:58.513955: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:36:58.883123: lr: 0.000335\n",
      "2022-11-27 22:36:58.883243: This epoch took 15.670167 s\n",
      "\n",
      "2022-11-27 22:36:58.883275: \n",
      "epoch:  977\n",
      "2022-11-27 22:37:13.154368: train loss : -0.9426\n",
      "2022-11-27 22:37:14.170579: validation loss: -0.8347\n",
      "2022-11-27 22:37:14.170925: Average global foreground Dice: [0.8954, 0.8774]\n",
      "2022-11-27 22:37:14.170979: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:37:14.536537: lr: 0.000322\n",
      "2022-11-27 22:37:14.536638: This epoch took 15.653329 s\n",
      "\n",
      "2022-11-27 22:37:14.536664: \n",
      "epoch:  978\n",
      "2022-11-27 22:37:28.754973: train loss : -0.9420\n",
      "2022-11-27 22:37:29.777168: validation loss: -0.8355\n",
      "2022-11-27 22:37:29.777513: Average global foreground Dice: [0.8955, 0.8779]\n",
      "2022-11-27 22:37:29.777570: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:37:30.265544: lr: 0.000309\n",
      "2022-11-27 22:37:30.265680: This epoch took 15.728976 s\n",
      "\n",
      "2022-11-27 22:37:30.265710: \n",
      "epoch:  979\n",
      "2022-11-27 22:37:44.597849: train loss : -0.9422\n",
      "2022-11-27 22:37:45.603298: validation loss: -0.8303\n",
      "2022-11-27 22:37:45.603675: Average global foreground Dice: [0.8918, 0.8753]\n",
      "2022-11-27 22:37:45.603737: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:37:45.971880: lr: 0.000296\n",
      "2022-11-27 22:37:45.971988: This epoch took 15.706252 s\n",
      "\n",
      "2022-11-27 22:37:45.972015: \n",
      "epoch:  980\n",
      "2022-11-27 22:38:00.255834: train loss : -0.9423\n",
      "2022-11-27 22:38:01.272732: validation loss: -0.8350\n",
      "2022-11-27 22:38:01.273055: Average global foreground Dice: [0.8935, 0.8788]\n",
      "2022-11-27 22:38:01.273114: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:38:01.638099: lr: 0.000282\n",
      "2022-11-27 22:38:01.638210: This epoch took 15.666170 s\n",
      "\n",
      "2022-11-27 22:38:01.638239: \n",
      "epoch:  981\n",
      "2022-11-27 22:38:15.946859: train loss : -0.9441\n",
      "2022-11-27 22:38:16.974967: validation loss: -0.8348\n",
      "2022-11-27 22:38:16.975388: Average global foreground Dice: [0.8948, 0.8794]\n",
      "2022-11-27 22:38:16.975491: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:38:17.342629: lr: 0.000269\n",
      "2022-11-27 22:38:17.342737: This epoch took 15.704471 s\n",
      "\n",
      "2022-11-27 22:38:17.342769: \n",
      "epoch:  982\n",
      "2022-11-27 22:38:31.622694: train loss : -0.9425\n",
      "2022-11-27 22:38:32.648416: validation loss: -0.8354\n",
      "2022-11-27 22:38:32.648735: Average global foreground Dice: [0.8945, 0.8786]\n",
      "2022-11-27 22:38:32.648789: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:38:33.014887: lr: 0.000256\n",
      "2022-11-27 22:38:33.015000: This epoch took 15.672204 s\n",
      "\n",
      "2022-11-27 22:38:33.015030: \n",
      "epoch:  983\n",
      "2022-11-27 22:38:47.337558: train loss : -0.9409\n",
      "2022-11-27 22:38:48.331157: validation loss: -0.8361\n",
      "2022-11-27 22:38:48.331545: Average global foreground Dice: [0.8959, 0.8788]\n",
      "2022-11-27 22:38:48.331604: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:38:48.720284: lr: 0.000242\n",
      "2022-11-27 22:38:48.720396: This epoch took 15.705339 s\n",
      "\n",
      "2022-11-27 22:38:48.720424: \n",
      "epoch:  984\n",
      "2022-11-27 22:39:02.992208: train loss : -0.9424\n",
      "2022-11-27 22:39:03.982731: validation loss: -0.8307\n",
      "2022-11-27 22:39:03.983079: Average global foreground Dice: [0.8918, 0.8762]\n",
      "2022-11-27 22:39:03.983136: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 22:39:04.352767: lr: 0.000228\n",
      "2022-11-27 22:39:04.352873: This epoch took 15.632422 s\n",
      "\n",
      "2022-11-27 22:39:04.352900: \n",
      "epoch:  985\n",
      "2022-11-27 22:39:18.601025: train loss : -0.9428\n",
      "2022-11-27 22:39:19.590462: validation loss: -0.8382\n",
      "2022-11-27 22:39:19.590826: Average global foreground Dice: [0.8967, 0.8812]\n",
      "2022-11-27 22:39:19.590926: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:39:19.960864: lr: 0.000215\n",
      "2022-11-27 22:39:19.961084: This epoch took 15.608159 s\n",
      "\n",
      "2022-11-27 22:39:19.961115: \n",
      "epoch:  986\n",
      "2022-11-27 22:39:34.278512: train loss : -0.9432\n",
      "2022-11-27 22:39:35.299432: validation loss: -0.8337\n",
      "2022-11-27 22:39:35.299815: Average global foreground Dice: [0.8945, 0.8777]\n",
      "2022-11-27 22:39:35.299871: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:39:35.676842: lr: 0.000201\n",
      "2022-11-27 22:39:35.676951: This epoch took 15.715809 s\n",
      "\n",
      "2022-11-27 22:39:35.676980: \n",
      "epoch:  987\n",
      "2022-11-27 22:39:49.897287: train loss : -0.9422\n",
      "2022-11-27 22:39:50.883248: validation loss: -0.8318\n",
      "2022-11-27 22:39:50.883588: Average global foreground Dice: [0.8926, 0.877]\n",
      "2022-11-27 22:39:50.883651: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:39:51.257538: lr: 0.000187\n",
      "2022-11-27 22:39:51.257643: This epoch took 15.580638 s\n",
      "\n",
      "2022-11-27 22:39:51.257672: \n",
      "epoch:  988\n",
      "2022-11-27 22:40:05.550955: train loss : -0.9424\n",
      "2022-11-27 22:40:06.539360: validation loss: -0.8316\n",
      "2022-11-27 22:40:06.539705: Average global foreground Dice: [0.8936, 0.8751]\n",
      "2022-11-27 22:40:06.539761: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:40:06.907958: lr: 0.000173\n",
      "2022-11-27 22:40:06.908062: This epoch took 15.650365 s\n",
      "\n",
      "2022-11-27 22:40:06.908091: \n",
      "epoch:  989\n",
      "2022-11-27 22:40:21.216994: train loss : -0.9427\n",
      "2022-11-27 22:40:22.234160: validation loss: -0.8336\n",
      "2022-11-27 22:40:22.234543: Average global foreground Dice: [0.8931, 0.8784]\n",
      "2022-11-27 22:40:22.234602: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:40:22.718856: lr: 0.000158\n",
      "2022-11-27 22:40:22.718972: This epoch took 15.810854 s\n",
      "\n",
      "2022-11-27 22:40:22.719001: \n",
      "epoch:  990\n",
      "2022-11-27 22:40:36.959293: train loss : -0.9422\n",
      "2022-11-27 22:40:37.938075: validation loss: -0.8320\n",
      "2022-11-27 22:40:37.938457: Average global foreground Dice: [0.8914, 0.8764]\n",
      "2022-11-27 22:40:37.938548: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:40:38.307700: lr: 0.000144\n",
      "2022-11-27 22:40:38.307806: This epoch took 15.588779 s\n",
      "\n",
      "2022-11-27 22:40:38.307835: \n",
      "epoch:  991\n",
      "2022-11-27 22:40:52.585337: train loss : -0.9432\n",
      "2022-11-27 22:40:53.561669: validation loss: -0.8351\n",
      "2022-11-27 22:40:53.562011: Average global foreground Dice: [0.8953, 0.8784]\n",
      "2022-11-27 22:40:53.562070: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:40:53.927486: lr: 0.00013\n",
      "2022-11-27 22:40:53.927599: This epoch took 15.619737 s\n",
      "\n",
      "2022-11-27 22:40:53.927627: \n",
      "epoch:  992\n",
      "2022-11-27 22:41:08.232818: train loss : -0.9428\n",
      "2022-11-27 22:41:09.212523: validation loss: -0.8410\n",
      "2022-11-27 22:41:09.213179: Average global foreground Dice: [0.8984, 0.8827]\n",
      "2022-11-27 22:41:09.213295: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:41:09.582013: lr: 0.000115\n",
      "2022-11-27 22:41:09.582123: This epoch took 15.654469 s\n",
      "\n",
      "2022-11-27 22:41:09.582151: \n",
      "epoch:  993\n",
      "2022-11-27 22:41:23.831596: train loss : -0.9431\n",
      "2022-11-27 22:41:24.847885: validation loss: -0.8328\n",
      "2022-11-27 22:41:24.848218: Average global foreground Dice: [0.8923, 0.8768]\n",
      "2022-11-27 22:41:24.848271: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:41:25.216825: lr: 0.0001\n",
      "2022-11-27 22:41:25.216960: This epoch took 15.634766 s\n",
      "\n",
      "2022-11-27 22:41:25.216998: \n",
      "epoch:  994\n",
      "2022-11-27 22:41:39.508006: train loss : -0.9429\n",
      "2022-11-27 22:41:40.518212: validation loss: -0.8346\n",
      "2022-11-27 22:41:40.518637: Average global foreground Dice: [0.8946, 0.8779]\n",
      "2022-11-27 22:41:40.518723: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:41:40.886988: lr: 8.5e-05\n",
      "2022-11-27 22:41:40.887100: This epoch took 15.670059 s\n",
      "\n",
      "2022-11-27 22:41:40.887140: \n",
      "epoch:  995\n",
      "2022-11-27 22:41:55.136678: train loss : -0.9439\n",
      "2022-11-27 22:41:56.141313: validation loss: -0.8342\n",
      "2022-11-27 22:41:56.141694: Average global foreground Dice: [0.8951, 0.878]\n",
      "2022-11-27 22:41:56.141755: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:41:56.513731: lr: 6.9e-05\n",
      "2022-11-27 22:41:56.513838: This epoch took 15.626671 s\n",
      "\n",
      "2022-11-27 22:41:56.513867: \n",
      "epoch:  996\n",
      "2022-11-27 22:42:10.829215: train loss : -0.9435\n",
      "2022-11-27 22:42:11.828232: validation loss: -0.8358\n",
      "2022-11-27 22:42:11.828567: Average global foreground Dice: [0.8953, 0.8798]\n",
      "2022-11-27 22:42:11.828624: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:42:12.235247: lr: 5.4e-05\n",
      "2022-11-27 22:42:12.235358: This epoch took 15.721464 s\n",
      "\n",
      "2022-11-27 22:42:12.235387: \n",
      "epoch:  997\n",
      "2022-11-27 22:42:26.550281: train loss : -0.9442\n",
      "2022-11-27 22:42:27.546799: validation loss: -0.8390\n",
      "2022-11-27 22:42:27.547147: Average global foreground Dice: [0.8962, 0.8809]\n",
      "2022-11-27 22:42:27.547201: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:42:27.923584: lr: 3.7e-05\n",
      "2022-11-27 22:42:27.923690: This epoch took 15.688276 s\n",
      "\n",
      "2022-11-27 22:42:27.923719: \n",
      "epoch:  998\n",
      "2022-11-27 22:42:42.135855: train loss : -0.9433\n",
      "2022-11-27 22:42:43.135360: validation loss: -0.8322\n",
      "2022-11-27 22:42:43.135688: Average global foreground Dice: [0.8928, 0.8765]\n",
      "2022-11-27 22:42:43.135743: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:42:43.520801: lr: 2e-05\n",
      "2022-11-27 22:42:43.520921: This epoch took 15.597176 s\n",
      "\n",
      "2022-11-27 22:42:43.520951: \n",
      "epoch:  999\n",
      "2022-11-27 22:42:57.801284: train loss : -0.9425\n",
      "2022-11-27 22:42:58.832787: validation loss: -0.8348\n",
      "2022-11-27 22:42:58.833168: Average global foreground Dice: [0.8943, 0.8786]\n",
      "2022-11-27 22:42:58.833228: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-11-27 22:42:59.315888: lr: 0.0\n",
      "2022-11-27 22:42:59.315986: saving scheduled checkpoint file...\n",
      "2022-11-27 22:42:59.320163: saving checkpoint...\n",
      "2022-11-27 22:42:59.392436: done, saving took 0.08 seconds\n",
      "2022-11-27 22:42:59.394316: done\n",
      "2022-11-27 22:42:59.394389: This epoch took 15.873413 s\n",
      "\n",
      "2022-11-27 22:42:59.398252: saving checkpoint...\n",
      "2022-11-27 22:42:59.448350: done, saving took 0.05 seconds\n",
      "hippocampus_003 (2, 35, 52, 34)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "hippocampus_014 (2, 40, 50, 39)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_034 (2, 40, 49, 36)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "hippocampus_058 (2, 36, 53, 34)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "prediction done\n",
      "hippocampus_074 (2, 42, 47, 37)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 42, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0, 2], [0], [0]]\n",
      "number of tiles: 2\n",
      "computing Gaussian\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction done\n",
      "hippocampus_093 (2, 37, 53, 34)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "hippocampus_094 (2, 38, 50, 38)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "force_separate_z: None interpolation order: 1\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "no resampling necessary\n",
      "prediction done\n",
      "hippocampus_096 (2, 39, 47, 34)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "force_separate_z: None interpolation order: 1\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "no resampling necessary\n",
      "prediction done\n",
      "hippocampus_099 (2, 27, 52, 33)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "prediction done\n",
      "hippocampus_107 (2, 34, 55, 35)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_109 (2, 36, 49, 36)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_142 (2, 41, 43, 38)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 41, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0, 1], [0], [0]]\n",
      "number of tiles: 2\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_152 (2, 37, 53, 36)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "hippocampus_156 (2, 36, 52, 36)\n",
      "no resampling necessary\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_162 (2, 37, 51, 38)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "hippocampus_163 (2, 44, 47, 36)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 44, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0, 4], [0], [0]]\n",
      "number of tiles: 2\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_169 (2, 39, 45, 36)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "hippocampus_171 (2, 28, 56, 35)\n",
      "no resampling necessary\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "hippocampus_177 (2, 40, 44, 33)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_188 (2, 36, 54, 37)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "hippocampus_193 (2, 29, 50, 33)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_195 (2, 28, 53, 33)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_197 (2, 31, 51, 38)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "hippocampus_207 (2, 33, 53, 35)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "force_separate_z: None interpolation order: 1\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "no resampling necessary\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_212 (2, 34, 56, 35)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_219 (2, 39, 45, 37)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_228 (2, 36, 48, 37)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_236 (2, 35, 57, 37)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 57, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0, 1], [0]]\n",
      "number of tiles: 2\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "hippocampus_242 (2, 34, 52, 38)\n",
      "no resampling necessary\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_248 (2, 38, 50, 36)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "hippocampus_274 (2, 40, 40, 35)\n",
      "no resampling necessary\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_279 (2, 32, 50, 34)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_294 (2, 44, 44, 35)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 44, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0, 4], [0], [0]]\n",
      "number of tiles: 2\n",
      "using precomputed Gaussian\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_296 (2, 35, 54, 35)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_303 (2, 38, 48, 35)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_310 (2, 38, 52, 35)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "hippocampus_311 (2, 37, 49, 37)\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_326 (2, 41, 49, 36)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 41, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0, 1], [0], [0]]\n",
      "number of tiles: 2\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_329 (2, 32, 53, 34)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_331 (2, 33, 52, 35)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_334 (2, 36, 47, 34)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_337 (2, 41, 44, 33)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 41, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0, 1], [0], [0]]\n",
      "number of tiles: 2\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_338 (2, 43, 43, 37)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 43, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0, 3], [0], [0]]\n",
      "number of tiles: 2\n",
      "using precomputed Gaussian\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_341 (2, 35, 48, 34)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_345 (2, 30, 49, 32)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_352 (2, 35, 51, 38)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_358 (2, 34, 50, 35)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_366 (2, 34, 47, 37)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_373 (2, 35, 49, 34)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_374 (2, 39, 48, 38)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_381 (2, 37, 49, 33)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "hippocampus_386 (2, 40, 45, 37)\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 40, 56, 40)\n",
      "patch size: [40 56 40]\n",
      "steps (x, y, and z): [[0], [0], [0]]\n",
      "number of tiles: 1\n",
      "prediction done\n",
      "force_separate_z: None interpolation order: 1\n",
      "no resampling necessary\n",
      "2022-11-27 22:43:02.370737: finished prediction\n",
      "2022-11-27 22:43:02.371082: evaluation of raw predictions\n",
      "2022-11-27 22:43:02.795668: determining postprocessing\n",
      "Foreground vs background\n",
      "before: 0.8900037611649412\n",
      "after:  0.8900037611649412\n",
      "1\n",
      "before: 0.8971246955675761\n",
      "after:  0.8971298464874911\n",
      "Removing all but the largest region for class 1 improved results!\n",
      "min_valid_object_sizes None\n",
      "2\n",
      "before: 0.8828828267623062\n",
      "after:  0.882876482097161\n",
      "done\n",
      "for which classes:\n",
      "[1]\n",
      "min_object_sizes\n",
      "None\n",
      "done\n",
      "CPU times: user 5min 3s, sys: 49.4 s, total: 5min 53s\n",
      "Wall time: 4h 21min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train the 3d nnUnet on the Full Resolution with Task 4, Normal training and Cross Validation Split 5\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 4 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oI_Qxqlortjn"
   },
   "source": [
    "## 6.3 Inference with Pre-Trained Models on Decathlon Prostate Dataset\n",
    "Here we will use a pretrained model on the Prostate Dataset and visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 Downloading Pretrained Model\n",
    "First Download the pretrained models and validate that everything works correctly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 346105,
     "status": "ok",
     "timestamp": 1643126427978,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "Y-OREi8L5JBX",
    "outputId": "96d804e1-48dc-4dae-8a90-e947e6196e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "\n",
      "######################################################\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!WARNING!!!!!!!!!!!!!!!!!!!!!!!\n",
      "######################################################\n",
      "Using the pretrained model weights is subject to the license of the dataset they were trained on. Some allow commercial use, others don't. It is your responsibility to make sure you use them appropriately! Use nnUNet_print_pretrained_model_info(task_name) to see a summary of the dataset and where to find its license!\n",
      "######################################################\n",
      "\n",
      "Downloading pretrained model from url: https://zenodo.org/record/4485926/files/Task005_Prostate.zip?download=1\n",
      "100%|██████████████████████████████████████| 2.60G/2.60G [06:55<00:00, 6.71MB/s]\n",
      "Download finished. Extracting...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Download the Pretrained Model for the Prostate Dataset (Decathlon Task)\n",
    "!nnUNet_download_pretrained_model Task005_Prostate\n",
    "\n",
    "# takes roughly 9 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nnUNet_print_pretrained_model_info Task005_Prostate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 Convert Prostate Dataset\n",
    "For inference the data has to be saved into the format nnU-Net expects as input (as detailed in 6.2.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82642,
     "status": "ok",
     "timestamp": 1642875101487,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "UPOO1zhz8thI",
    "outputId": "59e365a8-8196-4ca9-8a8f-c327f12a64d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocess Prostate Dataset\n",
    "!nnUNet_convert_decathlon_task -i \"${RAW_DATA_PATH}/Task05_Prostate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3 Inference on the Prostate Dataset\n",
    "Use 3d_fulles nnUnet (-m) trained on task 5 (-t 5) on the test dataset and save the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49799,
     "status": "ok",
     "timestamp": 1643127870499,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "IEPXgLEp_Tt0",
    "outputId": "6161a178-b723-4eee-ff99-575f9dedb65e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "using model stored in  /content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task005_Prostate/nnUNetTrainerV2__nnUNetPlansv2.1\n",
      "This model expects 2 input modalities for each image\n",
      "Found 16 unique case ids, here are some examples: ['prostate_36' 'prostate_09' 'prostate_12' 'prostate_27' 'prostate_30'\n",
      " 'prostate_26' 'prostate_08' 'prostate_27' 'prostate_12' 'prostate_36']\n",
      "If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc\n",
      "number of cases: 16\n",
      "number of cases that still need to be predicted: 0\n",
      "emptying cuda cache\n",
      "loading parameters for folds, None\n",
      "folds is None so we will automatically look for output folders (not using 'all'!)\n",
      "found the following folds:  ['/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task005_Prostate/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0', '/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task005_Prostate/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1', '/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task005_Prostate/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2', '/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task005_Prostate/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3', '/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task005_Prostate/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4']\n",
      "2022-01-25 16:23:47.500971: Using dummy2d data augmentation\n",
      "using the following model files:  ['/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task005_Prostate/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model', '/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task005_Prostate/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_final_checkpoint.model', '/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task005_Prostate/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_final_checkpoint.model', '/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task005_Prostate/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3/model_final_checkpoint.model', '/content/drive/My Drive/Colab Notebooks/nnUNet_Results_Folder/nnUNet/3d_fullres/Task005_Prostate/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4/model_final_checkpoint.model']\n",
      "starting preprocessing generator\n",
      "starting prediction...\n",
      "inference done. Now waiting for the segmentation export to finish...\n",
      "postprocessing...\n"
     ]
    }
   ],
   "source": [
    "# use fully trained nnU-Net to make predictions on data\n",
    "!nnUNet_predict -i \"${nnUNet_raw_data_base}/nnUNet_raw_data/Task005_Prostate/imagesTs/\" -o \"${RESULTS_FOLDER}/Task005_Prostate/predTs/\" -t 5 -m 3d_fullres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LetWZXletANY"
   },
   "source": [
    "## 6.3.4 Visualization of Data and Segmentations\n",
    "Download files from Google Drive:\n",
    "\n",
    "Images from: ```${nnUNet_raw_data_base}/nnUNet_raw_data/Task005_Prostate/imagesTs/```\n",
    "\n",
    "Segmentations from: ```${RESULTS_FOLDER}/Task005_Prostate/predTs/\"```\n",
    "\n",
    "\n",
    "After downloading these files you can visualize them with any volumetric visualization program.\n",
    "For this we would advise to use [MITK](https://www.mitk.org/wiki/The_Medical_Imaging_Interaction_Toolkit_(MITK)) which already has some great [tutorials](https://www.mitk.org/wiki/Tutorials).\n",
    "\n",
    "\n",
    "Note:\n",
    "- If you have not already downloaded it, here is the [MITK Download Link](https://www.mitk.org/wiki/Downloads)\n",
    "\n",
    "This is also the end of the basic tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hh3rQps8uStT"
   },
   "source": [
    "# 7. How to train and use nnU-Net on a new Dataset?\n",
    "\n",
    "Goal of the next Steps:\n",
    "- How can you Implement nnU-Net for a new Dataset?\n",
    "  - Example using the GM Spinal Cord Segmentation Challenge Dataset\n",
    "    - [Data & Task Explanation](https://www.sciencedirect.com/science/article/pii/S1053811917302185)\n",
    "    - [Data Download Link](http://cmictig.cs.ucl.ac.uk/niftyweb/challenge/)\n",
    "- How to store the Data for use with nnU-Net?\n",
    "  - General Information can be found [here](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/dataset_conversion.md)\n",
    "- How to create the Data Fingerprint?\n",
    "- How to create the Pipeline Fingerprint based on Rules?\n",
    "\n",
    "This part of the Tutorial based on: \n",
    "\n",
    "The [GoogleColab Notebook](https://github.com/prateekgupta891/nnUNet/blob/master/nnunetmec2020.ipynb) and the [Medium Article about nnU-Net](https://medium.com/miccai-educational-initiative/nnu-net-the-no-new-unet-for-automatic-segmentation-8d655f3f6d2a)\n",
    "written in the context of the MICCAI Educational Initiative by:\n",
    "- Prateek Gupta, Indian Institute of Information Technology, Pune (prateekgupta16@alumni.iiitp.ac.in)\n",
    "- Kumar T. Rajamani, Institute of Medical Informatics, University of Lübeck, Germany (kumar.rajamani@uni-luebeck.de)\n",
    "- Mattias P. Heinrich, Institute of Medical Informatics, University of Lübeck, Germany (heinrich@imi.uni-luebeck.de)\n",
    "\n",
    "Many Thanks to them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1316,
     "status": "ok",
     "timestamp": 1643208247485,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "fv28nQ-ZYx8c",
    "outputId": "37037c03-227d-4c06-8433-f01a7c6e5189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/nnUNet_raw_data_base/nnUNet_raw_data/Task501_SCGM created!\n",
      "/content/drive/My Drive/Colab Notebooks/nnUNet_raw_data_base/nnUNet_raw_data/Task501_SCGM/imagesTr created!\n",
      "/content/drive/My Drive/Colab Notebooks/nnUNet_raw_data_base/nnUNet_raw_data/Task501_SCGM/labelsTr created!\n",
      "/content/drive/My Drive/Colab Notebooks/nnUNet_raw_data_base/nnUNet_raw_data/Task501_SCGM/imagesTs created!\n"
     ]
    }
   ],
   "source": [
    "# Create Folderstructure for the new task!\n",
    "task_name = 'Task501_SCGM' #change here for different task name\n",
    "nnunet_raw_data = os.path.join(os.getenv(\"nnUNet_raw_data_base\"), \"nnUNet_raw_data\")\n",
    "# nnunet_raw_data = \"nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data\"\n",
    "task_folder_name = os.path.join(nnunet_raw_data,task_name)\n",
    "train_image_dir = os.path.join(task_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(task_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(task_folder_name,'imagesTs')\n",
    "# main_dir = os.path.join(base_dir,'nnUNet/nnunet')\n",
    "\n",
    "# Create Folder Structure for the SCGM Task on the system\n",
    "make_if_dont_exist(task_folder_name)\n",
    "make_if_dont_exist(train_image_dir)\n",
    "make_if_dont_exist(train_label_dir)\n",
    "make_if_dont_exist(test_dir)\n",
    "\n",
    "training_data_name=\"training-data-gm-sc-challenge-ismrm16-v20160302b\"\n",
    "test_data_name=\"test-data-gm-sc-challenge-ismrm16-v20160401\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Data Download\n",
    "Again, now the data has to be put into the proper place in the folder structure. \n",
    "\n",
    "In case you are not attending an in person workshop please skip the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4632,
     "status": "ok",
     "timestamp": 1643208256086,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "dhjsfUOLjcgf",
    "outputId": "83941303-f8f3-41ca-daa4-9e6ded9e4898"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?export=download&id=1Kynj_jFKwjXlSWkOf5A9uvfF0UAolpZl\n",
      "To: /content/drive/My Drive/Colab Notebooks/nnUNet_raw_data_base/nnUNet_raw_data/Task501_SCGM/training-data-gm-sc-challenge-ismrm16-v20160302b.zip\n",
      "100% 122M/122M [00:00<00:00, 126MB/s]\n",
      "imagesTr  labelsTr\n",
      "imagesTs  training-data-gm-sc-challenge-ismrm16-v20160302b.zip\n"
     ]
    }
   ],
   "source": [
    "# only for in poerson workshops\n",
    "\n",
    "os.chdir(task_folder_name)\n",
    "# download training data\n",
    "!gdown 'https://drive.google.com/uc?export=download&id=1Kynj_jFKwjXlSWkOf5A9uvfF0UAolpZl'\n",
    "!ls\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1643208397303,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "e7vA8XXf1DgQ",
    "outputId": "f15723b8-f6c1-40a9-cc4f-14b54fdf48cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file for exists SCGM Challenge exists\n"
     ]
    }
   ],
   "source": [
    "# continue from here again.\n",
    "if os.path.isfile(os.path.join(task_folder_name, training_data_name+'.zip')) is False: \n",
    "  print(\"Please download the dataset zipfiles and place them into the following directory: \\n {}\".format(task_folder_name))\n",
    "else:\n",
    "  print(f'Training file for exists SCGM Challenge exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1643208440013,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "PWY3RpZxafqi",
    "outputId": "ce61140e-06be-40d9-a706-c1d87d6bdae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagesTr  labelsTr\n",
      "imagesTs  training-data-gm-sc-challenge-ismrm16-v20160302b.zip\n",
      "Training file for exists SCGM Challenge exists\n",
      "We are currently in working directory /content\n"
     ]
    }
   ],
   "source": [
    "# verify that files are in the correct place!\n",
    "os.chdir(task_folder_name)\n",
    "!ls\n",
    "if os.path.isfile(training_data_name+'.zip'):\n",
    "    print(f'Training file for exists SCGM Challenge exists')\n",
    "else:\n",
    "    print('Training file for SCGM Challenge is not present in the directory')\n",
    "    print(\"Please check whether {}.zip is in Folder {}\".format(training_data_name, task_folder_name))\n",
    "\n",
    "# Testing Data is sadly Currently not available\n",
    "# if os.path.isfile(test_data_name+'.zip'):\n",
    "#     print('Testing file for SCGM Challenge exists')\n",
    "# else:\n",
    "#     print('Testing file for SCGM Challenge is not present in the directory')\n",
    "#     print(\"Please check whether {}.zip is in Folder {}\".format(test_data_name, task_folder_name))\n",
    "os.chdir(base_dir)\n",
    "print(\"We are currently in working directory {}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6441,
     "status": "ok",
     "timestamp": 1643208455244,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "mG5QHzSGyLW8",
    "outputId": "d7b54754-aa2d-43e2-fe0f-10cbc726d5da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  training-data-gm-sc-challenge-ismrm16-v20160302b.zip\n",
      "   creating: training-data-gm-sc-challenge-ismrm16-v20160302b/\n",
      "  inflating: __MACOSX/._training-data-gm-sc-challenge-ismrm16-v20160302b  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc04-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc04-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc05-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc05-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc10-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc10-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc01-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc01-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc05-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc05-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc10-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc10-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc04-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc04-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc02-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc02-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc06-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc06-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc04-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc04-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc05-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc05-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc10-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc10-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc05-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc05-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc03-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc03-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc04-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc04-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc02-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc02-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc02-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc02-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc05-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc05-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc10-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc10-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc06-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc06-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc03-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc03-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc02-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc02-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc09-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc09-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc01-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc01-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc04-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc04-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc07-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc07-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc02-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc02-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc03-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc03-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc03-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc03-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc08-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc08-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc02-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc02-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc03-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc03-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc10-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc10-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc05-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc05-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc07-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc07-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc02-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc02-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc10-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc10-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc03-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc03-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc07-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc07-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc03-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc03-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc02-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc02-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc04-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc04-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc02-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc02-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc02-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc02-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc04-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc04-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc10-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc10-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc05-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc05-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc10-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc10-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc05-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc05-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc01-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc01-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc04-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc04-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc03-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc03-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc10-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc10-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc05-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc05-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc04-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc04-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc07-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc07-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc07-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc07-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc07-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc07-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc06-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc06-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc08-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc08-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc07-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc07-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc09-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc09-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc06-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc06-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc08-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc08-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc07-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc07-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc06-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc06-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc01-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc01-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc06-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc06-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc05-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc05-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc09-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc09-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc06-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc06-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc07-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc07-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc08-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc08-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc09-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc09-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc01-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc01-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc01-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc01-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc09-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc09-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc08-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc08-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc06-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc06-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc01-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc01-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc01-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc01-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc08-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc08-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc07-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc07-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc01-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc01-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc07-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc07-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc09-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc09-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc08-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc08-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc09-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc09-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc08-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc08-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc01-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc01-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc01-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc01-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc05-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc05-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc08-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc08-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc09-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc09-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc06-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc06-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc07-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc07-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc06-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc06-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc09-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc09-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc02-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc02-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc06-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc06-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc07-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc07-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc01-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc01-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc06-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc06-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc08-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc08-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc01-mask-r1.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc01-mask-r1.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc03-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc03-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc08-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc08-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc07-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc07-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc06-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc06-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc07-mask-r3.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc07-mask-r3.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc02-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc02-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc03-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc03-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc06-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc06-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc07-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc07-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc06-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc06-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc09-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc09-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc10-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc10-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc01-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc01-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc02-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc02-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc09-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc09-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc03-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc03-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc05-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc05-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc10-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc10-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc06-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc06-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc03-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc03-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc04-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc04-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc05-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc05-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc10-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc10-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc09-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc09-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc04-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc04-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc10-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc10-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc01-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc01-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc05-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc05-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc08-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc08-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc09-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc09-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc05-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc05-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc10-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc10-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc01-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc01-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc06-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc06-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc09-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc09-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc02-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc02-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc01-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc01-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc02-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc02-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc08-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc08-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc07-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc07-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc08-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc08-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc04-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc04-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc09-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc09-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc05-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc05-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc03-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc03-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc04-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc04-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc08-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc08-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc10-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc10-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc05-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc05-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc01-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc01-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc04-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc04-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc03-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc03-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc03-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc03-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc08-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc08-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc08-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc08-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc04-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc04-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc10-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc10-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc07-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc07-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc03-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc03-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc04-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc04-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc05-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc05-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc02-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc02-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc02-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc02-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc09-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc09-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc03-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc03-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc08-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc08-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc06-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc06-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc07-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc07-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc06-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc06-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc10-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc10-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc08-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc08-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc06-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc06-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc09-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc09-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc05-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc05-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc10-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc10-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc01-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc01-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc08-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc08-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc02-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc02-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc01-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc01-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc05-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc05-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc10-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc10-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc09-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc09-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc04-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc04-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc02-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc02-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc04-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc04-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc09-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc09-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc05-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc05-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc01-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc01-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc03-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc03-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc02-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc02-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc01-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc01-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc10-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc10-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc06-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc06-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc05-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc05-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc10-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc10-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/license.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._license.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc05-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc05-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc02-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc02-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc03-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc03-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc02-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc02-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc02-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc02-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc10-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc10-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc09-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc09-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc06-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc06-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc07-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc07-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc09-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc09-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc09-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc09-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc04-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc04-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc03-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc03-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc02-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc02-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc08-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc08-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc03-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc03-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc10-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc10-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc06-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc06-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc07-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc07-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc08-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc08-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc06-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc06-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc09-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc09-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc03-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc03-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc07-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc07-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc04-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc04-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc07-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc07-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc03-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc03-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc04-image.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc04-image.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc10-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc10-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc05-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc05-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc04-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc04-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc08-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc08-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc04-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc04-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc01-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc01-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site4-sc09-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site4-sc09-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site2-sc08-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site2-sc08-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc04-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc04-mask-r4.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc07-mask-r2.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc07-mask-r2.nii.gz  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site3-sc01-levels.txt  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site3-sc01-levels.txt  \n",
      "  inflating: training-data-gm-sc-challenge-ismrm16-v20160302b/site1-sc03-mask-r4.nii.gz  \n",
      "  inflating: __MACOSX/training-data-gm-sc-challenge-ismrm16-v20160302b/._site1-sc03-mask-r4.nii.gz  \n"
     ]
    }
   ],
   "source": [
    "#unzipping in nnUNet_raw folder the training data\n",
    "os.chdir(task_folder_name)\n",
    "!unzip training-data-gm-sc-challenge-ismrm16-v20160302b.zip\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKs8v1ndynNJ"
   },
   "source": [
    "## 7.2 Data Preprocessing\n",
    "We have 4 annotation of the same image, by different experts in the SCGM Challenge. ( Image , Ann1 ) and ( Image , Ann2 ) can be considered as a different image and label pairs. Hence, 4 copies of the training .nii.gz file is created with its mapping to the respective label name.\n",
    "\n",
    "For this the data is renamed and relocated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oawSNmUjya-u"
   },
   "outputs": [],
   "source": [
    "# function for copying, savind and renaming\n",
    "def copy_and_rename(old_location,old_file_name,new_location,new_filename,delete_original = False):\n",
    "\n",
    "    shutil.copy(os.path.join(old_location,old_file_name),new_location)\n",
    "    os.rename(os.path.join(new_location,old_file_name),os.path.join(new_location,new_filename))\n",
    "    if delete_original:\n",
    "        os.remove(os.path.join(old_location,old_file_name))\n",
    "\n",
    "# putting training images into folder\n",
    "\n",
    "mask_count = 4 # change if more mask is available\n",
    "base_data_folder_name = os.path.join(task_folder_name, \"training-data-gm-sc-challenge-ismrm16-v20160302b\")\n",
    "\n",
    "for file in os.listdir(base_data_folder_name):\n",
    "    # print(file)\n",
    "    if file.endswith('.nii.gz'):\n",
    "        if file.find('mask')!=-1:\n",
    "            # putting mask\n",
    "            shutil.move(os.path.join(base_data_folder_name,file),train_label_dir)\n",
    "        else:\n",
    "            # making 4 copies\n",
    "            for mask in range(1,mask_count+1):\n",
    "                new_filename = file[:file.find('-image')] + '-mask-r' + str(mask) + '.nii.gz'\n",
    "                if mask==mask_count:\n",
    "                    copy_and_rename(base_data_folder_name,file,train_image_dir,new_filename,delete_original = True)\n",
    "                else:\n",
    "                    copy_and_rename(base_data_folder_name,file,train_image_dir,new_filename)\n",
    "    # removing all other files installed due to the unzip\n",
    "    elif file.endswith('.txt'):\n",
    "        os.remove(os.path.join(base_data_folder_name,file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOkK_ZcJ_zuu"
   },
   "source": [
    "## 7.3 Verification of Data\n",
    "\n",
    "Before going any further, verify that the data is present and labels and data matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1643208476256,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "NiNcsMqX_9Nu",
    "outputId": "b4287bc5-a18f-4562-f9d3-0486eba9dc34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image files: 160\n",
      "train label files: 160\n",
      "Matches: 160\n"
     ]
    }
   ],
   "source": [
    "train_files = os.listdir(train_image_dir)\n",
    "label_files = os.listdir(train_label_dir)\n",
    "print(\"train image files:\",len(train_files))\n",
    "print(\"train label files:\",len(label_files))\n",
    "print(\"Matches:\",len(set(train_files).intersection(set(label_files))))\n",
    "\n",
    "assert len(set(train_files).intersection(set(label_files))) == 160 #should be equal to 160 for SCGM Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyTlK-ty_YhS"
   },
   "outputs": [],
   "source": [
    "# skip this because testing data was somehow not downloadable\n",
    "\n",
    "# unzip the testing files in nnUNet_raw folder\n",
    "\n",
    "# os.chdir(task_folder_name)\n",
    "# !unzip test-data-gm-sc-challenge-ismrm16-v20160401.zip\n",
    "# os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKZujk0i_acp"
   },
   "outputs": [],
   "source": [
    "# for file in os.listdir(task_folder_name):\n",
    "\n",
    "#     if file.endswith('.nii.gz'):\n",
    "#         #putting mask\n",
    "#         shutil.move(os.path.join(task_folder_name,file),test_dir)\n",
    "    \n",
    "#     #removing all other files installed due to the unzip\n",
    "#     elif file.endswith('.txt'):\n",
    "#         os.remove(os.path.join(task_folder_name,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVZwxtEP_jjp"
   },
   "outputs": [],
   "source": [
    "# print(\"Testing files:\",len(os.listdir(test_dir)))\n",
    "# print(test_dir)\n",
    "#for spinal cord dataset testing files needs to be equal to 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2438,
     "status": "ok",
     "timestamp": 1643208484172,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "NaTA4qO2_lKP",
    "outputId": "1b98dc7b-0295-4a45-e0b9-28f4d88f2d32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed to site4-sc01-mask-r4_0000.nii.gz\n",
      "Renamed to site4-sc01-mask-r1_0000.nii.gz\n",
      "Renamed to site4-sc01-mask-r2_0000.nii.gz\n",
      "Renamed to site4-sc01-mask-r3_0000.nii.gz\n",
      "Renamed to site4-sc06-mask-r4_0000.nii.gz\n",
      "Renamed to site4-sc06-mask-r1_0000.nii.gz\n",
      "Renamed to site4-sc06-mask-r2_0000.nii.gz\n",
      "Renamed to site4-sc06-mask-r3_0000.nii.gz\n",
      "Renamed to site1-sc06-mask-r4_0000.nii.gz\n",
      "Renamed to site1-sc06-mask-r1_0000.nii.gz\n",
      "Renamed to site1-sc06-mask-r2_0000.nii.gz\n",
      "Renamed to site1-sc06-mask-r3_0000.nii.gz\n",
      "Renamed to site1-sc01-mask-r4_0000.nii.gz\n",
      "Renamed to site1-sc01-mask-r1_0000.nii.gz\n",
      "Renamed to site1-sc01-mask-r2_0000.nii.gz\n",
      "Renamed to site1-sc01-mask-r3_0000.nii.gz\n",
      "Renamed to site4-sc07-mask-r4_0000.nii.gz\n",
      "Renamed to site4-sc07-mask-r1_0000.nii.gz\n",
      "Renamed to site4-sc07-mask-r2_0000.nii.gz\n",
      "Renamed to site4-sc07-mask-r3_0000.nii.gz\n",
      "Renamed to site1-sc07-mask-r4_0000.nii.gz\n",
      "Renamed to site1-sc07-mask-r1_0000.nii.gz\n",
      "Renamed to site1-sc07-mask-r2_0000.nii.gz\n",
      "Renamed to site1-sc07-mask-r3_0000.nii.gz\n",
      "Renamed to site3-sc06-mask-r4_0000.nii.gz\n",
      "Renamed to site3-sc06-mask-r1_0000.nii.gz\n",
      "Renamed to site3-sc06-mask-r2_0000.nii.gz\n",
      "Renamed to site3-sc06-mask-r3_0000.nii.gz\n",
      "Renamed to site3-sc01-mask-r4_0000.nii.gz\n",
      "Renamed to site3-sc01-mask-r1_0000.nii.gz\n",
      "Renamed to site3-sc01-mask-r2_0000.nii.gz\n",
      "Renamed to site3-sc01-mask-r3_0000.nii.gz\n",
      "Renamed to site2-sc07-mask-r4_0000.nii.gz\n",
      "Renamed to site2-sc07-mask-r1_0000.nii.gz\n",
      "Renamed to site2-sc07-mask-r2_0000.nii.gz\n",
      "Renamed to site2-sc07-mask-r3_0000.nii.gz\n",
      "Renamed to site2-sc06-mask-r4_0000.nii.gz\n",
      "Renamed to site2-sc06-mask-r1_0000.nii.gz\n",
      "Renamed to site2-sc06-mask-r2_0000.nii.gz\n",
      "Renamed to site2-sc06-mask-r3_0000.nii.gz\n",
      "Renamed to site2-sc01-mask-r4_0000.nii.gz\n",
      "Renamed to site2-sc01-mask-r1_0000.nii.gz\n",
      "Renamed to site2-sc01-mask-r2_0000.nii.gz\n",
      "Renamed to site2-sc01-mask-r3_0000.nii.gz\n",
      "Renamed to site3-sc07-mask-r4_0000.nii.gz\n",
      "Renamed to site3-sc07-mask-r1_0000.nii.gz\n",
      "Renamed to site3-sc07-mask-r2_0000.nii.gz\n",
      "Renamed to site3-sc07-mask-r3_0000.nii.gz\n",
      "Renamed to site1-sc09-mask-r4_0000.nii.gz\n",
      "Renamed to site1-sc09-mask-r1_0000.nii.gz\n",
      "Renamed to site1-sc09-mask-r2_0000.nii.gz\n",
      "Renamed to site1-sc09-mask-r3_0000.nii.gz\n",
      "Renamed to site2-sc03-mask-r4_0000.nii.gz\n",
      "Renamed to site2-sc03-mask-r1_0000.nii.gz\n",
      "Renamed to site2-sc03-mask-r2_0000.nii.gz\n",
      "Renamed to site2-sc03-mask-r3_0000.nii.gz\n",
      "Renamed to site2-sc04-mask-r4_0000.nii.gz\n",
      "Renamed to site2-sc04-mask-r1_0000.nii.gz\n",
      "Renamed to site2-sc04-mask-r2_0000.nii.gz\n",
      "Renamed to site2-sc04-mask-r3_0000.nii.gz\n",
      "Renamed to site3-sc10-mask-r4_0000.nii.gz\n",
      "Renamed to site3-sc10-mask-r1_0000.nii.gz\n",
      "Renamed to site3-sc10-mask-r2_0000.nii.gz\n",
      "Renamed to site3-sc10-mask-r3_0000.nii.gz\n",
      "Renamed to site3-sc05-mask-r4_0000.nii.gz\n",
      "Renamed to site3-sc05-mask-r1_0000.nii.gz\n",
      "Renamed to site3-sc05-mask-r2_0000.nii.gz\n",
      "Renamed to site3-sc05-mask-r3_0000.nii.gz\n",
      "Renamed to site4-sc09-mask-r4_0000.nii.gz\n",
      "Renamed to site4-sc09-mask-r1_0000.nii.gz\n",
      "Renamed to site4-sc09-mask-r2_0000.nii.gz\n",
      "Renamed to site4-sc09-mask-r3_0000.nii.gz\n",
      "Renamed to site3-sc02-mask-r4_0000.nii.gz\n",
      "Renamed to site3-sc02-mask-r1_0000.nii.gz\n",
      "Renamed to site3-sc02-mask-r2_0000.nii.gz\n",
      "Renamed to site3-sc02-mask-r3_0000.nii.gz\n",
      "Renamed to site1-sc08-mask-r4_0000.nii.gz\n",
      "Renamed to site1-sc08-mask-r1_0000.nii.gz\n",
      "Renamed to site1-sc08-mask-r2_0000.nii.gz\n",
      "Renamed to site1-sc08-mask-r3_0000.nii.gz\n",
      "Renamed to site3-sc03-mask-r4_0000.nii.gz\n",
      "Renamed to site3-sc03-mask-r1_0000.nii.gz\n",
      "Renamed to site3-sc03-mask-r2_0000.nii.gz\n",
      "Renamed to site3-sc03-mask-r3_0000.nii.gz\n",
      "Renamed to site4-sc08-mask-r4_0000.nii.gz\n",
      "Renamed to site4-sc08-mask-r1_0000.nii.gz\n",
      "Renamed to site4-sc08-mask-r2_0000.nii.gz\n",
      "Renamed to site4-sc08-mask-r3_0000.nii.gz\n",
      "Renamed to site3-sc04-mask-r4_0000.nii.gz\n",
      "Renamed to site3-sc04-mask-r1_0000.nii.gz\n",
      "Renamed to site3-sc04-mask-r2_0000.nii.gz\n",
      "Renamed to site3-sc04-mask-r3_0000.nii.gz\n",
      "Renamed to site2-sc10-mask-r4_0000.nii.gz\n",
      "Renamed to site2-sc10-mask-r1_0000.nii.gz\n",
      "Renamed to site2-sc10-mask-r2_0000.nii.gz\n",
      "Renamed to site2-sc10-mask-r3_0000.nii.gz\n",
      "Renamed to site2-sc05-mask-r4_0000.nii.gz\n",
      "Renamed to site2-sc05-mask-r1_0000.nii.gz\n",
      "Renamed to site2-sc05-mask-r2_0000.nii.gz\n",
      "Renamed to site2-sc05-mask-r3_0000.nii.gz\n",
      "Renamed to site2-sc02-mask-r4_0000.nii.gz\n",
      "Renamed to site2-sc02-mask-r1_0000.nii.gz\n",
      "Renamed to site2-sc02-mask-r2_0000.nii.gz\n",
      "Renamed to site2-sc02-mask-r3_0000.nii.gz\n",
      "Renamed to site4-sc10-mask-r4_0000.nii.gz\n",
      "Renamed to site4-sc10-mask-r1_0000.nii.gz\n",
      "Renamed to site4-sc10-mask-r2_0000.nii.gz\n",
      "Renamed to site4-sc10-mask-r3_0000.nii.gz\n",
      "Renamed to site2-sc08-mask-r4_0000.nii.gz\n",
      "Renamed to site2-sc08-mask-r1_0000.nii.gz\n",
      "Renamed to site2-sc08-mask-r2_0000.nii.gz\n",
      "Renamed to site2-sc08-mask-r3_0000.nii.gz\n",
      "Renamed to site4-sc02-mask-r4_0000.nii.gz\n",
      "Renamed to site4-sc02-mask-r1_0000.nii.gz\n",
      "Renamed to site4-sc02-mask-r2_0000.nii.gz\n",
      "Renamed to site4-sc02-mask-r3_0000.nii.gz\n",
      "Renamed to site3-sc09-mask-r4_0000.nii.gz\n",
      "Renamed to site3-sc09-mask-r1_0000.nii.gz\n",
      "Renamed to site3-sc09-mask-r2_0000.nii.gz\n",
      "Renamed to site3-sc09-mask-r3_0000.nii.gz\n",
      "Renamed to site4-sc05-mask-r4_0000.nii.gz\n",
      "Renamed to site4-sc05-mask-r1_0000.nii.gz\n",
      "Renamed to site4-sc05-mask-r2_0000.nii.gz\n",
      "Renamed to site4-sc05-mask-r3_0000.nii.gz\n",
      "Renamed to site1-sc10-mask-r4_0000.nii.gz\n",
      "Renamed to site1-sc10-mask-r1_0000.nii.gz\n",
      "Renamed to site1-sc10-mask-r2_0000.nii.gz\n",
      "Renamed to site1-sc10-mask-r3_0000.nii.gz\n",
      "Renamed to site1-sc05-mask-r4_0000.nii.gz\n",
      "Renamed to site1-sc05-mask-r1_0000.nii.gz\n",
      "Renamed to site1-sc05-mask-r2_0000.nii.gz\n",
      "Renamed to site1-sc05-mask-r3_0000.nii.gz\n",
      "Renamed to site1-sc02-mask-r4_0000.nii.gz\n",
      "Renamed to site1-sc02-mask-r1_0000.nii.gz\n",
      "Renamed to site1-sc02-mask-r2_0000.nii.gz\n",
      "Renamed to site1-sc02-mask-r3_0000.nii.gz\n",
      "Renamed to site4-sc04-mask-r4_0000.nii.gz\n",
      "Renamed to site4-sc04-mask-r1_0000.nii.gz\n",
      "Renamed to site4-sc04-mask-r2_0000.nii.gz\n",
      "Renamed to site4-sc04-mask-r3_0000.nii.gz\n",
      "Renamed to site3-sc08-mask-r4_0000.nii.gz\n",
      "Renamed to site3-sc08-mask-r1_0000.nii.gz\n",
      "Renamed to site3-sc08-mask-r2_0000.nii.gz\n",
      "Renamed to site3-sc08-mask-r3_0000.nii.gz\n",
      "Renamed to site4-sc03-mask-r4_0000.nii.gz\n",
      "Renamed to site4-sc03-mask-r1_0000.nii.gz\n",
      "Renamed to site4-sc03-mask-r2_0000.nii.gz\n",
      "Renamed to site4-sc03-mask-r3_0000.nii.gz\n",
      "Renamed to site2-sc09-mask-r4_0000.nii.gz\n",
      "Renamed to site2-sc09-mask-r1_0000.nii.gz\n",
      "Renamed to site2-sc09-mask-r2_0000.nii.gz\n",
      "Renamed to site2-sc09-mask-r3_0000.nii.gz\n",
      "Renamed to site1-sc03-mask-r4_0000.nii.gz\n",
      "Renamed to site1-sc03-mask-r1_0000.nii.gz\n",
      "Renamed to site1-sc03-mask-r2_0000.nii.gz\n",
      "Renamed to site1-sc03-mask-r3_0000.nii.gz\n",
      "Renamed to site1-sc04-mask-r4_0000.nii.gz\n",
      "Renamed to site1-sc04-mask-r1_0000.nii.gz\n",
      "Renamed to site1-sc04-mask-r2_0000.nii.gz\n",
      "Renamed to site1-sc04-mask-r3_0000.nii.gz\n"
     ]
    }
   ],
   "source": [
    "#renaming to add the modality for SCGM there is only one modality \n",
    "#images should be added with 0000\n",
    "#can be skipped if modality is already mentioned\n",
    "#re-write for multiple modalities\n",
    "\n",
    "def check_modality(filename):\n",
    "    \"\"\"\n",
    "    check for the existence of modality\n",
    "    return False if modality is not found else True\n",
    "    \"\"\"\n",
    "    end = filename.find('.nii.gz')\n",
    "    modality = filename[end-4:end]\n",
    "    for mod in modality: \n",
    "        if not(ord(mod)>=48 and ord(mod)<=57): #if not in 0 to 9 digits\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def rename_for_single_modality(directory):\n",
    "    \n",
    "    for file in os.listdir(directory):\n",
    "        \n",
    "        if check_modality(file)==False:\n",
    "            new_name = file[:file.find('.nii.gz')]+\"_0000.nii.gz\"\n",
    "            os.rename(os.path.join(directory,file),os.path.join(directory,new_name))\n",
    "            print(f\"Renamed to {new_name}\")\n",
    "        else:\n",
    "            print(f\"Modality present: {file}\")\n",
    "\n",
    "rename_for_single_modality(train_image_dir)\n",
    "\n",
    "# again skip test due to non available data\n",
    "# rename_for_single_modality(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l42eWsw7zKAN"
   },
   "source": [
    "## 7.4 Creation of the Task501 for the SCGMC Dataset\n",
    "The Task gives nnU-Net Information for the Planning and Preprocessing Step.\n",
    "\n",
    "Based on the parameters of the task, the \"optimal strategy\" is selected (data fingerprint & pipeline fingerprint)\n",
    "\n",
    "This is done by creating the ```dataset.json``` file.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 392,
     "status": "ok",
     "timestamp": 1643208513681,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "kVCs1WSCywpH",
    "outputId": "327ea928-ab3d-465d-a99e-7f18259f1a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(os.path.join(task_folder_name,'dataset.json')):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['name'] = task_name\n",
    "    json_dict['description'] = \"Spinal Cord Grey Matter Segmenation Challenge\"\n",
    "    json_dict['tensorImageSize'] = \"3D\"\n",
    "    json_dict['reference'] = \"see challenge website\"\n",
    "    json_dict['licence'] = \"see challenge website\"\n",
    "    json_dict['release'] = \"0.0\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['modality'] = {\n",
    "        \"0\": \"MRI\"\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"0\": \"background\",\n",
    "        \"1\": \"grey matter\",\n",
    "        \"2\": \"white matter\"\n",
    "    }\n",
    "    \n",
    "    train_ids = os.listdir(train_label_dir)\n",
    "    test_ids = os.listdir(test_dir)\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTest'] = len(test_ids)\n",
    "\n",
    "    #no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    #removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % (i[:i.find(\"_0000\")]+'.nii.gz') for i in test_ids]\n",
    "\n",
    "    with open(os.path.join(task_folder_name,\"dataset.json\"), 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(os.path.join(task_folder_name,'dataset.json')):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-kguRqvAeb6"
   },
   "source": [
    "## 7.5 Dataset Preprocessing\n",
    "Also to ensure that nnU-Net can be trained on the dataset a integrity check is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 903679,
     "status": "ok",
     "timestamp": 1643209422073,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "z5RYzcjxAVhk",
    "outputId": "f6cf0430-ea6d-4154-951a-15d44c350629"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "Verifying training set\n",
      "checking case site2-sc07-mask-r1\n",
      "checking case site4-sc01-mask-r4\n",
      "checking case site3-sc07-mask-r2\n",
      "checking case site3-sc10-mask-r1\n",
      "checking case site2-sc01-mask-r4\n",
      "checking case site4-sc01-mask-r3\n",
      "checking case site3-sc02-mask-r1\n",
      "checking case site3-sc09-mask-r2\n",
      "checking case site1-sc03-mask-r2\n",
      "checking case site2-sc06-mask-r1\n",
      "checking case site1-sc04-mask-r4\n",
      "checking case site2-sc05-mask-r1\n",
      "checking case site1-sc06-mask-r4\n",
      "checking case site4-sc01-mask-r2\n",
      "checking case site3-sc03-mask-r3\n",
      "checking case site4-sc05-mask-r3\n",
      "checking case site1-sc02-mask-r1\n",
      "checking case site1-sc09-mask-r4\n",
      "checking case site3-sc08-mask-r1\n",
      "checking case site3-sc06-mask-r1\n",
      "checking case site1-sc01-mask-r3\n",
      "checking case site2-sc05-mask-r3\n",
      "checking case site4-sc08-mask-r4\n",
      "checking case site4-sc03-mask-r3\n",
      "checking case site3-sc03-mask-r1\n",
      "checking case site1-sc06-mask-r2\n",
      "checking case site2-sc10-mask-r4\n",
      "checking case site1-sc03-mask-r4\n",
      "checking case site2-sc07-mask-r4\n",
      "checking case site2-sc06-mask-r4\n",
      "checking case site1-sc08-mask-r4\n",
      "checking case site4-sc05-mask-r1\n",
      "checking case site3-sc06-mask-r4\n",
      "checking case site1-sc07-mask-r1\n",
      "checking case site3-sc01-mask-r1\n",
      "checking case site2-sc04-mask-r4\n",
      "checking case site3-sc10-mask-r3\n",
      "checking case site4-sc07-mask-r1\n",
      "checking case site2-sc06-mask-r2\n",
      "checking case site2-sc01-mask-r3\n",
      "checking case site4-sc06-mask-r2\n",
      "checking case site4-sc03-mask-r4\n",
      "checking case site4-sc07-mask-r3\n",
      "checking case site3-sc10-mask-r4\n",
      "checking case site2-sc10-mask-r1\n",
      "checking case site4-sc06-mask-r1\n",
      "checking case site4-sc07-mask-r2\n",
      "checking case site4-sc02-mask-r3\n",
      "checking case site3-sc02-mask-r3\n",
      "checking case site4-sc08-mask-r3\n",
      "checking case site2-sc01-mask-r1\n",
      "checking case site1-sc07-mask-r4\n",
      "checking case site3-sc01-mask-r3\n",
      "checking case site2-sc06-mask-r3\n",
      "checking case site1-sc06-mask-r1\n",
      "checking case site2-sc02-mask-r1\n",
      "checking case site1-sc09-mask-r3\n",
      "checking case site2-sc08-mask-r1\n",
      "checking case site4-sc03-mask-r1\n",
      "checking case site1-sc10-mask-r2\n",
      "checking case site2-sc03-mask-r1\n",
      "checking case site2-sc09-mask-r2\n",
      "checking case site3-sc06-mask-r2\n",
      "checking case site2-sc10-mask-r3\n",
      "checking case site4-sc06-mask-r3\n",
      "checking case site2-sc02-mask-r2\n",
      "checking case site1-sc02-mask-r2\n",
      "checking case site4-sc04-mask-r2\n",
      "checking case site3-sc01-mask-r4\n",
      "checking case site4-sc02-mask-r2\n",
      "checking case site3-sc02-mask-r2\n",
      "checking case site4-sc07-mask-r4\n",
      "checking case site1-sc04-mask-r2\n",
      "checking case site1-sc08-mask-r2\n",
      "checking case site4-sc06-mask-r4\n",
      "checking case site1-sc05-mask-r2\n",
      "checking case site1-sc01-mask-r2\n",
      "checking case site2-sc03-mask-r4\n",
      "checking case site4-sc04-mask-r3\n",
      "checking case site3-sc04-mask-r1\n",
      "checking case site2-sc09-mask-r1\n",
      "checking case site2-sc04-mask-r1\n",
      "checking case site3-sc09-mask-r1\n",
      "checking case site2-sc07-mask-r2\n",
      "checking case site4-sc09-mask-r3\n",
      "checking case site1-sc04-mask-r3\n",
      "checking case site1-sc05-mask-r4\n",
      "checking case site3-sc06-mask-r3\n",
      "checking case site3-sc09-mask-r4\n",
      "checking case site1-sc01-mask-r4\n",
      "checking case site3-sc04-mask-r4\n",
      "checking case site1-sc08-mask-r1\n",
      "checking case site1-sc01-mask-r1\n",
      "checking case site1-sc09-mask-r2\n",
      "checking case site3-sc07-mask-r4\n",
      "checking case site2-sc04-mask-r2\n",
      "checking case site3-sc07-mask-r3\n",
      "checking case site4-sc05-mask-r2\n",
      "checking case site4-sc10-mask-r1\n",
      "checking case site3-sc04-mask-r3\n",
      "checking case site2-sc09-mask-r3\n",
      "checking case site4-sc04-mask-r1\n",
      "checking case site3-sc02-mask-r4\n",
      "checking case site3-sc08-mask-r3\n",
      "checking case site4-sc08-mask-r2\n",
      "checking case site3-sc08-mask-r4\n",
      "checking case site1-sc09-mask-r1\n",
      "checking case site3-sc04-mask-r2\n",
      "checking case site4-sc04-mask-r4\n",
      "checking case site3-sc07-mask-r1\n",
      "checking case site3-sc09-mask-r3\n",
      "checking case site1-sc10-mask-r1\n",
      "checking case site3-sc10-mask-r2\n",
      "checking case site3-sc05-mask-r1\n",
      "checking case site1-sc06-mask-r3\n",
      "checking case site3-sc03-mask-r4\n",
      "checking case site2-sc08-mask-r3\n",
      "checking case site4-sc09-mask-r4\n",
      "checking case site2-sc10-mask-r2\n",
      "checking case site1-sc05-mask-r3\n",
      "checking case site1-sc07-mask-r3\n",
      "checking case site2-sc09-mask-r4\n",
      "checking case site1-sc03-mask-r1\n",
      "checking case site2-sc08-mask-r4\n",
      "checking case site2-sc05-mask-r4\n",
      "checking case site3-sc05-mask-r4\n",
      "checking case site1-sc10-mask-r3\n",
      "checking case site3-sc05-mask-r2\n",
      "checking case site4-sc10-mask-r2\n",
      "checking case site4-sc01-mask-r1\n",
      "checking case site3-sc05-mask-r3\n",
      "checking case site1-sc05-mask-r1\n",
      "checking case site4-sc09-mask-r1\n",
      "checking case site2-sc02-mask-r4\n",
      "checking case site1-sc10-mask-r4\n",
      "checking case site4-sc05-mask-r4\n",
      "checking case site2-sc01-mask-r2\n",
      "checking case site4-sc02-mask-r1\n",
      "checking case site2-sc03-mask-r3\n",
      "checking case site4-sc08-mask-r1\n",
      "checking case site2-sc04-mask-r3\n",
      "checking case site1-sc04-mask-r1\n",
      "checking case site1-sc07-mask-r2\n",
      "checking case site4-sc10-mask-r4\n",
      "checking case site1-sc03-mask-r3\n",
      "checking case site2-sc02-mask-r3\n",
      "checking case site1-sc02-mask-r3\n",
      "checking case site3-sc03-mask-r2\n",
      "checking case site4-sc02-mask-r4\n",
      "checking case site2-sc07-mask-r3\n",
      "checking case site4-sc03-mask-r2\n",
      "checking case site1-sc08-mask-r3\n",
      "checking case site1-sc02-mask-r4\n",
      "checking case site3-sc01-mask-r2\n",
      "checking case site4-sc09-mask-r2\n",
      "checking case site3-sc08-mask-r2\n",
      "checking case site2-sc03-mask-r2\n",
      "checking case site4-sc10-mask-r3\n",
      "checking case site2-sc08-mask-r2\n",
      "checking case site2-sc05-mask-r2\n",
      "Verifying label values\n",
      "Expected label values are [0, 1, 2]\n",
      "Labels OK\n",
      "WARNING: Not all images in the dataset have the same axis ordering. We very strongly recommend you correct that by reorienting the data. fslreorient2std should do the trick\n",
      "Dataset OK\n",
      "site2-sc07-mask-r1\n",
      "site4-sc01-mask-r3\n",
      "site4-sc01-mask-r4\n",
      "site3-sc02-mask-r1\n",
      "site3-sc07-mask-r2\n",
      "site3-sc09-mask-r2\n",
      "site1-sc04-mask-r4\n",
      "site3-sc10-mask-r1\n",
      "site1-sc03-mask-r2\n",
      "site2-sc05-mask-r1\n",
      "site2-sc01-mask-r4\n",
      "site2-sc06-mask-r1\n",
      "site1-sc06-mask-r4\n",
      "site4-sc05-mask-r3\n",
      "site1-sc01-mask-r3\n",
      "site1-sc06-mask-r2\n",
      "site1-sc08-mask-r4\n",
      "site2-sc04-mask-r4\n",
      "site4-sc06-mask-r2\n",
      "site4-sc01-mask-r2\n",
      "site4-sc06-mask-r1\n",
      "site2-sc05-mask-r3\n",
      "site3-sc10-mask-r3\n",
      "site1-sc02-mask-r1\n",
      "site4-sc03-mask-r4\n",
      "site4-sc05-mask-r1\n",
      "site3-sc03-mask-r3\n",
      "site2-sc10-mask-r4\n",
      "site4-sc07-mask-r2\n",
      "site4-sc08-mask-r4\n",
      "site4-sc07-mask-r1\n",
      "site1-sc09-mask-r4\n",
      "site4-sc07-mask-r3\n",
      "site3-sc06-mask-r4\n",
      "site2-sc01-mask-r1\n",
      "site1-sc03-mask-r4\n",
      "site4-sc02-mask-r3\n",
      "site3-sc08-mask-r1\n",
      "site4-sc03-mask-r3\n",
      "site2-sc06-mask-r2\n",
      "site3-sc10-mask-r4\n",
      "site1-sc07-mask-r1\n",
      "site1-sc07-mask-r4\n",
      "site2-sc07-mask-r4\n",
      "site3-sc02-mask-r3\n",
      "site3-sc06-mask-r1\n",
      "site3-sc03-mask-r1\n",
      "site2-sc01-mask-r3\n",
      "site2-sc10-mask-r1\n",
      "site3-sc01-mask-r1\n",
      "site3-sc01-mask-r3\n",
      "site2-sc06-mask-r4\n",
      "site4-sc08-mask-r3\n",
      "site2-sc02-mask-r1\n",
      "site2-sc03-mask-r1\n",
      "site2-sc02-mask-r2\n",
      "site2-sc06-mask-r3\n",
      "site3-sc02-mask-r2\n",
      "site1-sc05-mask-r2\n",
      "site2-sc09-mask-r1\n",
      "site1-sc04-mask-r3\n",
      "site1-sc06-mask-r1\n",
      "site1-sc09-mask-r3\n",
      "site4-sc07-mask-r4\n",
      "site1-sc01-mask-r2\n",
      "site2-sc09-mask-r2\n",
      "site2-sc04-mask-r1\n",
      "site1-sc02-mask-r2\n",
      "site1-sc05-mask-r4\n",
      "site3-sc04-mask-r4\n",
      "site2-sc08-mask-r1\n",
      "site1-sc04-mask-r2\n",
      "site2-sc03-mask-r4\n",
      "site3-sc06-mask-r2\n",
      "site3-sc09-mask-r1\n",
      "site4-sc04-mask-r2\n",
      "site3-sc06-mask-r3\n",
      "site1-sc08-mask-r1\n",
      "site4-sc03-mask-r1\n",
      "site1-sc08-mask-r2\n",
      "site4-sc04-mask-r3\n",
      "site2-sc10-mask-r3\n",
      "site2-sc07-mask-r2\n",
      "site3-sc01-mask-r4\n",
      "site3-sc09-mask-r4\n",
      "site1-sc01-mask-r1\n",
      "site1-sc10-mask-r2\n",
      "site4-sc06-mask-r4\n",
      "site3-sc04-mask-r1\n",
      "site4-sc06-mask-r3\n",
      "site4-sc09-mask-r3\n",
      "site4-sc02-mask-r2\n",
      "site1-sc01-mask-r4\n",
      "site1-sc09-mask-r2\n",
      "site2-sc04-mask-r2\n",
      "site2-sc09-mask-r3\n",
      "site3-sc08-mask-r4\n",
      "site3-sc09-mask-r3\n",
      "site3-sc03-mask-r4\n",
      "site1-sc07-mask-r3\n",
      "site3-sc05-mask-r4\n",
      "site3-sc07-mask-r4\n",
      "site3-sc07-mask-r3\n",
      "site2-sc08-mask-r3\n",
      "site1-sc10-mask-r1\n",
      "site4-sc04-mask-r1\n",
      "site2-sc09-mask-r4\n",
      "site1-sc09-mask-r1\n",
      "site1-sc10-mask-r3\n",
      "site3-sc05-mask-r3\n",
      "site4-sc05-mask-r2\n",
      "site4-sc09-mask-r4\n",
      "site3-sc10-mask-r2\n",
      "site3-sc02-mask-r4\n",
      "site1-sc03-mask-r1\n",
      "site3-sc04-mask-r2\n",
      "site3-sc05-mask-r2\n",
      "site1-sc05-mask-r1\n",
      "site4-sc10-mask-r1\n",
      "site2-sc10-mask-r2\n",
      "site3-sc05-mask-r1\n",
      "site3-sc08-mask-r3\n",
      "site2-sc08-mask-r4\n",
      "site4-sc04-mask-r4\n",
      "site4-sc10-mask-r2\n",
      "site4-sc09-mask-r1\n",
      "site3-sc04-mask-r3\n",
      "site1-sc05-mask-r3\n",
      "site1-sc06-mask-r3\n",
      "site4-sc08-mask-r2\n",
      "site2-sc05-mask-r4\n",
      "site3-sc07-mask-r1\n",
      "site4-sc01-mask-r1\n",
      "site2-sc02-mask-r4\n",
      "site4-sc05-mask-r4\n",
      "site2-sc04-mask-r3\n",
      "site2-sc02-mask-r3\n",
      "site4-sc03-mask-r2\n",
      "site3-sc08-mask-r2\n",
      "site1-sc10-mask-r4\n",
      "site1-sc04-mask-r1\n",
      "site2-sc01-mask-r2\n",
      "site1-sc02-mask-r3\n",
      "site1-sc08-mask-r3\n",
      "site2-sc03-mask-r2\n",
      "site1-sc07-mask-r2\n",
      "site4-sc02-mask-r1\n",
      "site3-sc03-mask-r2\n",
      "site4-sc10-mask-r3\n",
      "site1-sc02-mask-r4\n",
      "site4-sc10-mask-r4\n",
      "site2-sc03-mask-r3\n",
      "site4-sc02-mask-r4\n",
      "site2-sc08-mask-r2\n",
      "site3-sc01-mask-r2\n",
      "site1-sc03-mask-r3\n",
      "site4-sc08-mask-r1\n",
      "site2-sc07-mask-r3\n",
      "site2-sc05-mask-r2\n",
      "site4-sc09-mask-r2\n",
      "\n",
      "\n",
      "\n",
      " Task101_SCGM\n",
      "number of threads:  (8, 8) \n",
      "\n",
      "not using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalizaion? OrderedDict([(0, False)])\n",
      "the median shape of the dataset is  [ 20.50000067 401.02463054 401.02463054]\n",
      "the max shape in the dataset is  [ 41.99999199 485.51724138 410.48275862]\n",
      "the min shape in the dataset is  [  5.99999657 126.10837438 126.10837438]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [ 20.50000067 401.02463054 401.02463054]\n",
      "generating configuration for 3d_fullres\n",
      "{0: {'batch_size': 2, 'num_pool_per_axis': [2, 6, 6], 'patch_size': array([ 16, 320, 320]), 'median_patient_size_in_voxels': array([ 21, 401, 401]), 'current_spacing': array([2.5       , 0.39648438, 0.39648438]), 'original_spacing': array([2.5       , 0.39648438, 0.39648438]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[1, 2, 2], [1, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\n",
      "transpose forward [0, 1, 2]\n",
      "transpose backward [0, 1, 2]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /content/drive/My Drive/Colab Notebooks/nnUNet_raw_data_base/nnUNet_cropped_data/Task101_SCGM\n",
      "output_folder: /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([4.99999905, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999905, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 450\n",
      "before: {'spacing': array([4.99999714, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999714, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after: before: {'spacing': array([5.00000191, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000191, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "2 2444\n",
      "\n",
      "1 606\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc07-mask-r2.npz\n",
      "before: {'spacing': array([5.00000143, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000143, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      " {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "2 2734\n",
      "1 410\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc08-mask-r3.npz\n",
      "before: {'spacing': array([4.99999857, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "before: {'spacing': array([5.00000095, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "before: {'spacing': array([4.99999857, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "before: {'spacing': array([5.00000095, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after: 2 3262\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc09-mask-r4.npz\n",
      " {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 464\n",
      "2 2368\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc02-mask-r2.npz\n",
      "1 476\n",
      "2 2212\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc04-mask-r4.npz\n",
      "1 540\n",
      "1 396\n",
      "2 2888\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc01-mask-r1.npz\n",
      "2 2640\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc06-mask-r1.npz\n",
      "1 474\n",
      "2 2156\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc03-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([4.99999905, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999905, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "before: {'spacing': array([4.99999714, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999714, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after: 1 498\n",
      "2 2448\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc07-mask-r3.npz\n",
      " {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 482\n",
      "2 2674\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc08-mask-r4.npz\n",
      "before: {'spacing': array([5.00000095, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 552\n",
      "before: {'spacing': array([5.00000143, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000143, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "2 2468\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc06-mask-r2.npz\n",
      "1 482\n",
      "2 2462\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc02-mask-r3.npz\n",
      "before: {'spacing': array([4.99999857, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after: before: {'spacing': array([5.00000095, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      " {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "before: {'spacing': array([4.99999905, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999905, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after: \n",
      " {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 472\n",
      "2 2052\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc03-mask-r4.npz\n",
      "1 526\n",
      "2 2552\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc01-mask-r2.npz\n",
      "before: {'spacing': array([4.99999952, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999952, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 422\n",
      "2 2782\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc05-mask-r1.npz\n",
      "1 342\n",
      "2 2270\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc10-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([4.99999905, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999905, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "before: {'spacing': array([5.00000191, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000191, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 432\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "2 3472\n",
      "1 452\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc09-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "2 2378\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc07-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.00000095, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after: before: {'spacing': array([5.00000143, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000143, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      " {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 500\n",
      "1 574\n",
      "2 2622\n",
      "2 2406\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc02-mask-r4.npz\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc06-mask-r3.npz\n",
      "before: {'spacing': array([5.00000095, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 524\n",
      "2 2746\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc01-mask-r3.npz\n",
      "before: {'spacing': array([4.99999905, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999905, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "before: {'spacing': array([4.99999857, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 470\n",
      "2 2350\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc04-mask-r1.npz\n",
      "1 470\n",
      "2 1962\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc10-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([4.99999952, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999952, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 450\n",
      "2 2450\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc05-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([5.00000191, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000191, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 462\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "2 3178\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc09-mask-r2.npz\n",
      "before: {'spacing': array([4.99999714, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999714, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 420\n",
      "2 2952\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc08-mask-r1.npz\n",
      "before: {'spacing': array([5.00000095, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 520\n",
      "2 2450\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc06-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([4.99999857, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "before: {'spacing': array([5.00000095, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 482\n",
      "1 460\n",
      "2 2198\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc03-mask-r1.npz\n",
      "2 2632\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc01-mask-r4.npz\n",
      "before: {'spacing': array([4.99999857, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 506\n",
      "2 2168\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc04-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([4.99999905, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999905, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 542\n",
      "2 2066\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc10-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([4.99999952, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999952, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 488\n",
      "2 2660\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc05-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.00000191, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000191, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 546\n",
      "2 3248\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc09-mask-r3.npz\n",
      "before: {'spacing': array([4.99999714, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999714, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 574\n",
      "2 2448\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc08-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([4.99999905, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999905, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 372\n",
      "2 2636\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc07-mask-r1.npz\n",
      "before: {'spacing': array([5.00000143, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000143, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "before: {'spacing': array([4.99999857, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 498\n",
      "before: {'spacing': array([4.99999857, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after: 1 376\n",
      " {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "2 2008\n",
      "2 2612\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc02-mask-r1.npz\n",
      "1 554\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc03-mask-r2.npz\n",
      "2 2246\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc04-mask-r3.npz\n",
      "before: {'spacing': array([4.99999905, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999905, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 394\n",
      "2 2064\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc10-mask-r4.npz\n",
      "before: {'spacing': array([4.99999952, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999952, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 6, 126, 126)} \n",
      "\n",
      "1 416\n",
      "2 2608\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site1-sc05-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.50000048, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000048, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 7, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 21, 401, 401)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 2004\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc01-mask-r1.npz\n",
      "before: {'spacing': array([7.50000286, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000286, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 7, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 21, 401, 401)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 2067\n",
      "2 8880\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc07-mask-r2.npz\n",
      "before: {'spacing': array([7.50000095, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 10, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 30, 401, 401)} \n",
      "\n",
      "1 3447\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc03-mask-r3.npz\n",
      "before: {'spacing': array([7.50000143, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000143, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 12, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 36, 401, 401)} \n",
      "\n",
      "1 3807\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc02-mask-r2.npz\n",
      "before: {'spacing': array([7.50000048, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000048, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 39, 401, 401)} \n",
      "\n",
      "before: {'spacing': array([7.49999857, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 39, 401, 401)} \n",
      "\n",
      "before: {'spacing': array([7.5, 0.5, 0.5]), 'spacing_transposed': array([7.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 39, 401, 401)} \n",
      "\n",
      "before: {'spacing': array([7.50000238, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000238, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after: 1 3747\n",
      " {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 39, 401, 401)} \n",
      "\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc09-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 3678\n",
      "1 3372\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc08-mask-r3.npz\n",
      "1 3420\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc06-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc04-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.50000048, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000048, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 7, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 21, 401, 401)} \n",
      "\n",
      "before: {'spacing': array([7.50000286, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000286, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 7, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 21, 401, 401)} \n",
      "\n",
      "1 2070\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc01-mask-r2.npz\n",
      "1 2229\n",
      "2 9486\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc07-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.50000095, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 10, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 30, 401, 401)} \n",
      "\n",
      "1 3045\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc03-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.50000048, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000048, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 7, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 21, 401, 401)} \n",
      "\n",
      "1 2466\n",
      "2 9543\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc01-mask-r3.npz\n",
      "before: {'spacing': array([7.50000286, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000286, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 7, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 21, 401, 401)} \n",
      "\n",
      "1 1926\n",
      "2 9039\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc07-mask-r4.npz\n",
      "before: {'spacing': array([7.50000143, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000143, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 12, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 36, 401, 401)} \n",
      "\n",
      "1 4263\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc02-mask-r3.npz\n",
      "before: {'spacing': array([7.49999952, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999952, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 11, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 33, 401, 401)} \n",
      "\n",
      "1 2421\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc10-mask-r1.npz\n",
      "before: {'spacing': array([7.49999857, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 39, 401, 401)} \n",
      "\n",
      "1 3543\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc08-mask-r4.npz\n",
      "before: {'spacing': array([7.5, 0.5, 0.5]), 'spacing_transposed': array([7.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 39, 401, 401)} \n",
      "\n",
      "1 3582\n",
      "before: {'spacing': array([7.49999857, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 14, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 42, 401, 401)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc06-mask-r2.npz\n",
      "1 3999\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc05-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.50000048, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000048, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 7, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 21, 401, 401)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 2031\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc01-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.50000238, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000238, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 39, 401, 401)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 3474\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc04-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.49999857, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 39, 401, 401)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 2886\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc08-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.49999952, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999952, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 11, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 33, 401, 401)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.50000143, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000143, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 12, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 36, 401, 401)} \n",
      "\n",
      "1 3063\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc10-mask-r2.npz\n",
      "1 3420\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc02-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.50000048, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000048, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 39, 401, 401)} \n",
      "\n",
      "1 3387\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc09-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.5, 0.5, 0.5]), 'spacing_transposed': array([7.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 39, 401, 401)} \n",
      "\n",
      "1 4074\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc06-mask-r3.npz\n",
      "before: {'spacing': array([7.50000143, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000143, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 12, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 36, 401, 401)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.49999857, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 14, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 42, 401, 401)} \n",
      "\n",
      "1 3726\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc02-mask-r1.npz\n",
      "1 4452\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc05-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.50000238, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000238, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 39, 401, 401)} \n",
      "\n",
      "1 3471\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc04-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.49999857, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 39, 401, 401)} \n",
      "\n",
      "1 3285\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc08-mask-r2.npz\n",
      "before: {'spacing': array([7.50000095, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 10, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 30, 401, 401)} \n",
      "\n",
      "before: {'spacing': array([7.49999952, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999952, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 11, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 33, 401, 401)} \n",
      "\n",
      "1 2748\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc03-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 3081\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc10-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.50000048, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000048, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 39, 401, 401)} \n",
      "\n",
      "1 3735\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc09-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.5, 0.5, 0.5]), 'spacing_transposed': array([7.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 39, 401, 401)} \n",
      "\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 409)} \n",
      "\n",
      "1 3477\n",
      "1 892\n",
      "2 6305\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc01-mask-r1.npz\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc06-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.49999857, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 14, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 42, 401, 401)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 4887\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc05-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.50000095, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 10, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 30, 401, 401)} \n",
      "\n",
      "1 2826\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc03-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.49999952, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999952, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 11, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 33, 401, 401)} \n",
      "\n",
      "before: {'spacing': array([7.50000238, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000238, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 39, 401, 401)} \n",
      "\n",
      "1 2769\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc10-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 3759\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc04-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 650)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 410)} \n",
      "\n",
      "1 1428\n",
      "2 9767\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc02-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.50000286, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000286, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 7, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 21, 401, 401)} \n",
      "\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 409)} \n",
      "\n",
      "1 1887\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc07-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 1493\n",
      "2 8274\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc01-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.50000048, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000048, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 39, 401, 401)} \n",
      "\n",
      "1 3933\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc09-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.49999857, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 14, 318, 318)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 42, 401, 401)} \n",
      "\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "1 1773\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc03-mask-r3.npz\n",
      "1 4116\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site2-sc05-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 650)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 410)} \n",
      "\n",
      "1 1739\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 769, 650)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 485, 410)} \n",
      "\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc02-mask-r3.npz\n",
      "1 1220\n",
      "2 7473\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc04-mask-r4.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 651)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 410)} \n",
      "\n",
      "1 890\n",
      "2 6199\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc06-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "1 1409\n",
      "2 8641\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc07-mask-r2.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 409)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 1727\n",
      "2 8809\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc01-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "1 1629\n",
      "2 9328\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc08-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 1218\n",
      "2 8866\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc03-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 650)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 410)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 1315\n",
      "2 9188\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc02-mask-r4.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 409)} \n",
      "\n",
      "1 985\n",
      "2 7913\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc05-mask-r1.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 651)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 410)} \n",
      "\n",
      "1 1381\n",
      "2 7578\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc06-mask-r2.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 649)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "1 1394\n",
      "2 8236\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc09-mask-r4.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 1934\n",
      "2 9757\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc07-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 409)} \n",
      "\n",
      "1 1180\n",
      "2 7065\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc01-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 1241\n",
      "2 8027\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc08-mask-r4.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 769, 650)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 485, 410)} \n",
      "\n",
      "1 898\n",
      "2 6750\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc04-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 988\n",
      "2 7490\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc03-mask-r1.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 409)} \n",
      "\n",
      "1 1470\n",
      "2 9926\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc05-mask-r2.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "1 969\n",
      "2 7149\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc10-mask-r1.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 651)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 410)} \n",
      "\n",
      "1 1738\n",
      "2 8593\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc06-mask-r3.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 1369\n",
      "2 8537\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc07-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 650)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 410)} \n",
      "\n",
      "1 999\n",
      "2 7755\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc02-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 649)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "1 1134\n",
      "2 6788\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc09-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 769, 650)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 485, 410)} \n",
      "\n",
      "1 1280\n",
      "2 7917\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc04-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "1 1505\n",
      "2 9303\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc03-mask-r2.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 409)} \n",
      "\n",
      "1 1835\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc05-mask-r3.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "1 1467\n",
      "2 8804\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc10-mask-r2.npz\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 24, 378, 378)} \n",
      "\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 651)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 410)} \n",
      "\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "1 2004\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc01-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 1232\n",
      "2 7648\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc06-mask-r4.npz\n",
      "1 947\n",
      "2 6618\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc08-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 649)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 1730\n",
      "2 8702\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc09-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 769, 650)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 485, 410)} \n",
      "\n",
      "1 1487\n",
      "2 9962\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc04-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "1 2510\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 24, 378, 378)} \n",
      "\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc02-mask-r2.npz\n",
      "1 2154\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc01-mask-r2.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 409)} \n",
      "\n",
      "1 1329\n",
      "2 9878\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc05-mask-r4.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "1 1718\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc10-mask-r3.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "1 1061\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "2 7228\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc07-mask-r1.npz\n",
      "1 1339\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "2 8118\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc08-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 649)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "1 1909\n",
      "2 9785\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc09-mask-r3.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 2846\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc03-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 24, 378, 378)} \n",
      "\n",
      "1 2692\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc01-mask-r3.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "1 1184\n",
      "2 8878\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site3-sc10-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "1 3050\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc02-mask-r3.npz\n",
      "1 2232\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc04-mask-r4.npz\n",
      "1 2534\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc06-mask-r1.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "1 2894\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc07-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 24, 378, 378)} \n",
      "\n",
      "1 2696\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc08-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 24, 378, 378)} \n",
      "\n",
      "1 2474\n",
      "2 9970\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc01-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "1 1998\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc03-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 2424\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc09-mask-r4.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "1 2252\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc02-mask-r4.npz\n",
      "1 2544\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc05-mask-r1.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "1 2772\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc06-mask-r2.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "1 3112\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc07-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 24, 378, 378)} \n",
      "\n",
      "1 2038\n",
      "2 9790\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc08-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "1 2054\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc02-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "1 2478\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc04-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 24, 378, 378)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 2372\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc10-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "1 2054\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc03-mask-r1.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "1 2872\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc05-mask-r2.npz\n",
      "1 3300\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc06-mask-r3.npz\n",
      "1 2732\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc09-mask-r1.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 2406\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc07-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 24, 378, 378)} \n",
      "\n",
      "1 2662\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc10-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "1 2746\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc04-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 24, 378, 378)} \n",
      "\n",
      "1 2092\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc08-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "1 2234\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc03-mask-r2.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "1 2550\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc06-mask-r4.npz\n",
      "1 2922\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc09-mask-r2.npz\n",
      "1 3306\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc05-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 24, 378, 378)} \n",
      "\n",
      "1 2788\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc10-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 24, 378, 378)} \n",
      "\n",
      "1 2420\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc08-mask-r2.npz\n",
      "1 3100\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc04-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 24, 378, 378)} \n",
      "\n",
      "1 1960\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc10-mask-r4.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "1 2556\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc07-mask-r1.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 28, 404, 404)} \n",
      "\n",
      "1 3338\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc09-mask-r3.npz\n",
      "1 2362\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_stage0/site4-sc05-mask-r4.npz\n",
      "not using nonzero mask for normalization\n",
      "Are we using the nonzero maks for normalizaion? OrderedDict([(0, False)])\n",
      "the median shape of the dataset is  [ 10.25000033 401.02463054 401.02463054]\n",
      "the max shape in the dataset is  [ 20.99999599 485.51724138 410.48275862]\n",
      "the min shape in the dataset is  [  2.99999828 126.10837438 126.10837438]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [ 10.25000033 401.02463054 401.02463054]\n",
      "[{'batch_size': 16, 'num_pool_per_axis': [6, 6], 'patch_size': array([448, 448]), 'median_patient_size_in_voxels': array([ 10, 401, 401]), 'current_spacing': array([5.        , 0.39648438, 0.39648438]), 'original_spacing': array([5.        , 0.39648438, 0.39648438]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /content/drive/My Drive/Colab Notebooks/nnUNet_raw_data_base/nnUNet_cropped_data/Task101_SCGM\n",
      "output_folder: /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([4.99999905, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999905, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999905, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "before: {'spacing': array([4.99999857, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999857, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([4.99999714, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999714, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after: before: {'spacing': array([4.99999857, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after: before: {'spacing': array([5.00000095, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([5.00000095, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([5.00000191, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000191, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([5.00000191, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      " {'spacing': array([4.99999857, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "before: {'spacing': array([5.00000095, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([5.00000095, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      " {'spacing': array([4.99999714, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "normalization done\n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 225\n",
      "2 1222\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc07-mask-r2.npz\n",
      "normalization done\n",
      "normalization done\n",
      "1 237\n",
      "2 1078\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc03-mask-r3.npz\n",
      "1 205\n",
      "2 1631\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc09-mask-r4.npz\n",
      "before: {'spacing': array([5.00000143, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000143, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([5.00000143, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "1 198\n",
      "2 1444\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc01-mask-r1.npz\n",
      "\n",
      "normalization...\n",
      "1 303\n",
      "1 238\n",
      "normalization done\n",
      "1 270\n",
      "2 1320\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc06-mask-r1.npz\n",
      "2 1367\n",
      "2 1106\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc04-mask-r4.npz\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc08-mask-r3.npz\n",
      "1 232\n",
      "2 1184\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc02-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([4.99999905, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999905, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999905, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 171\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "2 1135\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc10-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.00000095, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([5.00000095, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 276\n",
      "2 1234\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc06-mask-r2.npz\n",
      "before: {'spacing': array([4.99999905, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999905, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999905, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 249\n",
      "2 1224\n",
      "before: {'spacing': array([4.99999952, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999952, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after: saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc07-mask-r3.npz\n",
      " {'spacing': array([4.99999952, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "before: {'spacing': array([4.99999857, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999857, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "before: {'spacing': array([5.00000143, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000143, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([5.00000143, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "before: {'spacing': array([4.99999714, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999714, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999714, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization...\n",
      "1 211\n",
      "2 1391\n",
      "before: {'spacing': array([5.00000095, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([5.00000095, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "1 236\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc05-mask-r1.npz\n",
      "normalization done\n",
      "normalization done\n",
      "2 1026\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc03-mask-r4.npz\n",
      "1 241\n",
      "2 1337\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc08-mask-r4.npz\n",
      "normalization...\n",
      "normalization done\n",
      "1 241\n",
      "2 1231\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc02-mask-r3.npz\n",
      "1 263\n",
      "2 1276\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc01-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([4.99999905, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999905, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999905, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 235\n",
      "2 981\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc10-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.00000095, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([5.00000095, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 287\n",
      "2 1311\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc06-mask-r3.npz\n",
      "before: {'spacing': array([4.99999952, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999952, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999952, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "before: {'spacing': array([4.99999905, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999905, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999905, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 226\n",
      "2 1189\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc07-mask-r4.npz\n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 225\n",
      "2 1225\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc05-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([4.99999857, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999857, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 235\n",
      "2 1175\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc04-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.00000143, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000143, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([5.00000143, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 250\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "2 1203\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc02-mask-r4.npz\n",
      "before: {'spacing': array([5.00000095, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([5.00000095, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 262\n",
      "2 1373\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc01-mask-r3.npz\n",
      "before: {'spacing': array([5.00000191, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000191, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([5.00000191, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 216\n",
      "2 1736\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc09-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([4.99999905, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999905, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999905, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 271\n",
      "2 1033\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc10-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.00000095, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([5.00000095, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 260\n",
      "2 1225\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc06-mask-r4.npz\n",
      "before: {'spacing': array([4.99999952, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999952, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999952, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "normalization done\n",
      "1 244\n",
      "before: {'spacing': array([4.99999714, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999714, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after: 2 1330\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc05-mask-r3.npz\n",
      " {'spacing': array([4.99999714, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 210\n",
      "2 1476\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc08-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([4.99999857, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999857, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 253\n",
      "2 1084\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc04-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([5.00000095, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([5.00000095, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 241\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "2 1316\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc01-mask-r4.npz\n",
      "before: {'spacing': array([4.99999857, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999857, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "normalization done\n",
      "1 230\n",
      "2 1099\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc03-mask-r1.npz\n",
      "before: {'spacing': array([5.00000191, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000191, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([5.00000191, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 231\n",
      "2 1589\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc09-mask-r2.npz\n",
      "before: {'spacing': array([4.99999905, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999905, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999905, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "before: {'spacing': array([4.99999905, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999905, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999905, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 197\n",
      "1 186\n",
      "2 1032\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc10-mask-r4.npz\n",
      "2 1318\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc07-mask-r1.npz\n",
      "before: {'spacing': array([4.99999952, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999952, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after: separate z, order in z is 0 order inplane is 3\n",
      " {'spacing': array([4.99999952, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "before: {'spacing': array([4.99999714, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999714, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999714, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 208\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "2 1304\n",
      "1 287\n",
      "2 1224\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc08-mask-r2.npz\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc05-mask-r4.npz\n",
      "before: {'spacing': array([4.99999857, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999857, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 277\n",
      "2 1123\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc04-mask-r3.npz\n",
      "before: {'spacing': array([5.00000143, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000143, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([5.00000143, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 188\n",
      "2 1306\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc02-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([5.00000191, 0.5       , 0.5       ]), 'spacing_transposed': array([5.00000191, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([5.00000191, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([4.99999857, 0.5       , 0.5       ]), 'spacing_transposed': array([4.99999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 3, 100, 100)} \n",
      "after:  {'spacing': array([4.99999857, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 3, 126, 126)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 249\n",
      "normalization done\n",
      "2 1004\n",
      "1 273\n",
      "2 1624\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc09-mask-r3.npz\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site1-sc03-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.50000048, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000048, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 7, 318, 318)} \n",
      "after:  {'spacing': array([7.50000048, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 7, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "normalization done\n",
      "1 668\n",
      "2 3334\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc01-mask-r1.npz\n",
      "before: {'spacing': array([7.50000286, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000286, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 7, 318, 318)} \n",
      "after:  {'spacing': array([7.50000286, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 7, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 689\n",
      "2 2960\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc07-mask-r2.npz\n",
      "before: {'spacing': array([7.50000095, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 10, 318, 318)} \n",
      "after:  {'spacing': array([7.50000095, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 10, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1149\n",
      "2 4499\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc03-mask-r3.npz\n",
      "before: {'spacing': array([7.50000143, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000143, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 12, 318, 318)} \n",
      "after:  {'spacing': array([7.50000143, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 12, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([7.5, 0.5, 0.5]), 'spacing_transposed': array([7.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([7.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 13, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "before: {'spacing': array([7.50000238, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000238, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([7.50000238, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 13, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "1 1269\n",
      "normalization done\n",
      "2 5273\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc02-mask-r2.npz\n",
      "normalization done\n",
      "1 1124\n",
      "2 5251\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc06-mask-r1.npz\n",
      "1 1140\n",
      "2 4871\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc04-mask-r4.npz\n",
      "before: {'spacing': array([7.49999857, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([7.49999857, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 13, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([7.50000048, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000048, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([7.50000048, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 13, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 1226\n",
      "1 1249\n",
      "2 4939\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc08-mask-r3.npz\n",
      "2 5174\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc09-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.50000048, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000048, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 7, 318, 318)} \n",
      "after:  {'spacing': array([7.50000048, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 7, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 690\n",
      "2 3395\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc01-mask-r2.npz\n",
      "before: {'spacing': array([7.50000286, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000286, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 7, 318, 318)} \n",
      "after:  {'spacing': array([7.50000286, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 7, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 743\n",
      "2 3162\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc07-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.50000095, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 10, 318, 318)} \n",
      "after:  {'spacing': array([7.50000095, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 10, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1015\n",
      "2 4435\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc03-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.50000048, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000048, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 7, 318, 318)} \n",
      "after:  {'spacing': array([7.50000048, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 7, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 822\n",
      "2 3181\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc01-mask-r3.npz\n",
      "before: {'spacing': array([7.50000286, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000286, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 7, 318, 318)} \n",
      "after:  {'spacing': array([7.50000286, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 7, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 642\n",
      "2 3013\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc07-mask-r4.npz\n",
      "before: {'spacing': array([7.50000143, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000143, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 12, 318, 318)} \n",
      "after:  {'spacing': array([7.50000143, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 12, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1421\n",
      "2 5412\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc02-mask-r3.npz\n",
      "before: {'spacing': array([7.49999952, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999952, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 11, 318, 318)} \n",
      "after: before: {'spacing': array([7.5, 0.5, 0.5]), 'spacing_transposed': array([7.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([7.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 13, 401, 401)} \n",
      "\n",
      " {'spacing': array([7.49999952, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 11, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 807\n",
      "2 4659\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc10-mask-r1.npz\n",
      "1 1194\n",
      "before: {'spacing': array([7.49999857, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([7.49999857, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 13, 401, 401)} \n",
      "\n",
      "before: {'spacing': array([7.49999857, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 14, 318, 318)} \n",
      "after:  {'spacing': array([7.49999857, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "2 4697\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc06-mask-r2.npz\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 1333\n",
      "1 1181\n",
      "2 6463\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc05-mask-r1.npz\n",
      "2 4905\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc08-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.50000048, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000048, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 7, 318, 318)} \n",
      "after:  {'spacing': array([7.50000048, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 7, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 677\n",
      "2 3450\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc01-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.50000238, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000238, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([7.50000238, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 13, 401, 401)} \n",
      "separate z, order in z is 0 order inplane is 3\n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "before: {'spacing': array([7.49999857, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([7.49999857, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 13, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 1158\n",
      "2 4873\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc04-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "normalization done\n",
      "1 962\n",
      "2 5300\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc08-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.50000143, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000143, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 12, 318, 318)} \n",
      "after:  {'spacing': array([7.50000143, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 12, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([7.49999952, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999952, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 11, 318, 318)} \n",
      "after:  {'spacing': array([7.49999952, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 11, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "normalization done\n",
      "normalization done\n",
      "1 1140\n",
      "2 5394\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc02-mask-r4.npz\n",
      "1 1021\n",
      "2 3953\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc10-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.5, 0.5, 0.5]), 'spacing_transposed': array([7.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([7.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 13, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "before: {'spacing': array([7.50000048, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000048, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([7.50000048, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 13, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "1 1358\n",
      "2 5096\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc06-mask-r3.npz\n",
      "normalization done\n",
      "1 1129\n",
      "2 5613\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc09-mask-r1.npz\n",
      "before: {'spacing': array([7.49999857, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 14, 318, 318)} \n",
      "after:  {'spacing': array([7.49999857, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1484\n",
      "2 6652\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc05-mask-r2.npz\n",
      "before: {'spacing': array([7.50000143, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000143, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 12, 318, 318)} \n",
      "after:  {'spacing': array([7.50000143, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 12, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "normalization done\n",
      "1 1242\n",
      "2 5724\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc02-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.50000238, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000238, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([7.50000238, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 13, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1157\n",
      "2 4749\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc04-mask-r2.npz\n",
      "before: {'spacing': array([7.49999857, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([7.49999857, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 13, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([7.50000095, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 10, 318, 318)} \n",
      "after: normalization done\n",
      " {'spacing': array([7.50000095, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 10, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 1095\n",
      "2 4739\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc08-mask-r2.npz\n",
      "normalization done\n",
      "1 916\n",
      "2 4726\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc03-mask-r1.npz\n",
      "before: {'spacing': array([7.49999952, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999952, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 11, 318, 318)} \n",
      "after:  {'spacing': array([7.49999952, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 11, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 1027\n",
      "2 4337\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc10-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.5, 0.5, 0.5]), 'spacing_transposed': array([7.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([7.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 13, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1159\n",
      "before: {'spacing': array([7.50000048, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000048, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([7.50000048, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 13, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "2 4970\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc06-mask-r4.npz\n",
      "normalization done\n",
      "1 1245\n",
      "2 5149\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc09-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.49999857, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 14, 318, 318)} \n",
      "after:  {'spacing': array([7.49999857, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "normalization done\n",
      "1 1629\n",
      "2 6609\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc05-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.50000095, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000095, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 10, 318, 318)} \n",
      "after:  {'spacing': array([7.50000095, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 10, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "normalization done\n",
      "1 942\n",
      "2 4395\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc03-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.49999952, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999952, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 11, 318, 318)} \n",
      "after:  {'spacing': array([7.49999952, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 11, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 923\n",
      "before: {'spacing': array([7.50000238, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000238, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([7.50000238, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 13, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "2 4030\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc10-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "normalization done\n",
      "1 1253\n",
      "2 4858\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc04-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.50000286, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000286, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 7, 318, 318)} \n",
      "after:  {'spacing': array([7.50000286, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 7, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "normalization done\n",
      "1 629\n",
      "2 3349\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc07-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([7.50000048, 0.5       , 0.5       ]), 'spacing_transposed': array([7.50000048, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 13, 318, 318)} \n",
      "after:  {'spacing': array([7.50000048, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 13, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 648)} \n",
      "after: 1 1311\n",
      " {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 409)} \n",
      "\n",
      "normalization...\n",
      "2 5369\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc09-mask-r3.npz\n",
      "normalization done\n",
      "1 892\n",
      "2 6305\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc01-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([7.49999857, 0.5       , 0.5       ]), 'spacing_transposed': array([7.49999857, 0.5       , 0.5       ]), 'data.shape (data is transposed)': (1, 14, 318, 318)} \n",
      "after:  {'spacing': array([7.49999857, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 401, 401)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1372\n",
      "2 6522\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site2-sc05-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 650)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 410)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "normalization done\n",
      "1 1428\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "2 9767\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc02-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 651)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 410)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 769, 650)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 485, 410)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "1 1773\n",
      "1 890\n",
      "normalization done\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc03-mask-r3.npz\n",
      "2 6199\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc06-mask-r1.npz\n",
      "1 1220\n",
      "normalization done\n",
      "2 7473\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc04-mask-r4.npz\n",
      "1 1409\n",
      "2 8641\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc07-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1629\n",
      "2 9328\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc08-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 649)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1394\n",
      "2 8236\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc09-mask-r4.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1493\n",
      "2 8274\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc01-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 650)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 410)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 1739\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc02-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "normalization done\n",
      "1 1218\n",
      "2 8866\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc03-mask-r4.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 651)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 410)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 409)} \n",
      "\n",
      "normalization...\n",
      "1 1381\n",
      "normalization done\n",
      "2 7578\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc06-mask-r2.npz\n",
      "normalization done\n",
      "1 1934\n",
      "2 9757\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc07-mask-r3.npz\n",
      "1 985\n",
      "2 7913\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc05-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1241\n",
      "2 8027\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc08-mask-r4.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 969\n",
      "2 7149\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc10-mask-r1.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1727\n",
      "2 8809\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc01-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 650)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 410)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1315\n",
      "2 9188\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc02-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 769, 650)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 485, 410)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "normalization done\n",
      "1 898\n",
      "2 6750\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc04-mask-r1.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 651)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 410)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 1738\n",
      "2 8593\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc06-mask-r3.npz\n",
      "1 1369\n",
      "2 8537\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc07-mask-r4.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 1470\n",
      "2 9926\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc05-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 649)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1134\n",
      "2 6788\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc09-mask-r1.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "normalization done\n",
      "1 1467\n",
      "2 8804\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc10-mask-r2.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1180\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "2 7065\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc01-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 988\n",
      "2 7490\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc03-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 769, 650)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 485, 410)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "normalization done\n",
      "1 1280\n",
      "2 7917\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc04-mask-r2.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 947\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 651)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 410)} \n",
      "\n",
      "normalization...\n",
      "2 6618\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc08-mask-r1.npz\n",
      "normalization done\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 1232\n",
      "2 7648\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc06-mask-r4.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 409)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "normalization done\n",
      "1 1835\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc05-mask-r3.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 649)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1730\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "2 8702\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc09-mask-r2.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1718\n",
      "2 10000\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc10-mask-r3.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 650)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 410)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 999\n",
      "2 7755\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc02-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "normalization done\n",
      "1 1505\n",
      "2 9303\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc03-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 769, 650)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 485, 410)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 1487\n",
      "2 9962\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc04-mask-r3.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "1 1339\n",
      "2 8118\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc08-mask-r2.npz\n",
      "normalization done\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([5.00024986, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 12, 378, 378)} \n",
      "\n",
      "normalization...\n",
      "1 1061\n",
      "2 7228\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc07-mask-r1.npz\n",
      "normalization done\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 1002\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 770, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 486, 409)} \n",
      "\n",
      "2 5598\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc01-mask-r1.npz\n",
      "normalization...\n",
      "normalization done\n",
      "1 1329\n",
      "2 9878\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc05-mask-r4.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 649)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1909\n",
      "2 9785\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc09-mask-r3.npz\n",
      "before: {'spacing': array([2.5 , 0.25, 0.25]), 'spacing_transposed': array([2.5 , 0.25, 0.25]), 'data.shape (data is transposed)': (1, 20, 768, 648)} \n",
      "after:  {'spacing': array([2.5       , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 20, 484, 409)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 1255\n",
      "2 5575\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc02-mask-r2.npz\n",
      "1 1184\n",
      "2 8878\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site3-sc10-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([5.00024986, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 12, 378, 378)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1077\n",
      "2 5167\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc01-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1423\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "2 5332\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc03-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 1116\n",
      "2 6226\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc04-mask-r4.npz\n",
      "1 1267\n",
      "2 7534\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc06-mask-r1.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 1525\n",
      "1 1447\n",
      "2 5409\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc02-mask-r3.npz\n",
      "2 6155\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc07-mask-r2.npz\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([5.00024986, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 12, 378, 378)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1348\n",
      "2 5347\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc08-mask-r3.npz\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([5.00024986, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 12, 378, 378)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1346\n",
      "2 5151\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc01-mask-r3.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1212\n",
      "2 5730\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc09-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([5.00024986, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 12, 378, 378)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1019\n",
      "2 4895\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc08-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([5.00024986, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 12, 378, 378)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1237\n",
      "2 4985\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc01-mask-r4.npz\n",
      "normalization done\n",
      "1 999\n",
      "2 5269\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc03-mask-r4.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1272\n",
      "normalization done\n",
      "2 6079\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc05-mask-r1.npz\n",
      "1 1386\n",
      "2 7191\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc06-mask-r2.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1126\n",
      "normalization done\n",
      "2 5060\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc02-mask-r4.npz\n",
      "1 1556\n",
      "2 6167\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc07-mask-r3.npz\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([5.00024986, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 12, 378, 378)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1186\n",
      "2 6424\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc10-mask-r1.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "1 1366\n",
      "2 6324\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc09-mask-r1.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1027\n",
      "2 6067\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc02-mask-r1.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([5.00024986, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 12, 378, 378)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 1239\n",
      "1 1331\n",
      "2 6108\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc10-mask-r2.npz\n",
      "2 6917\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc04-mask-r1.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "1 1650\n",
      "1 1436\n",
      "2 5824\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc05-mask-r2.npz\n",
      "2 6885\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc06-mask-r3.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "1 1027\n",
      "2 5838\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc03-mask-r1.npz\n",
      "normalization done\n",
      "1 1203\n",
      "2 5641\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc07-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "normalization done\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([5.00024986, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 12, 378, 378)} \n",
      "\n",
      "normalization...\n",
      "1 1461\n",
      "normalization done\n",
      "2 6332\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc09-mask-r2.npz\n",
      "1 1394\n",
      "2 6126\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc10-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([5.00024986, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 12, 378, 378)} \n",
      "\n",
      "normalization...\n",
      "1 1373\n",
      "2 6370\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc04-mask-r2.npz\n",
      "normalization done\n",
      "1 1046\n",
      "2 5652\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc08-mask-r1.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "1 1275\n",
      "2 6529\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc06-mask-r4.npz\n",
      "normalization done\n",
      "1 1653\n",
      "2 5498\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc05-mask-r3.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1117\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "2 5584\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc03-mask-r2.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([5.00024986, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 12, 378, 378)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "1 980\n",
      "2 5473\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc10-mask-r4.npz\n",
      "separate z, order in z is 0 order inplane is 3\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after: separate z, order in z is 0 order inplane is 1\n",
      " {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1669\n",
      "2 5966\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc09-mask-r3.npz\n",
      "separate z, order in z is 0 order inplane is 1\n",
      "before: {'spacing': array([5.00024986, 0.29296875, 0.29296875]), 'spacing_transposed': array([5.00024986, 0.29296875, 0.29296875]), 'data.shape (data is transposed)': (1, 12, 512, 512)} \n",
      "after:  {'spacing': array([5.00024986, 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 12, 378, 378)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 1210\n",
      "2 5250\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc08-mask-r2.npz\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "1 1550\n",
      "2 6484\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc04-mask-r3.npz\n",
      "normalization done\n",
      "before: {'spacing': array([5.       , 0.2857143, 0.2857143]), 'spacing_transposed': array([5.       , 0.2857143, 0.2857143]), 'data.shape (data is transposed)': (1, 14, 560, 560)} \n",
      "after:  {'spacing': array([5.        , 0.39648438, 0.39648438]), 'data.shape (data is resampled)': (1, 14, 404, 404)} \n",
      "\n",
      "normalization...\n",
      "1 1278\n",
      "2 6540\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc07-mask-r1.npz\n",
      "normalization done\n",
      "1 1181\n",
      "2 5702\n",
      "saving:  /content/drive/My Drive/Colab Notebooks/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1_2D_stage0/site4-sc05-mask-r4.npz\n"
     ]
    }
   ],
   "source": [
    "# verify that the dataset will work & create plans - this may take about 11 minutes\n",
    "!nnUNet_plan_and_preprocess -t 501 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yW8MX96FAmjO"
   },
   "source": [
    "## 7.6 Dataset Visualization\n",
    "At this stage it is useful to examine the training and testing data.\n",
    "\n",
    "Here is an example for how to do this in python, however we would encourage you to visualize the data with MITK-Workbench, since it allows much more interaction with the data and therefore better understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAdAHMdMA4eR"
   },
   "source": [
    "Train Data (with Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "executionInfo": {
     "elapsed": 939,
     "status": "ok",
     "timestamp": 1643041791697,
     "user": {
      "displayName": "Carsten L",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16100963491359375963"
     },
     "user_tz": -60
    },
    "id": "vAzrqTrkAooq",
    "outputId": "652abcd1-82d2-4450-db09-5f1b67787f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 3) (100, 100, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualizing some of the training images and labels\n",
    "# (re-run to see random pick-ups)\n",
    "# only maximum of first 5 slices are plotted\n",
    "train_img_name = os.listdir(train_image_dir)[np.random.randint(0,160)]\n",
    "train_img = np.array(nib.load(os.path.join(train_image_dir,train_img_name)).dataobj)[:,:,:5]\n",
    "train_label_name = train_img_name[:train_img_name.find('_0000.nii.gz')]+'.nii.gz'\n",
    "train_label = np.array(nib.load(os.path.join(train_label_dir,train_label_name)).dataobj)[:,:,:5]\n",
    "\n",
    "print(train_img.shape,train_label.shape)\n",
    "\n",
    "max_rows = 2\n",
    "max_cols = train_img.shape[2]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=max_rows, ncols=max_cols, figsize=(20,8))\n",
    "for idx in range(max_cols):\n",
    "    axes[0, idx].axis(\"off\") \n",
    "    axes[0, idx].set_title('Train Image'+str(idx+1))\n",
    "    axes[0 ,idx].imshow(train_img[:,:,idx], cmap=\"gray\")\n",
    "for idx in range(max_cols):    \n",
    "    axes[1, idx].axis(\"off\")\n",
    "    axes[1, idx].set_title('Train Label'+str(idx+1))\n",
    "    axes[1, idx].imshow(train_label[:,:,idx])\n",
    "\n",
    "plt.subplots_adjust(wspace=.1, hspace=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4I5iZ03pAxtO"
   },
   "source": [
    "Note: In the label image, yellow color represents white Matter and green-ish color represents grey matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vicf7OmVA_Gb"
   },
   "source": [
    "Test Data (without Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gi1VwbsIAu7b"
   },
   "outputs": [],
   "source": [
    "# skip this due to non-existent data\n",
    "\n",
    "#visualizing some of the test images\n",
    "# (re-run to see random pick-ups)\n",
    "# only maximum of first 5 slices are plotted\n",
    "\n",
    "# test_img_name = os.listdir(test_dir)[np.random.randint(0,40)]\n",
    "# test_img = np.array(nib.load(os.path.join(test_dir,test_img_name)).dataobj)[:,:,:5]\n",
    "\n",
    "# print(test_img.shape)\n",
    "\n",
    "# max_cols = test_img.shape[2]\n",
    "# max_rows = 1\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=max_rows, ncols=max_cols, figsize=(20,20))\n",
    "# for idx in range(max_cols):\n",
    "#     axes[ idx].axis(\"off\") \n",
    "#     axes[ idx].set_title('Test Image'+str(idx))\n",
    "#     axes[ idx].imshow(test_img[:,:,idx], cmap=\"gray\")\n",
    "    \n",
    "    \n",
    "# plt.subplots_adjust(wspace=.1, hspace=.1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dup4exmGvPZW"
   },
   "source": [
    "### 7.6.1 Sighting of Data and Lables with MITK-Workbench\n",
    "At this stage it is also useful to analyze the imaging data with MITK-Workbench.\n",
    "To do this, download the training data to your own local machine and visualize them via drag and drop into MITK-Workbench\n",
    "\n",
    "This is already explained in part 6.3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeeY1Yh_BV14"
   },
   "source": [
    "## 7.7 Training nnU-Net\n",
    "\n",
    "nnU-Net stores a checkpoint every 50 epochs. If you need to continue a previous training, just add a -c to the training command.\n",
    "\n",
    "Generic Training Commands:\n",
    "\n",
    "```nnUNet_train CONFIGURATION TRAINER_CLASS_NAME TASK_NAME_OR_ID FOLD (additional options)```\n",
    "\n",
    "For 2D:  ```nnUNet_train 2d nnUNetTrainerV2 TaskXXX_MYTASK FOLD```\n",
    "\n",
    "For 3D Full resolution: ```nnUNet_train 3d_fullres nnUNetTrainerV2 TaskXXX_MYTASK FOLD```\n",
    "\n",
    "For Cascaded 3D:\n",
    "\n",
    "First Run lowres: ```nnUNet_train 3d_lowres nnUNetTrainerV2 TaskXXX_MYTASK FOLD```\n",
    "\n",
    "Then Run fullres: ```nnUNet_train 3d_cascade_fullres nnUNetTrainerV2CascadeFullRes TaskXXX_MYTASK FOLD```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNWpcAnVBDhX",
    "outputId": "7a7d58ac-f727-4a4a-b29a-ddf7fa7964a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  2\n",
      "modalities:  {0: 'MRI'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [2, 6, 6], 'patch_size': array([ 16, 320, 320]), 'median_patient_size_in_voxels': array([ 21, 401, 401]), 'current_spacing': array([2.5       , 0.39648438, 0.39648438]), 'original_spacing': array([2.5       , 0.39648438, 0.39648438]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[1, 2, 2], [1, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /content/nnUNet_preprocessed/Task101_SCGM/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "2022-01-24 16:30:04.509631: Using dummy2d data augmentation\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2022-01-24 16:30:04.760235: Creating new 5-fold cross-validation split...\n",
      "2022-01-24 16:30:04.765513: Desired fold for training: 0\n",
      "2022-01-24 16:30:04.768678: This split has 128 training and 32 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2022-01-24 16:31:18.840379: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2022-01-24 16:31:58.841006: Unable to plot network architecture:\n",
      "2022-01-24 16:31:58.847499: No module named 'hiddenlayer'\n",
      "2022-01-24 16:31:58.854697: \n",
      "printing the network instead:\n",
      "\n",
      "2022-01-24 16:31:58.908292: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)\n",
      "    (1): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(128, 64, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)\n",
      "    (5): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(320, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(256, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(128, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (5): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2022-01-24 16:31:58.928155: \n",
      "\n",
      "2022-01-24 16:31:58.944025: \n",
      "epoch:  0\n"
     ]
    }
   ],
   "source": [
    "# train nnU-Net with 3d_fullres model on the SCGM Task with Fold 0\n",
    "# Again Training may take a while therefore it is advised to interrupt the training after some time (e.g. after 1 epoch)\n",
    "# 1 Epoch takes approximately: over 30 minutes on GoogleColab -- you need GoogleColab Pro to run this completely\n",
    "!nnUNet_train 3d_fullres nnUNetTrainerV2 501 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPHW8VZ0C7lP"
   },
   "source": [
    "## 7.8 Inference Code\n",
    "\n",
    "nnUNet_find_best_configuration will print inference commands you need to use. The easiest way to run inference is to simply use these commands.\n",
    "\n",
    "For each of the desired configurations, run:\n",
    "\n",
    "```nnUNet_predict -i INPUT_FOLDER -o OUTPUT_FOLDER -t TASK_NAME_OR_ID -m CONFIGURATION --save_npz```\n",
    "\n",
    "Only specify ```--save_npz``` if you intend to use ensembling. ```--save_npz``` will make the command save the softmax probabilities alongside of the predicted segmentation masks requiring a lot of disk space.\n",
    "\n",
    "Note: Please select a separate OUTPUT_FOLDER for each configuration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ordg3hM7DGx6"
   },
   "outputs": [],
   "source": [
    "# Optional\n",
    "!nnUNet_find_best_configuration -t 501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u44bFWQoDQLV"
   },
   "outputs": [],
   "source": [
    "result_dir = os.path.join(os.getenv(\"RESULTS_FOLDER\"),'nnUNet_Prediction_Results',task_name)\n",
    "make_if_dont_exist(result_dir)\n",
    "\n",
    "team_name = 'awesome_nnU-Net_team' #make sure to change for your own team name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFhCbIP2DXnj"
   },
   "source": [
    "**Note**: \n",
    "\n",
    "If you interrupted the training go the given fold inside of the RESULTS_FOLDER for the task and:\n",
    "1. rename **model_best.model.pkl** to **model_final_checkpoint.model.pkl** \n",
    "2. rename **model_best.model** to **model_final_checkpoint.model** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XH86gjTJDRks"
   },
   "outputs": [],
   "source": [
    "#location where you want save your results, will be created if dont exist\n",
    "!nnUNet_predict -i '${nnUNet_raw_data_base}/nnUNet_raw_data/Task101_SCGM/imagesTs' -o '${RESULTS_FOLDER}/Task101_SCGM/predTs' -t 501 -tr nnUNetTrainerV2 -m 3d_fullres #--num_threads_preprocessing 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrybnwGkDzeA"
   },
   "source": [
    "If you wish to run ensembling, you can ensemble the predictions from several configurations with the following command:\n",
    "\n",
    "```nnUNet_ensemble -f FOLDER1 FOLDER2 ... -o OUTPUT_FOLDER -pp POSTPROCESSING_FILE```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xkk_cgwpD4Tg"
   },
   "source": [
    "## 7.9 Visualization of Predictions\n",
    "Similar to the dataset visualization we would encourage you to do this with MITIK-Workbench.\n",
    "\n",
    "Here is a quick visualization with python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qBVpSIPED7b"
   },
   "outputs": [],
   "source": [
    "#visualizing the predicted results\n",
    "# (re-run to see random pick-ups)\n",
    "# only maximum of first 5 slices are plotted\n",
    "\n",
    "test_img_name = os.listdir(test_dir)[np.random.randint(0,40)]\n",
    "test_img = np.array(nib.load(os.path.join(test_dir,test_img_name)).dataobj)[:,:,:5]\n",
    "predicted_img_name = test_img_name[:test_img_name.find('_0000.nii.gz')]+'.nii.gz'\n",
    "predicted_label = np.array(nib.load(os.path.join(result_dir,predicted_img_name)).dataobj)[:,:,:5]\n",
    "print('Test Image Shape: ',test_img.shape)\n",
    "print(\"Predicted Image Shape:\",predicted_label.shape)\n",
    "\n",
    "max_rows = 2\n",
    "max_cols = test_img.shape[2]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=max_rows, ncols=max_cols, figsize=(20,8))\n",
    "for idx in range(max_cols):\n",
    "    axes[0, idx].axis(\"off\") \n",
    "    axes[0, idx].set_title('Test Image'+str(idx+1))\n",
    "    axes[0 ,idx].imshow(test_img[:,:,idx], cmap=\"gray\")\n",
    "for idx in range(max_cols):    \n",
    "    axes[1, idx].axis(\"off\")\n",
    "    axes[1, idx].set_title('Predicted Label'+str(idx+1))\n",
    "    axes[1, idx].imshow(predicted_label[:,:,idx])\n",
    "    \n",
    "plt.subplots_adjust(wspace=.1, hspace=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnX5wrhC1Dgk"
   },
   "source": [
    "# 8. Final Words\n",
    "The Workshop and this tutorial is now finished.\n",
    "\n",
    "If you made it this far, we hope you enjoyed the ride.\n",
    "\n",
    "To further expand your knowledge about nnU-Net you may now want to tackle one of the following tasks:\n",
    "- Use Pretrained nnU-Net models for other Decathlon Tasks.\n",
    "- Look up a Dataset of your own and implement a new Task for nnU-Net.\n",
    "- Download the nnU-Net repository to your local machine and familiarize yourself with the codebase.\n",
    "\n",
    "Please feel free to share it with people who you believe might benefit from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgements\n",
    "Many thanks to the people who tested this tutorial and gave feedback:\n",
    "- Stephen Schaumann\n",
    "- Robin Peretzke\n",
    "- Santhosh P.\n",
    "- Jonas Bohn\n",
    "- Sebastian Ziegler\n",
    "- Yannick Kirchhoff\n",
    "- Tobias Norajitra\n",
    "- Lars Krämer\n",
    "- Peter Full\n",
    "- Sebastian Zieger\n",
    "- Lukas Klein\n",
    "- Tassilo Wald\n",
    "- Stefan Dinkelacker\n",
    "- Fabian Isensee\n",
    "- Paul Jäger"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nnU-Net_Workshop-IML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
